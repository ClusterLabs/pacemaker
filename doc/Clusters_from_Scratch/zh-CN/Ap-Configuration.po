#
# AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: 0\n"
"POT-Creation-Date: 2012-10-17T05:19:03\n"
"PO-Revision-Date: 2010-12-15 23:34+0800\n"
"Last-Translator: Charlie Chen <laneovcc@gmail.com>\n"
"Language-Team: None\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. Tag: title
#, no-c-format
msgid "Configuration Recap"
msgstr "配置扼要重述"

#. Tag: title
#, no-c-format
msgid "Final Cluster Configuration"
msgstr "最终的集群配置文件"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs resource\n"
" Master/Slave Set: WebDataClone [WebData]\n"
"     Masters: [ pcmk-2 pcmk-1 ]\n"
" Clone Set: dlm-clone [dlm]\n"
"     Started: [ pcmk-2 pcmk-1 ]\n"
" Clone Set: ClusterIP-clone [ClusterIP] (unique)\n"
"     ClusterIP:0        (ocf::heartbeat:IPaddr2) Started\n"
"     ClusterIP:1        (ocf::heartbeat:IPaddr2) Started\n"
" Clone Set: WebFS-clone [WebFS]\n"
"     Started: [ pcmk-1 pcmk-2 ]\n"
" Clone Set: WebSite-clone [WebSite]\n"
"     Started: [ pcmk-1 pcmk-2 ]\n"
"# pcs resource rsc defaults\n"
"resource-stickiness: 100\n"
"# pcs resource op defaults\n"
"timeout: 240s\n"
"# pcs stonith\n"
" impi-fencing   (stonith:fence_ipmilan) Started\n"
"# pcs property\n"
"dc-version: 1.1.8-1.el7-60a19ed12fdb4d5c6a6b6767f52e5391e447fec0\n"
"cluster-infrastructure: corosync\n"
"no-quorum-policy: ignore\n"
"stonith-enabled: true\n"
"# pcs constraint\n"
"Location Constraints:\n"
"Ordering Constraints:\n"
"  ClusterIP-clone then WebSite-clone\n"
"  WebDataClone then WebSite-clone\n"
"  WebFS-clone then WebSite-clone\n"
"Colocation Constraints:\n"
"  WebSite-clone with ClusterIP-clone\n"
"  WebFS-clone with WebDataClone (with-rsc-role:Master)\n"
"  WebSite-clone with WebFS-clone\n"
"#\n"
"# pcs status\n"
"\n"
"Last updated: Fri Sep 14 13:45:34 2012\n"
"Last change: Fri Sep 14 13:43:13 2012 via cibadmin on pcmk-1\n"
"Stack: corosync\n"
"Current DC: pcmk-1 (1) - partition with quorum\n"
"Version: 1.1.8-1.el7-60a19ed12fdb4d5c6a6b6767f52e5391e447fec0\n"
"2 Nodes configured, unknown expected votes\n"
"11 Resources configured.\n"
"\n"
"Online: [ pcmk-1 pcmk-2 ]\n"
"\n"
"Full list of resources:\n"
"\n"
" Master/Slave Set: WebDataClone [WebData]\n"
"     Masters: [ pcmk-2 pcmk-1 ]\n"
" Clone Set: dlm-clone [dlm]\n"
"     Started: [ pcmk-1 pcmk-2 ]\n"
" Clone Set: ClusterIP-clone [ClusterIP] (unique)\n"
"     ClusterIP:0        (ocf::heartbeat:IPaddr2):       Started pcmk-1\n"
"     ClusterIP:1        (ocf::heartbeat:IPaddr2):       Started pcmk-2\n"
" Clone Set: WebFS-clone [WebFS]\n"
"     Started: [ pcmk-1 pcmk-2 ]\n"
" Clone Set: WebSite-clone [WebSite]\n"
"     Started: [ pcmk-1 pcmk-2 ]\n"
" impi-fencing   (stonith:fence_ipmilan):        Started"
msgstr ""

#. Tag: para
#, no-c-format
msgid "In xml it should look similar to this."
msgstr ""

#. Tag: programlisting
#, no-c-format
msgid ""
"&lt;cib admin_epoch=\"0\" cib-last-written=\"Fri Sep 14 13:43:13 2012\" crm_feature_set=\"3.0.6\" dc-uuid=\"1\" epoch=\"47\" have-quorum=\"1\" num_updates=\"50\" update-client=\"cibadmin\" update-origin=\"pcmk-1\" validate-with=\"pacemaker-1.2\"&gt;\n"
"  &lt;configuration&gt;\n"
"    &lt;crm_config&gt;\n"
"      &lt;cluster_property_set id=\"cib-bootstrap-options\"&gt;\n"
"        &lt;nvpair id=\"cib-bootstrap-options-dc-version\" name=\"dc-version\" value=\"1.1.8-1.el7-60a19ed12fdb4d5c6a6b6767f52e5391e447fec0\"/&gt;\n"
"        &lt;nvpair id=\"cib-bootstrap-options-cluster-infrastructure\" name=\"cluster-infrastructure\" value=\"corosync\"/&gt;\n"
"        &lt;nvpair id=\"cib-bootstrap-options-no-quorum-policy\" name=\"no-quorum-policy\" value=\"ignore\"/&gt;\n"
"        &lt;nvpair id=\"cib-bootstrap-options-stonith-enabled\" name=\"stonith-enabled\" value=\"true\"/&gt;\n"
"      &lt;/cluster_property_set&gt;\n"
"    &lt;/crm_config&gt;\n"
"    &lt;nodes&gt;\n"
"      &lt;node id=\"1\" type=\"normal\" uname=\"pcmk-1\"/&gt;\n"
"      &lt;node id=\"2\" type=\"normal\" uname=\"pcmk-2\"/&gt;\n"
"    &lt;/nodes&gt;\n"
"    &lt;resources&gt;\n"
"      &lt;master id=\"WebDataClone\"&gt;\n"
"        &lt;primitive class=\"ocf\" id=\"WebData\" provider=\"linbit\" type=\"drbd\"&gt;\n"
"          &lt;instance_attributes id=\"WebData-instance_attributes\"&gt;\n"
"            &lt;nvpair id=\"WebData-instance_attributes-drbd_resource\" name=\"drbd_resource\" value=\"wwwdata\"/&gt;\n"
"          &lt;/instance_attributes&gt;\n"
"          &lt;operations&gt;\n"
"            &lt;op id=\"WebData-interval-60s\" interval=\"60s\" name=\"monitor\"/&gt;\n"
"          &lt;/operations&gt;\n"
"        &lt;/primitive&gt;\n"
"        &lt;meta_attributes id=\"WebDataClone-meta_attributes\"&gt;\n"
"          &lt;nvpair id=\"WebDataClone-meta_attributes-master-node-max\" name=\"master-node-max\" value=\"1\"/&gt;\n"
"          &lt;nvpair id=\"WebDataClone-meta_attributes-clone-max\" name=\"clone-max\" value=\"2\"/&gt;\n"
"          &lt;nvpair id=\"WebDataClone-meta_attributes-clone-node-max\" name=\"clone-node-max\" value=\"1\"/&gt;\n"
"          &lt;nvpair id=\"WebDataClone-meta_attributes-notify\" name=\"notify\" value=\"true\"/&gt;\n"
"          &lt;nvpair id=\"WebDataClone-meta_attributes-master-max\" name=\"master-max\" value=\"2\"/&gt;\n"
"        &lt;/meta_attributes&gt;\n"
"      &lt;/master&gt;\n"
"      &lt;clone id=\"dlm-clone\"&gt;\n"
"        &lt;primitive class=\"ocf\" id=\"dlm\" provider=\"pacemaker\" type=\"controld\"&gt;\n"
"          &lt;instance_attributes id=\"dlm-instance_attributes\"/&gt;\n"
"          &lt;operations&gt;\n"
"            &lt;op id=\"dlm-interval-60s\" interval=\"60s\" name=\"monitor\"/&gt;\n"
"          &lt;/operations&gt;\n"
"        &lt;/primitive&gt;\n"
"        &lt;meta_attributes id=\"dlm-clone-meta\"&gt;\n"
"          &lt;nvpair id=\"dlm-clone-max\" name=\"clone-max\" value=\"2\"/&gt;\n"
"          &lt;nvpair id=\"dlm-clone-node-max\" name=\"clone-node-max\" value=\"1\"/&gt;\n"
"        &lt;/meta_attributes&gt;\n"
"      &lt;/clone&gt;\n"
"      &lt;clone id=\"ClusterIP-clone\"&gt;\n"
"        &lt;primitive class=\"ocf\" id=\"ClusterIP\" provider=\"heartbeat\" type=\"IPaddr2\"&gt;\n"
"          &lt;instance_attributes id=\"ClusterIP-instance_attributes\"&gt;\n"
"            &lt;nvpair id=\"ClusterIP-instance_attributes-ip\" name=\"ip\" value=\"192.168.0.120\"/&gt;\n"
"            &lt;nvpair id=\"ClusterIP-instance_attributes-cidr_netmask\" name=\"cidr_netmask\" value=\"32\"/&gt;\n"
"            &lt;nvpair id=\"ClusterIP-instance_attributes-clusterip_hash\" name=\"clusterip_hash\" value=\"sourceip\"/&gt;\n"
"          &lt;/instance_attributes&gt;\n"
"          &lt;operations&gt;\n"
"            &lt;op id=\"ClusterIP-interval-30s\" interval=\"30s\" name=\"monitor\"/&gt;\n"
"          &lt;/operations&gt;\n"
"        &lt;/primitive&gt;\n"
"        &lt;meta_attributes id=\"ClusterIP-clone-meta\"&gt;\n"
"          &lt;nvpair id=\"ClusterIP-globally-unique\" name=\"globally-unique\" value=\"true\"/&gt;\n"
"          &lt;nvpair id=\"ClusterIP-clone-max\" name=\"clone-max\" value=\"2\"/&gt;\n"
"          &lt;nvpair id=\"ClusterIP-clone-node-max\" name=\"clone-node-max\" value=\"2\"/&gt;\n"
"        &lt;/meta_attributes&gt;\n"
"      &lt;/clone&gt;\n"
"      &lt;clone id=\"WebFS-clone\"&gt;\n"
"        &lt;primitive class=\"ocf\" id=\"WebFS\" provider=\"heartbeat\" type=\"Filesystem\"&gt;\n"
"          &lt;instance_attributes id=\"WebFS-instance_attributes\"&gt;\n"
"            &lt;nvpair id=\"WebFS-instance_attributes-device\" name=\"device\" value=\"/dev/drbd/by-res/wwwdata\"/&gt;\n"
"            &lt;nvpair id=\"WebFS-instance_attributes-directory\" name=\"directory\" value=\"/var/www/html\"/&gt;\n"
"            &lt;nvpair id=\"WebFS-instance_attributes-fstype\" name=\"fstype\" value=\"gfs2\"/&gt;\n"
"          &lt;/instance_attributes&gt;\n"
"          &lt;meta_attributes id=\"WebFS-meta_attributes\"/&gt;\n"
"        &lt;/primitive&gt;\n"
"        &lt;meta_attributes id=\"WebFS-clone-meta\"/&gt;\n"
"      &lt;/clone&gt;\n"
"      &lt;clone id=\"WebSite-clone\"&gt;\n"
"        &lt;primitive class=\"ocf\" id=\"WebSite\" provider=\"heartbeat\" type=\"apache\"&gt;\n"
"          &lt;instance_attributes id=\"WebSite-instance_attributes\"&gt;\n"
"            &lt;nvpair id=\"WebSite-instance_attributes-configfile\" name=\"configfile\" value=\"/etc/httpd/conf/httpd.conf\"/&gt;\n"
"            &lt;nvpair id=\"WebSite-instance_attributes-statusurl\" name=\"statusurl\" value=\"http://localhost/server-status\"/&gt;\n"
"          &lt;/instance_attributes&gt;\n"
"          &lt;operations&gt;\n"
"            &lt;op id=\"WebSite-interval-1min\" interval=\"1min\" name=\"monitor\"/&gt;\n"
"          &lt;/operations&gt;\n"
"        &lt;/primitive&gt;\n"
"        &lt;meta_attributes id=\"WebSite-clone-meta\"/&gt;\n"
"      &lt;/clone&gt;\n"
"      &lt;primitive class=\"stonith\" id=\"impi-fencing\" type=\"fence_ipmilan\"&gt;\n"
"        &lt;instance_attributes id=\"impi-fencing-instance_attributes\"&gt;\n"
"          &lt;nvpair id=\"impi-fencing-instance_attributes-pcmk_host_list\" name=\"pcmk_host_list\" value=\"pcmk-1 pcmk-2\"/&gt;\n"
"          &lt;nvpair id=\"impi-fencing-instance_attributes-ipaddr\" name=\"ipaddr\" value=\"10.0.0.1\"/&gt;\n"
"          &lt;nvpair id=\"impi-fencing-instance_attributes-login\" name=\"login\" value=\"testuser\"/&gt;\n"
"          &lt;nvpair id=\"impi-fencing-instance_attributes-passwd\" name=\"passwd\" value=\"acd123\"/&gt;\n"
"        &lt;/instance_attributes&gt;\n"
"        &lt;operations&gt;\n"
"          &lt;op id=\"impi-fencing-interval-60s\" interval=\"60s\" name=\"monitor\"/&gt;\n"
"        &lt;/operations&gt;\n"
"      &lt;/primitive&gt;\n"
"    &lt;/resources&gt;\n"
"    &lt;constraints&gt;\n"
"      &lt;rsc_colocation id=\"colocation-WebSite-ClusterIP-INFINITY\" rsc=\"WebSite-clone\" score=\"INFINITY\" with-rsc=\"ClusterIP-clone\"/&gt;\n"
"      &lt;rsc_order first=\"ClusterIP-clone\" first-action=\"start\" id=\"order-ClusterIP-WebSite-mandatory\" then=\"WebSite-clone\" then-action=\"start\"/&gt;\n"
"      &lt;rsc_colocation id=\"colocation-WebFS-WebDataClone-INFINITY\" rsc=\"WebFS-clone\" score=\"INFINITY\" with-rsc=\"WebDataClone\" with-rsc-role=\"Master\"/&gt;\n"
"      &lt;rsc_colocation id=\"colocation-WebSite-WebFS-INFINITY\" rsc=\"WebSite-clone\" score=\"INFINITY\" with-rsc=\"WebFS-clone\"/&gt;\n"
"      &lt;rsc_order first=\"WebFS-clone\" id=\"order-WebFS-WebSite-mandatory\" then=\"WebSite-clone\"/&gt;\n"
"      &lt;rsc_order first=\"WebDataClone\" first-action=\"promote\" id=\"order-WebDataClone-WebFS-mandatory\" then=\"WebFS-clone\" then-action=\"start\"/&gt;\n"
"    &lt;/constraints&gt;\n"
"    &lt;rsc_defaults&gt;\n"
"      &lt;meta_attributes id=\"rsc_defaults-options\"&gt;\n"
"        &lt;nvpair id=\"rsc_defaults-options-resource-stickiness\" name=\"resource-stickiness\" value=\"100\"/&gt;\n"
"      &lt;/meta_attributes&gt;\n"
"    &lt;/rsc_defaults&gt;\n"
"    &lt;op_defaults&gt;\n"
"      &lt;meta_attributes id=\"op_defaults-options\"&gt;\n"
"        &lt;nvpair id=\"op_defaults-options-timeout\" name=\"timeout\" value=\"240s\"/&gt;\n"
"      &lt;/meta_attributes&gt;\n"
"    &lt;/op_defaults&gt;\n"
"  &lt;/configuration&gt;\n"
"&lt;/cib&gt;"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Node List"
msgstr "节点列表"

#. Tag: para
#, no-c-format
msgid "The list of cluster nodes is automatically populated by the cluster."
msgstr "这个列表中的集群节点是集群自动添加的。"

#. Tag: literallayout
#, no-c-format
msgid ""
"Pacemaker Nodes:\n"
" Online: [ pcmk-1 pcmk-2  ]"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Cluster Options"
msgstr "集群选项"

#. Tag: para
#, no-c-format
msgid "This is where the cluster automatically stores some information about the cluster"
msgstr "这是集群自动存储集群信息的地方"

#. Tag: para
#, no-c-format
msgid "dc-version - the version (including upstream source-code hash) of Pacemaker used on the DC"
msgstr "dc-version - DC使用的Pacemaker的版本(包括源代码的hash)"

#. Tag: para
#, no-c-format
msgid "cluster-infrastructure - the cluster infrastructure being used (heartbeat or openais)"
msgstr "集群-基层 - 集群使用的基层软件 (heartbeat or openais/corosync)"

#. Tag: para
#, no-c-format
msgid "expected-quorum-votes - the maximum number of nodes expected to be part of the cluster"
msgstr "expected-quorum-votes - 预期的集群最大成员数"

#. Tag: para
#, no-c-format
msgid "and where the admin can set options that control the way the cluster operates"
msgstr "以及管理员设置集群操作的方法选项"

#. Tag: para
#, no-c-format
msgid "stonith-enabled=true - Make use of STONITH"
msgstr "stonith-enabled=true - 使用STONITH"

#. Tag: para
#, no-c-format
msgid "no-quorum-policy=ignore - Ignore loss of quorum and continue to host resources."
msgstr "no-quorum-policy=ignore - 忽略达不到法定人数的情况，继续运行资源"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs property\n"
"dc-version: 1.1.8-1.el7-60a19ed12fdb4d5c6a6b6767f52e5391e447fec0\n"
"cluster-infrastructure: corosync\n"
"no-quorum-policy: ignore\n"
"stonith-enabled: true"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Resources"
msgstr "资源"

#. Tag: title
#, no-c-format
msgid "Default Options"
msgstr "默认选项"

#. Tag: para
#, no-c-format
msgid "Here we configure cluster options that apply to every resource."
msgstr "这里我们设置所有资源共用的集群选项"

#. Tag: para
#, no-c-format
msgid "resource-stickiness - Specify the aversion to moving resources to other machines"
msgstr "resource-stickiness - 资源粘稠值"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs resource rsc defaults\n"
"resource-stickiness: 100"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Fencing"
msgstr "隔离"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs stonith show\n"
" impi-fencing   (stonith:fence_ipmilan) Started\n"
"# pcs stonith show impi-fencing\n"
"Resource: impi-fencing\n"
"  pcmk_host_list: pcmk-1 pcmk-2\n"
"  ipaddr: 10.0.0.1\n"
"  login: testuser\n"
"  passwd: acd123"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Service Address"
msgstr "服务地址"

#. Tag: para
#, fuzzy, no-c-format
msgid "Users of the services provided by the cluster require an unchanging address with which to access it. Additionally, we cloned the address so it will be active on both nodes. An iptables rule (created as part of the resource agent) is used to ensure that each request only gets processed by one of the two clone instances. The additional meta options tell the cluster that we want two instances of the clone (one \"request bucket\" for each node) and that if one node fails, then the remaining node should hold both."
msgstr "用户需要一个不变的地址来访问集群所提供的服务。此外，我们clone了地址，以便在两个节点上都使用这个IP。一个iptables规则（resource agent的一部分）是用来确保每个请求只能由两个节点中的某一个处理。这些额外的集群选项告诉我们想要两个clone（每个节点一个“请求桶”）实例，如果一个节点失效，那么剩下的节点处理这两个请求桶。"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs resource show ClusterIP-clone\n"
"Resource: ClusterIP-clone\n"
"  ip: 192.168.0.120\n"
"  cidr_netmask: 32\n"
"  clusterip_hash: sourceip\n"
"  globally-unique: true\n"
"  clone-max: 2\n"
"  clone-node-max: 2\n"
"  op monitor interval=30s"
msgstr ""

#. Tag: para
#, no-c-format
msgid "TODO: The RA should check for globally-unique=true when cloned"
msgstr "TODO: The RA should check for globally-unique=true when cloned"

#. Tag: title
#, no-c-format
msgid "DRBD - Shared Storage"
msgstr "DRBD - 共享存储"

#. Tag: para
#, no-c-format
msgid "Here we define the DRBD service and specify which DRBD resource (from drbd.conf) it should manage. We make it a master/slave resource and, in order to have an active/active setup, allow both instances to be promoted by specifying master-max=2. We also set the notify option so that the cluster will tell DRBD agent when it’s peer changes state."
msgstr "在这里，我们定义了DRBD技术服务，并指定DRBD应该管理的资源（从drbd.conf）。我们让它作为主/从资源，并且为了active/active，用设置master-max=2来允许两者都晋升为master。我们还可以设置通知选项，这样，当时集群的节点的状态发生改变时，该集群将告诉DRBD的agent。 "

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs resource show WebDataClone\n"
"Resource: WebDataClone\n"
"  drbd_resource: wwwdata\n"
"  master-node-max: 1\n"
"  clone-max: 2\n"
"  clone-node-max: 1\n"
"  notify: true\n"
"  master-max: 2\n"
"  op monitor interval=60s\n"
"# pcs constraint ref WebDataClone\n"
"Resource: WebDataClone\n"
"  colocation-WebFS-WebDataClone-INFINITY\n"
"  order-WebDataClone-WebFS-mandatory"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Cluster Filesystem"
msgstr "集群文件系统"

#. Tag: para
#, no-c-format
msgid "The cluster filesystem ensures that files are read and written correctly. We need to specify the block device (provided by DRBD), where we want it mounted and that we are using GFS2. Again it is a clone because it is intended to be active on both nodes. The additional constraints ensure that it can only be started on nodes with active gfs-control and drbd instances."
msgstr "群集文件系统可确保文件读写正确。我们需要指定我们想挂载并使用GFS2的块设备（由DRBD提供）。这又是一个clone，因为它的目的是在两个节点上都可用。这些额外的限制确保它只在有gfs-control和drbd 实例的节点上运行。"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs resource show WebFS-clone\n"
"Resource: WebFS-clone\n"
"  device: /dev/drbd/by-res/wwwdata\n"
"  directory: /var/www/html\n"
"  fstype: gfs2\n"
"# pcs constraint ref WebFS-clone\n"
"Resource: WebFS-clone\n"
"  colocation-WebFS-WebDataClone-INFINITY\n"
"  colocation-WebSite-WebFS-INFINITY\n"
"  order-WebFS-WebSite-mandatory\n"
"  order-WebDataClone-WebFS-mandatory"
msgstr ""

#. Tag: title
#, no-c-format
msgid "Apache"
msgstr "Apache"

#. Tag: para
#, no-c-format
msgid "Lastly we have the actual service, Apache. We need only tell the cluster where to find it’s main configuration file and restrict it to running on nodes that have the required filesystem mounted and the IP address active."
msgstr "最后我们有了真正的服务，Apache，我们只需要告诉集群在哪里可以找到它的主配置文件，并限制其只在挂载了文件系统和有可用IP节点上运行"

#. Tag: programlisting
#, no-c-format
msgid ""
"# pcs resource show WebSite-clone\n"
"Resource: WebSite-clone\n"
"  configfile: /etc/httpd/conf/httpd.conf\n"
"  statusurl: http://localhost/server-status\n"
"  master-max: 2\n"
"  op monitor interval=1min\n"
"# pcs constraint ref WebSite-clone\n"
"Resource: WebSite-clone\n"
"  colocation-WebSite-ClusterIP-INFINITY\n"
"  colocation-WebSite-WebFS-INFINITY\n"
"  order-ClusterIP-WebSite-mandatory\n"
"  order-WebFS-WebSite-mandatory"
msgstr ""

#~ msgid ""
#~ "\n"
#~ "[root@pcmk-1 ~]# crm configure show\n"
#~ "node pcmk-1\n"
#~ "node pcmk-2\n"
#~ "primitive WebData ocf:linbit:drbd \\\n"
#~ "        params drbd_resource=\"wwwdata\" \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "primitive WebFS ocf:heartbeat:Filesystem \\\n"
#~ "        params device=\"/dev/drbd/by-res/wwwdata\" directory=\"/var/www/html\" fstype=”gfs2”\n"
#~ "primitive WebSite ocf:heartbeat:apache \\\n"
#~ "        params configfile=\"/etc/httpd/conf/httpd.conf\" \\\n"
#~ "        op monitor interval=\"1min\"\n"
#~ "primitive ClusterIP ocf:heartbeat:IPaddr2 \\\n"
#~ "        params ip=”192.168.122.101” cidr_netmask=”32” clusterip_hash=”sourceip” \\\n"
#~ "        op monitor interval=\"30s\"\n"
#~ "primitive dlm ocf:pacemaker:controld \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "primitive gfs-control ocf:pacemaker:controld \\\n"
#~ "   params daemon=”gfs_controld.pcmk” args=”-g 0” \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "primitive rsa-fencing stonith::external/ibmrsa \\\n"
#~ "        params hostname=”pcmk-1 pcmk-2\" ipaddr=192.168.122.31 userid=mgmt passwd=abc123 type=ibm \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "ms WebDataClone WebData \\\n"
#~ "        meta master-max=\"2\" master-node-max=\"1\" clone-max=\"2\" clone-node-max=\"1\" notify=\"true\"\n"
#~ "clone Fencing rsa-fencing \n"
#~ "clone WebFSClone WebFS\n"
#~ "clone WebIP ClusterIP  \\\n"
#~ "        meta globally-unique=”true” clone-max=”2” clone-node-max=”2”\n"
#~ "clone WebSiteClone WebSite\n"
#~ "clone dlm-clone dlm \\\n"
#~ "        meta interleave=\"true\"\n"
#~ "clone gfs-clone gfs-control \\\n"
#~ "        meta interleave=\"true\"\n"
#~ "colocation WebFS-with-gfs-control inf: WebFSClone gfs-clone\n"
#~ "colocation WebSite-with-WebFS inf: WebSiteClone WebFSClone\n"
#~ "colocation fs_on_drbd inf: WebFSClone WebDataClone:Master\n"
#~ "colocation gfs-with-dlm inf: gfs-clone dlm-clone\n"
#~ "colocation website-with-ip inf: WebSiteClone WebIP\n"
#~ "order WebFS-after-WebData inf: WebDataClone:promote WebFSClone:start\n"
#~ "order WebSite-after-WebFS inf: WebFSClone WebSiteClone\n"
#~ "order apache-after-ip inf: WebIP WebSiteClone\n"
#~ "order start-WebFS-after-gfs-control inf: gfs-clone WebFSClone\n"
#~ "order start-gfs-after-dlm inf: dlm-clone gfs-clone\n"
#~ "property $id=\"cib-bootstrap-options\" \\\n"
#~ "        dc-version=\"1.0.5-462f1569a43740667daf7b0f6b521742e9eb8fa7\" \\\n"
#~ "        cluster-infrastructure=\"openais\" \\\n"
#~ "        expected-quorum-votes=”2” \\\n"
#~ "        stonith-enabled=”true” \\\n"
#~ "        no-quorum-policy=\"ignore\"\n"
#~ "rsc_defaults $id=\"rsc-options\" \\\n"
#~ "        resource-stickiness=”100”\n"
#~ msgstr ""
#~ "\n"
#~ "[root@pcmk-1 ~]# crm configure show\n"
#~ "node pcmk-1\n"
#~ "node pcmk-2\n"
#~ "primitive WebData ocf:linbit:drbd \\\n"
#~ "        params drbd_resource=\"wwwdata\" \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "primitive WebFS ocf:heartbeat:Filesystem \\\n"
#~ "        params device=\"/dev/drbd/by-res/wwwdata\" directory=\"/var/www/html\" fstype=”gfs2”\n"
#~ "primitive WebSite ocf:heartbeat:apache \\\n"
#~ "        params configfile=\"/etc/httpd/conf/httpd.conf\" \\\n"
#~ "        op monitor interval=\"1min\"\n"
#~ "primitive ClusterIP ocf:heartbeat:IPaddr2 \\\n"
#~ "        params ip=”192.168.122.101” cidr_netmask=”32” clusterip_hash=”sourceip” \\\n"
#~ "        op monitor interval=\"30s\"\n"
#~ "primitive dlm ocf:pacemaker:controld \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "primitive gfs-control ocf:pacemaker:controld \\\n"
#~ "   params daemon=”gfs_controld.pcmk” args=”-g 0” \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "primitive rsa-fencing stonith::external/ibmrsa \\\n"
#~ "        params hostname=”pcmk-1 pcmk-2\" ipaddr=192.168.122.31 userid=mgmt passwd=abc123 type=ibm \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "ms WebDataClone WebData \\\n"
#~ "        meta master-max=\"2\" master-node-max=\"1\" clone-max=\"2\" clone-node-max=\"1\" notify=\"true\"\n"
#~ "clone Fencing rsa-fencing \n"
#~ "clone WebFSClone WebFS\n"
#~ "clone WebIP ClusterIP  \\\n"
#~ "        meta globally-unique=”true” clone-max=”2” clone-node-max=”2”\n"
#~ "clone WebSiteClone WebSite\n"
#~ "clone dlm-clone dlm \\\n"
#~ "        meta interleave=\"true\"\n"
#~ "clone gfs-clone gfs-control \\\n"
#~ "        meta interleave=\"true\"\n"
#~ "colocation WebFS-with-gfs-control inf: WebFSClone gfs-clone\n"
#~ "colocation WebSite-with-WebFS inf: WebSiteClone WebFSClone\n"
#~ "colocation fs_on_drbd inf: WebFSClone WebDataClone:Master\n"
#~ "colocation gfs-with-dlm inf: gfs-clone dlm-clone\n"
#~ "colocation website-with-ip inf: WebSiteClone WebIP\n"
#~ "order WebFS-after-WebData inf: WebDataClone:promote WebFSClone:start\n"
#~ "order WebSite-after-WebFS inf: WebFSClone WebSiteClone\n"
#~ "order apache-after-ip inf: WebIP WebSiteClone\n"
#~ "order start-WebFS-after-gfs-control inf: gfs-clone WebFSClone\n"
#~ "order start-gfs-after-dlm inf: dlm-clone gfs-clone\n"
#~ "property $id=\"cib-bootstrap-options\" \\\n"
#~ "        dc-version=\"1.0.5-462f1569a43740667daf7b0f6b521742e9eb8fa7\" \\\n"
#~ "        cluster-infrastructure=\"openais\" \\\n"
#~ "        expected-quorum-votes=”2” \\\n"
#~ "        stonith-enabled=”true” \\\n"
#~ "        no-quorum-policy=\"ignore\"\n"
#~ "rsc_defaults $id=\"rsc-options\" \\\n"
#~ "        resource-stickiness=”100”\n"

#~ msgid ""
#~ "\n"
#~ "node pcmk-1\n"
#~ "node pcmk-2\n"
#~ msgstr ""
#~ "\n"
#~ "node pcmk-1\n"
#~ "node pcmk-2\n"

#~ msgid ""
#~ "\n"
#~ "property $id=\"cib-bootstrap-options\" \\\n"
#~ "        dc-version=\"1.0.5-462f1569a43740667daf7b0f6b521742e9eb8fa7\" \\\n"
#~ "        cluster-infrastructure=\"openais\" \\\n"
#~ "        expected-quorum-votes=”2” \\\n"
#~ "        stonith-enabled=”true” \\\n"
#~ "        no-quorum-policy=\"ignore\"\n"
#~ msgstr ""
#~ "\n"
#~ "property $id=\"cib-bootstrap-options\" \\\n"
#~ "        dc-version=\"1.0.5-462f1569a43740667daf7b0f6b521742e9eb8fa7\" \\\n"
#~ "        cluster-infrastructure=\"openais\" \\\n"
#~ "        expected-quorum-votes=”2” \\\n"
#~ "        stonith-enabled=”true” \\\n"
#~ "        no-quorum-policy=\"ignore\"\n"

#~ msgid ""
#~ "\n"
#~ "rsc_defaults $id=\"rsc-options\" \\\n"
#~ "        resource-stickiness=”100”\n"
#~ msgstr ""
#~ "\n"
#~ "rsc_defaults $id=\"rsc-options\" \\\n"
#~ "        resource-stickiness=”100”\n"

#~ msgid "TODO: Add text here"
#~ msgstr "TODO: Add text here"

#~ msgid ""
#~ "\n"
#~ "primitive rsa-fencing stonith::external/ibmrsa \\\n"
#~ "        params hostname=”pcmk-1 pcmk-2\" ipaddr=192.168.122.31 userid=mgmt passwd=abc123 type=ibm \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "clone Fencing rsa-fencing\n"
#~ msgstr ""
#~ "\n"
#~ "primitive rsa-fencing stonith::external/ibmrsa \\\n"
#~ "        params hostname=”pcmk-1 pcmk-2\" ipaddr=192.168.122.31 userid=mgmt passwd=abc123 type=ibm \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "clone Fencing rsa-fencing\n"

#~ msgid ""
#~ "\n"
#~ "primitive ClusterIP ocf:heartbeat:IPaddr2 \\\n"
#~ "        params ip=”192.168.122.101” cidr_netmask=”32” clusterip_hash=”sourceip” \\\n"
#~ "        op monitor interval=\"30s\"\n"
#~ "clone WebIP ClusterIP  \n"
#~ "        meta globally-unique=”true” clone-max=”2” clone-node-max=”2”\n"
#~ msgstr ""
#~ "\n"
#~ "primitive ClusterIP ocf:heartbeat:IPaddr2 \\\n"
#~ "        params ip=”192.168.122.101” cidr_netmask=”32” clusterip_hash=”sourceip” \\\n"
#~ "        op monitor interval=\"30s\"\n"
#~ "clone WebIP ClusterIP  \n"
#~ "        meta globally-unique=”true” clone-max=”2” clone-node-max=”2”\n"

#~ msgid "Distributed lock manager"
#~ msgstr "分布式锁控制器"

#~ msgid "Cluster filesystems like GFS2 require a lock manager. This service starts the daemon that provides user-space applications (such as the GFS2 daemon) with access to the in-kernel lock manager. Since we need it to be available on all nodes in the cluster, we have it cloned."
#~ msgstr "像GFS2集群文件系统需要一个锁管理。该服务启动守护进程，提供了访问内核中的锁管理器的用户空间应用程序（如GFS2守护进程）。因为我们需要它在集群中的所有可用节点中运行，我们把它clone。"

#~ msgid ""
#~ "\n"
#~ "primitive dlm ocf:pacemaker:controld \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "clone dlm-clone dlm \\\n"
#~ "        meta interleave=\"true\n"
#~ msgstr ""
#~ "\n"
#~ "primitive dlm ocf:pacemaker:controld \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "clone dlm-clone dlm \\\n"
#~ "        meta interleave=\"true\n"

#~ msgid "TODO: Confirm <literal>interleave</literal> is no longer needed"
#~ msgstr "TODO: Confirm <literal>interleave</literal> is no longer needed"

#~ msgid "GFS control daemon"
#~ msgstr "GFS 控制守护进程"

#~ msgid "GFS2 also needs a user-space/kernel bridge that runs on every node. So here we have another clone, however this time we must also specify that it can only run on machines that are also running the DLM (colocation constraint) and that it can only be started after the DLM is running (order constraint). Additionally, the gfs-control clone should only care about the DLM instances it is paired with, so we need to set the interleave option."
#~ msgstr "GFS2还需要一个user-space到kernel的桥梁，每个节点上要运行。所以在这里我们还有一个clone，但是这一次我们还必须指定它只能运行在有DLM的机器上（colocation 约束），它只能在DLM后启动 （order约束）。此外，gfs-control clone应该只关系与其配对的DLM实例，所以我们还要设置interleave 选项"

#~ msgid ""
#~ "\n"
#~ "primitive gfs-control ocf:pacemaker:controld \\\n"
#~ "   params daemon=”gfs_controld.pcmk” args=”-g 0” \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "clone gfs-clone gfs-control \\\n"
#~ "        meta interleave=\"true\"\n"
#~ "colocation gfs-with-dlm inf: gfs-clone dlm-clone\n"
#~ "order start-gfs-after-dlm inf: dlm-clone gfs-clone\n"
#~ msgstr ""
#~ "\n"
#~ "primitive gfs-control ocf:pacemaker:controld \\\n"
#~ "   params daemon=”gfs_controld.pcmk” args=”-g 0” \\\n"
#~ "        op monitor interval=\"120s\"\n"
#~ "clone gfs-clone gfs-control \\\n"
#~ "        meta interleave=\"true\"\n"
#~ "colocation gfs-with-dlm inf: gfs-clone dlm-clone\n"
#~ "order start-gfs-after-dlm inf: dlm-clone gfs-clone\n"

#~ msgid ""
#~ "\n"
#~ "primitive WebData ocf:linbit:drbd \\\n"
#~ "        params drbd_resource=\"wwwdata\" \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "ms WebDataClone WebData \\\n"
#~ "        meta master-max=\"2\" master-node-max=\"1\" clone-max=\"2\" clone-node-max=\"1\" notify=\"true\"\n"
#~ msgstr ""
#~ "\n"
#~ "primitive WebData ocf:linbit:drbd \\\n"
#~ "        params drbd_resource=\"wwwdata\" \\\n"
#~ "        op monitor interval=\"60s\"\n"
#~ "ms WebDataClone WebData \\\n"
#~ "        meta master-max=\"2\" master-node-max=\"1\" clone-max=\"2\" clone-node-max=\"1\" notify=\"true\"\n"

#~ msgid ""
#~ "\n"
#~ "primitive WebFS ocf:heartbeat:Filesystem \\\n"
#~ "        params device=\"/dev/drbd/by-res/wwwdata\" directory=\"/var/www/html\" fstype=”gfs2”\n"
#~ "clone WebFSClone WebFS\n"
#~ "colocation WebFS-with-gfs-control inf: WebFSClone gfs-clone\n"
#~ "colocation fs_on_drbd inf: WebFSClone WebDataClone:Master\n"
#~ "order WebFS-after-WebData inf: WebDataClone:promote WebFSClone:start\n"
#~ "order start-WebFS-after-gfs-control inf: gfs-clone WebFSClone\n"
#~ msgstr ""
#~ "\n"
#~ "primitive WebFS ocf:heartbeat:Filesystem \\\n"
#~ "        params device=\"/dev/drbd/by-res/wwwdata\" directory=\"/var/www/html\" fstype=”gfs2”\n"
#~ "clone WebFSClone WebFS\n"
#~ "colocation WebFS-with-gfs-control inf: WebFSClone gfs-clone\n"
#~ "colocation fs_on_drbd inf: WebFSClone WebDataClone:Master\n"
#~ "order WebFS-after-WebData inf: WebDataClone:promote WebFSClone:start\n"
#~ "order start-WebFS-after-gfs-control inf: gfs-clone WebFSClone\n"

#~ msgid ""
#~ "\n"
#~ "primitive WebSite ocf:heartbeat:apache \\\n"
#~ "        params configfile=\"/etc/httpd/conf/httpd.conf\" \\\n"
#~ "        op monitor interval=\"1min\"\n"
#~ "clone WebSiteClone WebSite\n"
#~ "colocation WebSite-with-WebFS inf: WebSiteClone WebFSClone\n"
#~ "colocation website-with-ip inf: WebSiteClone WebIP\n"
#~ "order apache-after-ip inf: WebIP WebSiteClone\n"
#~ "order WebSite-after-WebFS inf: WebFSClone WebSiteClone\n"
#~ msgstr ""
#~ "\n"
#~ "primitive WebSite ocf:heartbeat:apache \\\n"
#~ "        params configfile=\"/etc/httpd/conf/httpd.conf\" \\\n"
#~ "        op monitor interval=\"1min\"\n"
#~ "clone WebSiteClone WebSite\n"
#~ "colocation WebSite-with-WebFS inf: WebSiteClone WebFSClone\n"
#~ "colocation website-with-ip inf: WebSiteClone WebIP\n"
#~ "order apache-after-ip inf: WebIP WebSiteClone\n"
#~ "order WebSite-after-WebFS inf: WebFSClone WebSiteClone\n"
