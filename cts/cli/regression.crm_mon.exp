=#=#=#= Begin test: Basic output =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
    * Unpromoted: [ cluster01 ]
=#=#=#= End test: Basic output - OK (0) =#=#=#=
* Passed: crm_mon               - Basic output
=#=#=#= Begin test: Basic output (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <group id="exim-group" number_resources="2" maintenance="false" managed="true" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Basic output (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Basic output (XML)
=#=#=#= Begin test: Output without node section =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
    * Unpromoted: [ cluster01 ]
=#=#=#= End test: Output without node section - OK (0) =#=#=#=
* Passed: crm_mon               - Output without node section
=#=#=#= Begin test: Output without node section (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --exclude=nodes">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <group id="exim-group" number_resources="2" maintenance="false" managed="true" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output without node section (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output without node section (XML)
=#=#=#= Begin test: Output with only the node section =#=#=#=
Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]
=#=#=#= End test: Output with only the node section - OK (0) =#=#=#=
* Passed: crm_mon               - Output with only the node section
=#=#=#= Begin test: Complete text output =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
    * Unpromoted: [ cluster01 ]

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
    * dummy: migration-threshold=1000000:
      * (18) start
      * (19) monitor: interval="60000ms"
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (4) monitor: interval="10000ms"
      * (5) cancel: interval="10000ms"
      * (6) promote
      * (7) monitor: interval="5000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * dummy: migration-threshold=1000000:
      * (16) stop
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (2) start
      * (4) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1:
    * httpd: migration-threshold=1000000:
      * (1) start

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01
=#=#=#= End test: Complete text output - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output
=#=#=#= Begin test: Complete text output with detail =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster02
    * ping	(ocf:pacemaker:ping):	 Started cluster01
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd-bundle-ip-192.168.122.131	(ocf:heartbeat:IPaddr2):	 Started cluster01
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-0
      * httpd-bundle-docker-0	(ocf:heartbeat:docker):	 Started cluster01
      * httpd-bundle-0	(ocf:pacemaker:remote):	 Started cluster01
    * Replica[1]
      * httpd-bundle-ip-192.168.122.132	(ocf:heartbeat:IPaddr2):	 Started cluster02
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-1
      * httpd-bundle-docker-1	(ocf:heartbeat:docker):	 Started cluster02
      * httpd-bundle-1	(ocf:pacemaker:remote):	 Started cluster02
    * Replica[2]
      * httpd-bundle-ip-192.168.122.133	(ocf:heartbeat:IPaddr2):	 Stopped
      * httpd	(ocf:heartbeat:apache):	 Stopped
      * httpd-bundle-docker-2	(ocf:heartbeat:docker):	 Stopped
      * httpd-bundle-2	(ocf:pacemaker:remote):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:0:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02
    * Resource Group: mysql-group:1:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Promoted cluster02 (test_description)
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Unpromoted cluster01 (test_description)
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Stopped (test_description)
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Stopped (test_description)
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Stopped (test_description)

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
    * dummy: migration-threshold=1000000:
      * (18) start
      * (19) monitor: interval="60000ms"
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (4) monitor: interval="10000ms"
      * (5) cancel: interval="10000ms"
      * (6) promote
      * (7) monitor: interval="5000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: cluster01 (1):
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * dummy: migration-threshold=1000000:
      * (16) stop
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (2) start
      * (4) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0@cluster01:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1@cluster02:
    * httpd: migration-threshold=1000000:
      * (1) start

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01 (1)
=#=#=#= End test: Complete text output with detail - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output with detail
=#=#=#= Begin test: Complete brief text output =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * 1	(ocf:pacemaker:Dummy):	Active cluster02
  * 1	(stonith:fence_xvm):	Active cluster01
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * 1/1	(lsb:exim):	Active cluster02
    * 1/1	(ocf:heartbeat:IPaddr):	Active cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
    * Unpromoted: [ cluster01 ]

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
    * dummy: migration-threshold=1000000:
      * (18) start
      * (19) monitor: interval="60000ms"
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (4) monitor: interval="10000ms"
      * (5) cancel: interval="10000ms"
      * (6) promote
      * (7) monitor: interval="5000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * dummy: migration-threshold=1000000:
      * (16) stop
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (2) start
      * (4) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1:
    * httpd: migration-threshold=1000000:
      * (1) start

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01
=#=#=#= End test: Complete brief text output - OK (0) =#=#=#=
* Passed: crm_mon               - Complete brief text output
=#=#=#= Begin test: Complete text output grouped by node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01: online:
    * Resources:
      * ping	(ocf:pacemaker:ping):	 Started
      * Fencing	(stonith:fence_xvm):	 Started
      * mysql-proxy	(lsb:mysql-proxy):	 Started
      * promotable-rsc	(ocf:pacemaker:Stateful):	 Unpromoted (test_description)
      * httpd-bundle-ip-192.168.122.131	(ocf:heartbeat:IPaddr2):	 Started
      * httpd-bundle-docker-0	(ocf:heartbeat:docker):	 Started
  * Node cluster02: online:
    * Resources:
      * ping	(ocf:pacemaker:ping):	 Started
      * dummy	(ocf:pacemaker:Dummy):	 Started
      * Public-IP	(ocf:heartbeat:IPaddr):	 Started
      * Email	(lsb:exim):	 Started
      * mysql-proxy	(lsb:mysql-proxy):	 Started
      * promotable-rsc	(ocf:pacemaker:Stateful):	 Promoted (test_description)
      * httpd-bundle-ip-192.168.122.132	(ocf:heartbeat:IPaddr2):	 Started
      * httpd-bundle-docker-1	(ocf:heartbeat:docker):	 Started
  * GuestNode httpd-bundle-0: online:
    * Resources:
      * httpd	(ocf:heartbeat:apache):	 Started
  * GuestNode httpd-bundle-1: online:
    * Resources:
      * httpd	(ocf:heartbeat:apache):	 Started
  * GuestNode httpd-bundle-2: OFFLINE:
    * Resources:

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
    * dummy: migration-threshold=1000000:
      * (18) start
      * (19) monitor: interval="60000ms"
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (4) monitor: interval="10000ms"
      * (5) cancel: interval="10000ms"
      * (6) promote
      * (7) monitor: interval="5000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * dummy: migration-threshold=1000000:
      * (16) stop
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (2) start
      * (4) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1:
    * httpd: migration-threshold=1000000:
      * (1) start

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01
=#=#=#= End test: Complete text output grouped by node - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output grouped by node
=#=#=#= Begin test: Complete brief text output grouped by node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01: online:
    * Resources:
      * 1	(lsb:mysql-proxy):	Active 
      * 1	(ocf:heartbeat:IPaddr2):	Active 
      * 1	(ocf:heartbeat:docker):	Active 
      * 1	(ocf:pacemaker:Stateful):	Active 
      * 1	(ocf:pacemaker:ping):	Active 
      * 1	(ocf:pacemaker:remote):	Active 
      * 1	(stonith:fence_xvm):	Active 
  * Node cluster02: online:
    * Resources:
      * 1	(lsb:exim):	Active 
      * 1	(lsb:mysql-proxy):	Active 
      * 1	(ocf:heartbeat:IPaddr):	Active 
      * 1	(ocf:heartbeat:IPaddr2):	Active 
      * 1	(ocf:heartbeat:docker):	Active 
      * 1	(ocf:pacemaker:Dummy):	Active 
      * 1	(ocf:pacemaker:Stateful):	Active 
      * 1	(ocf:pacemaker:ping):	Active 
      * 1	(ocf:pacemaker:remote):	Active 
  * GuestNode httpd-bundle-0: online:
    * Resources:
      * 1	(ocf:heartbeat:apache):	Active 
  * GuestNode httpd-bundle-1: online:
    * Resources:
      * 1	(ocf:heartbeat:apache):	Active 

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
    * dummy: migration-threshold=1000000:
      * (18) start
      * (19) monitor: interval="60000ms"
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (4) monitor: interval="10000ms"
      * (5) cancel: interval="10000ms"
      * (6) promote
      * (7) monitor: interval="5000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * dummy: migration-threshold=1000000:
      * (16) stop
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (2) start
      * (4) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1:
    * httpd: migration-threshold=1000000:
      * (1) start

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01
=#=#=#= End test: Complete brief text output grouped by node - OK (0) =#=#=#=
* Passed: crm_mon               - Complete brief text output grouped by node
=#=#=#= Begin test: Output grouped by node (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --group-by-node">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1" description="test_description">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </node>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1" description="test_description">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </node>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0">
      <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
      </resource>
    </node>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1">
      <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
      </resource>
    </node>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output grouped by node (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output grouped by node (XML)
=#=#=#= Begin test: Complete output filtered by node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Unpromoted: [ cluster01 ]

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      

Operations:
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * dummy: migration-threshold=1000000:
      * (16) stop
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (2) start
      * (4) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01
=#=#=#= End test: Complete output filtered by node - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by node
=#=#=#= Begin test: Complete output filtered by node (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --node=cluster01">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by node (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by node (XML)
=#=#=#= Begin test: Complete output filtered by tag =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster02 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster02 ]
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]

Node Attributes:
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
    * dummy: migration-threshold=1000000:
      * (18) start
      * (19) monitor: interval="60000ms"
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * promotable-rsc: migration-threshold=1000000:
      * (4) monitor: interval="10000ms"
      * (5) cancel: interval="10000ms"
      * (6) promote
      * (7) monitor: interval="5000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"

Negative Location Constraints:
  * not-on-cluster1	prevents dummy from running on cluster01
=#=#=#= End test: Complete output filtered by tag - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by tag
=#=#=#= Begin test: Complete output filtered by tag (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --node=even-nodes">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </clone>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <group id="exim-group" number_resources="2" maintenance="false" managed="true" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by tag (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by tag (XML)
=#=#=#= Begin test: Complete output filtered by resource tag =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Fencing	(stonith:fence_xvm):	 Started cluster01

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster01:
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
=#=#=#= End test: Complete output filtered by resource tag - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by resource tag
=#=#=#= Begin test: Complete output filtered by resource tag (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --resource=fencing-rscs">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster01">
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by resource tag (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by resource tag (XML)
=#=#=#= Begin test: Output filtered by node that doesn't exist =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Active Resources:
  * No active resources
=#=#=#= End test: Output filtered by node that doesn't exist - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by node that doesn't exist
=#=#=#= Begin test: Output filtered by node that doesn't exist (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --node=blah">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes/>
  <resources>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
  </resources>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by node that doesn't exist (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by node that doesn't exist (XML)
=#=#=#= Begin test: Basic text output with inactive resources =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Clone Set: inactive-clone [inactive-dhcpd] (disabled):
    * Stopped (disabled): [ cluster01 cluster02 ]
  * Resource Group: inactive-group (disabled):
    * inactive-dummy-1	(ocf:pacemaker:Dummy):	 Stopped (disabled)
    * inactive-dummy-2	(ocf:pacemaker:Dummy):	 Stopped (disabled)
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
    * Unpromoted: [ cluster01 ]
=#=#=#= End test: Basic text output with inactive resources - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources
=#=#=#= Begin test: Basic text output with inactive resources, filtered by node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster02 ]

Full List of Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster02 ]
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Clone Set: inactive-clone [inactive-dhcpd] (disabled):
    * Stopped (disabled): [ cluster02 ]
  * Resource Group: inactive-group (disabled):
    * inactive-dummy-1	(ocf:pacemaker:Dummy):	 Stopped (disabled)
    * inactive-dummy-2	(ocf:pacemaker:Dummy):	 Stopped (disabled)
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
=#=#=#= End test: Basic text output with inactive resources, filtered by node - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by node
=#=#=#= Begin test: Complete output filtered by primitive resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Fencing	(stonith:fence_xvm):	 Started cluster01

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster01:
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
=#=#=#= End test: Complete output filtered by primitive resource - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by primitive resource
=#=#=#= Begin test: Complete output filtered by primitive resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --resource=Fencing">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster01">
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by primitive resource (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by primitive resource (XML)
=#=#=#= Begin test: Complete output filtered by group resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * Public-IP: migration-threshold=1000000:
      * (2) start
    * Email: migration-threshold=1000000:
      * (2) start
=#=#=#= End test: Complete output filtered by group resource - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by group resource
=#=#=#= Begin test: Complete output filtered by group resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --resource=exim-group">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <group id="exim-group" number_resources="2" maintenance="false" managed="true" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by group resource (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by group resource (XML)
=#=#=#= Begin test: Complete text output filtered by group resource member =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * Public-IP: migration-threshold=1000000:
      * (2) start
=#=#=#= End test: Complete text output filtered by group resource member - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output filtered by group resource member
=#=#=#= Begin test: Output filtered by group resource member (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=Email">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <group id="exim-group" number_resources="1" maintenance="false" managed="true" disabled="false">
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by group resource member (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by group resource member (XML)
=#=#=#= Begin test: Complete output filtered by clone resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
=#=#=#= End test: Complete output filtered by clone resource - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by clone resource
=#=#=#= Begin test: Complete output filtered by clone resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --resource=ping-clone">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by clone resource (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by clone resource (XML)
=#=#=#= Begin test: Complete output filtered by clone resource instance =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]

Node Attributes:
  * Node: cluster01:
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02:
    * pingd                           	: 1000      

Operations:
  * Node: cluster02:
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
  * Node: cluster01:
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
=#=#=#= End test: Complete output filtered by clone resource instance - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by clone resource instance
=#=#=#= Begin test: Complete output filtered by clone resource instance (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --include=all --resource=ping">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Complete output filtered by clone resource instance (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Complete output filtered by clone resource instance (XML)
=#=#=#= Begin test: Complete text output filtered by exact clone resource instance =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster02

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * ping: migration-threshold=1000000:
      * (11) start
      * (12) monitor: interval="10000ms"
  * Node: cluster01 (1):
    * ping: migration-threshold=1000000:
      * (17) start
      * (18) monitor: interval="10000ms"
=#=#=#= End test: Complete text output filtered by exact clone resource instance - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output filtered by exact clone resource instance
=#=#=#= Begin test: Output filtered by exact clone resource instance (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=ping:1">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by exact clone resource instance (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by exact clone resource instance (XML)
=#=#=#= Begin test: Output filtered by resource that doesn't exist =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * No active resources
=#=#=#= End test: Output filtered by resource that doesn't exist - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by resource that doesn't exist
=#=#=#= Begin test: Output filtered by resource that doesn't exist (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 --resource=blah">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources/>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history/>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by resource that doesn't exist (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by resource that doesn't exist (XML)
=#=#=#= Begin test: Basic text output with inactive resources, filtered by tag =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Clone Set: inactive-clone [inactive-dhcpd] (disabled):
    * Stopped (disabled): [ cluster01 cluster02 ]
  * Resource Group: inactive-group (disabled):
    * inactive-dummy-1	(ocf:pacemaker:Dummy):	 Stopped (disabled)
    * inactive-dummy-2	(ocf:pacemaker:Dummy):	 Stopped (disabled)
=#=#=#= End test: Basic text output with inactive resources, filtered by tag - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by tag
=#=#=#= Begin test: Basic text output with inactive resources, filtered by bundle resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
=#=#=#= End test: Basic text output with inactive resources, filtered by bundle resource - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by bundle resource
=#=#=#= Begin test: Output filtered by inactive bundle resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=httpd-bundle">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by inactive bundle resource (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by inactive bundle resource (XML)
=#=#=#= Begin test: Basic text output with inactive resources, filtered by bundled IP address resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd-bundle-ip-192.168.122.131	(ocf:heartbeat:IPaddr2):	 Started cluster01
=#=#=#= End test: Basic text output with inactive resources, filtered by bundled IP address resource - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by bundled IP address resource
=#=#=#= Begin test: Output filtered by bundled IP address resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=httpd-bundle-ip-192.168.122.132">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
    </bundle>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by bundled IP address resource (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by bundled IP address resource (XML)
=#=#=#= Begin test: Basic text output with inactive resources, filtered by bundled container =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[1]
      * httpd-bundle-docker-1	(ocf:heartbeat:docker):	 Started cluster02
=#=#=#= End test: Basic text output with inactive resources, filtered by bundled container - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by bundled container
=#=#=#= Begin test: Output filtered by bundled container (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=httpd-bundle-docker-2">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="2">
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by bundled container (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by bundled container (XML)
=#=#=#= Begin test: Basic text output with inactive resources, filtered by bundle connection =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd-bundle-0	(ocf:pacemaker:remote):	 Started cluster01
=#=#=#= End test: Basic text output with inactive resources, filtered by bundle connection - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by bundle connection
=#=#=#= Begin test: Output filtered by bundle connection (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=httpd-bundle-0">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
    </bundle>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by bundle connection (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by bundle connection (XML)
=#=#=#= Begin test: Basic text output with inactive resources, filtered by bundled primitive resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-0
    * Replica[1]
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-1
    * Replica[2]
      * httpd	(ocf:heartbeat:apache):	 Stopped
=#=#=#= End test: Basic text output with inactive resources, filtered by bundled primitive resource - OK (0) =#=#=#=
* Passed: crm_mon               - Basic text output with inactive resources, filtered by bundled primitive resource
=#=#=#= Begin test: Output filtered by bundled primitive resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=httpd">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output filtered by bundled primitive resource (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output filtered by bundled primitive resource (XML)
=#=#=#= Begin test: Complete text output, filtered by clone name in cloned group =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:0:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02
    * Resource Group: mysql-group:1:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
  * Node: cluster01 (1):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
=#=#=#= End test: Complete text output, filtered by clone name in cloned group - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output, filtered by clone name in cloned group
=#=#=#= Begin test: Output, filtered by clone name in cloned group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=mysql-clone-group">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output, filtered by clone name in cloned group (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output, filtered by clone name in cloned group (XML)
=#=#=#= Begin test: Complete text output, filtered by group name in cloned group =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:0:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02
    * Resource Group: mysql-group:1:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
  * Node: cluster01 (1):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
=#=#=#= End test: Complete text output, filtered by group name in cloned group - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output, filtered by group name in cloned group
=#=#=#= Begin test: Output, filtered by group name in cloned group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=mysql-group">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output, filtered by group name in cloned group (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output, filtered by group name in cloned group (XML)
=#=#=#= Begin test: Complete text output, filtered by exact group instance name in cloned group =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:1:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
  * Node: cluster01 (1):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
=#=#=#= End test: Complete text output, filtered by exact group instance name in cloned group - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output, filtered by exact group instance name in cloned group
=#=#=#= Begin test: Output, filtered by exact group instance name in cloned group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=mysql-group:1">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output, filtered by exact group instance name in cloned group (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output, filtered by exact group instance name in cloned group (XML)
=#=#=#= Begin test: Complete text output, filtered by primitive name in cloned group =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:0:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02
    * Resource Group: mysql-group:1:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
  * Node: cluster01 (1):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
=#=#=#= End test: Complete text output, filtered by primitive name in cloned group - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output, filtered by primitive name in cloned group
=#=#=#= Begin test: Output, filtered by primitive name in cloned group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=mysql-proxy">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output, filtered by primitive name in cloned group (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output, filtered by primitive name in cloned group (XML)
=#=#=#= Begin test: Complete text output, filtered by exact primitive instance name in cloned group =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster01: online
  * GuestNode httpd-bundle-1@cluster02: online
  * GuestNode httpd-bundle-2@: OFFLINE

Active Resources:
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:1:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01

Node Attributes:
  * Node: cluster01 (1):
    * location                        	: office    
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
  * Node: cluster01 (1):
    * mysql-proxy: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
=#=#=#= End test: Complete text output, filtered by exact primitive instance name in cloned group - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output, filtered by exact primitive instance name in cloned group
=#=#=#= Begin test: Output, filtered by exact primitive instance name in cloned group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --resource=mysql-proxy:1">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output, filtered by exact primitive instance name in cloned group (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output, filtered by exact primitive instance name in cloned group (XML)
=#=#=#= Begin test: Check that CIB_file="-" works =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 cluster02 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02
    * Email	(lsb:exim):	 Started cluster02
  * Clone Set: mysql-clone-group [mysql-group]:
    * Started: [ cluster01 cluster02 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * Promoted: [ cluster02 ]
    * Unpromoted: [ cluster01 ]
=#=#=#= End test: Check that CIB_file="-" works - OK (0) =#=#=#=
* Passed: crm_mon               - Check that CIB_file="-" works
=#=#=#= Begin test: Output of partially active resources =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster02: online
  * GuestNode httpd-bundle-1@cluster01: online

Active Resources:
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster01
    * ping	(ocf:pacemaker:ping):	 Stopped (Not installed) 
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd-bundle-ip-192.168.122.131	(ocf:heartbeat:IPaddr2):	 Started cluster02
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-0
      * httpd-bundle-docker-0	(ocf:heartbeat:docker):	 Started cluster02
      * httpd-bundle-0	(ocf:pacemaker:remote):	 Started cluster02
    * Replica[1]
      * httpd-bundle-ip-192.168.122.132	(ocf:heartbeat:IPaddr2):	 Started cluster01
      * httpd	(ocf:heartbeat:apache):	 FAILED httpd-bundle-1
      * httpd-bundle-docker-1	(ocf:heartbeat:docker):	 Started cluster01
      * httpd-bundle-1	(ocf:pacemaker:remote):	 Started cluster01
  * Resource Group: partially-active-group (2 members inactive):
    * dummy-1	(ocf:pacemaker:Dummy):	 Started cluster02
    * dummy-2	(ocf:pacemaker:Dummy):	 FAILED cluster02

Failed Resource Actions:
  * dummy-2_monitor_0 on cluster02 'Unimplemented' (3): call=2, status='Done', queued=0ms, exec=33ms
=#=#=#= End test: Output of partially active resources - OK (0) =#=#=#=
* Passed: crm_mon               - Output of partially active resources
=#=#=#= Begin test: Output of partially active resources (XML) =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
<pacemaker-result api-version="X" request="crm_mon --output-as=xml">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="4"/>
    <resources_configured number="16" disabled="1" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="5" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="5" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="true" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
    </bundle>
    <group id="partially-active-group" number_resources="4" maintenance="false" managed="true" disabled="false">
      <resource id="dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="true" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="dummy-3" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="dummy-4" resource_agent="ocf:pacemaker:Dummy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <resource id="smart-mon" resource_agent="ocf:pacemaker:HealthSMART" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy-2" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="probe" rc="3" rc_text="Unimplemented" exec-time="33ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy-4" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="probe" rc="5" rc_text="Not installed" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="smart-mon" orphan="false" migration-threshold="1000000">
        <operation_history call="9" task="probe" rc="5" rc_text="Not installed" exec-time="33ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="6" task="probe" rc="5" rc_text="Not installed" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="probe" rc="2" rc_text="Invalid parameter" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <failures>
    <failure op_key="dummy-2_monitor_0" node="cluster02" exitstatus="Unimplemented" exitreason="" exitcode="3" call="2" status="Done" queued="0" exec="33" interval="0" task="monitor"/>
  </failures>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output of partially active resources (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output of partially active resources (XML)
=#=#=#= Begin test: Output of partially active resources, with inactive resources =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster02: online
  * GuestNode httpd-bundle-1@cluster01: online

Full List of Resources:
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster01
    * ping	(ocf:pacemaker:ping):	 Stopped (Not installed) 
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd-bundle-ip-192.168.122.131	(ocf:heartbeat:IPaddr2):	 Started cluster02
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-0
      * httpd-bundle-docker-0	(ocf:heartbeat:docker):	 Started cluster02
      * httpd-bundle-0	(ocf:pacemaker:remote):	 Started cluster02
    * Replica[1]
      * httpd-bundle-ip-192.168.122.132	(ocf:heartbeat:IPaddr2):	 Started cluster01
      * httpd	(ocf:heartbeat:apache):	 FAILED httpd-bundle-1
      * httpd-bundle-docker-1	(ocf:heartbeat:docker):	 Started cluster01
      * httpd-bundle-1	(ocf:pacemaker:remote):	 Started cluster01
  * Resource Group: partially-active-group:
    * dummy-1	(ocf:pacemaker:Dummy):	 Started cluster02
    * dummy-2	(ocf:pacemaker:Dummy):	 FAILED cluster02
    * dummy-3	(ocf:pacemaker:Dummy):	 Stopped (disabled)
    * dummy-4	(ocf:pacemaker:Dummy):	 Stopped (Not installed) 
  * smart-mon	(ocf:pacemaker:HealthSMART):	 Stopped (Not installed) 

Failed Resource Actions:
  * dummy-2_monitor_0 on cluster02 'Unimplemented' (3): call=2, status='Done', queued=0ms, exec=33ms
=#=#=#= End test: Output of partially active resources, with inactive resources - OK (0) =#=#=#=
* Passed: crm_mon               - Output of partially active resources, with inactive resources
=#=#=#= Begin test: Complete brief text output, with inactive resources =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster02: online
  * GuestNode httpd-bundle-1@cluster01: online

Full List of Resources:
  * 0/1	(ocf:pacemaker:HealthSMART):	Active
  * 1/1	(stonith:fence_xvm):	Active cluster01
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster01
    * ping	(ocf:pacemaker:ping):	 Stopped (Not installed) 
  * Container bundle set: httpd-bundle [pcmk:http]:
    * Replica[0]
      * httpd-bundle-ip-192.168.122.131	(ocf:heartbeat:IPaddr2):	 Started cluster02
      * httpd	(ocf:heartbeat:apache):	 Started httpd-bundle-0
      * httpd-bundle-docker-0	(ocf:heartbeat:docker):	 Started cluster02
      * httpd-bundle-0	(ocf:pacemaker:remote):	 Started cluster02
    * Replica[1]
      * httpd-bundle-ip-192.168.122.132	(ocf:heartbeat:IPaddr2):	 Started cluster01
      * httpd	(ocf:heartbeat:apache):	 FAILED httpd-bundle-1
      * httpd-bundle-docker-1	(ocf:heartbeat:docker):	 Started cluster01
      * httpd-bundle-1	(ocf:pacemaker:remote):	 Started cluster01
  * Resource Group: partially-active-group:
    * 2/4	(ocf:pacemaker:Dummy):	Active cluster02

Node Attributes:
  * Node: cluster01 (1):
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
    * dummy-1: migration-threshold=1000000:
      * (2) start
    * dummy-2: migration-threshold=1000000:
      * (2) probe
    * dummy-4: migration-threshold=1000000:
      * (2) probe
    * smart-mon: migration-threshold=1000000:
      * (9) probe
    * ping: migration-threshold=1000000:
      * (6) probe
  * Node: cluster01 (1):
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * ping: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0@cluster02:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1@cluster01:
    * httpd: migration-threshold=1000000:
      * (1) probe

Failed Resource Actions:
  * dummy-2_monitor_0 on cluster02 'Unimplemented' (3): call=2, status='Done', queued=0ms, exec=33ms
=#=#=#= End test: Complete brief text output, with inactive resources - OK (0) =#=#=#=
* Passed: crm_mon               - Complete brief text output, with inactive resources
=#=#=#= Begin test: Text output of partially active group =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Resource Group: partially-active-group (2 members inactive):
    * dummy-1	(ocf:pacemaker:Dummy):	 Started cluster02
    * dummy-2	(ocf:pacemaker:Dummy):	 FAILED cluster02
=#=#=#= End test: Text output of partially active group - OK (0) =#=#=#=
* Passed: crm_mon               - Text output of partially active group
=#=#=#= Begin test: Text output of partially active group, with inactive resources =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Full List of Resources:
  * Resource Group: partially-active-group:
    * dummy-1	(ocf:pacemaker:Dummy):	 Started cluster02
    * dummy-2	(ocf:pacemaker:Dummy):	 FAILED cluster02
    * dummy-3	(ocf:pacemaker:Dummy):	 Stopped (disabled)
    * dummy-4	(ocf:pacemaker:Dummy):	 Stopped (Not installed) 
=#=#=#= End test: Text output of partially active group, with inactive resources - OK (0) =#=#=#=
* Passed: crm_mon               - Text output of partially active group, with inactive resources
=#=#=#= Begin test: Text output of active member of partially active group =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Online: [ cluster01 cluster02 ]
  * GuestOnline: [ httpd-bundle-0 httpd-bundle-1 ]

Active Resources:
  * Resource Group: partially-active-group (2 members inactive):
    * dummy-1	(ocf:pacemaker:Dummy):	 Started cluster02
=#=#=#= End test: Text output of active member of partially active group - OK (0) =#=#=#=
* Passed: crm_mon               - Text output of active member of partially active group
=#=#=#= Begin test: Text output of inactive member of partially active group =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1
  * Node cluster02 (2): online, feature set <3.15.1
  * GuestNode httpd-bundle-0@cluster02: online
  * GuestNode httpd-bundle-1@cluster01: online

Active Resources:
  * Resource Group: partially-active-group (2 members inactive):
    * dummy-2	(ocf:pacemaker:Dummy):	 FAILED cluster02

Failed Resource Actions:
  * dummy-2_monitor_0 on cluster02 'Unimplemented' (3): call=2, status='Done', queued=0ms, exec=33ms
=#=#=#= End test: Text output of inactive member of partially active group - OK (0) =#=#=#=
* Passed: crm_mon               - Text output of inactive member of partially active group
=#=#=#= Begin test: Complete brief text output grouped by node, with inactive resources =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (2) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Node cluster01 (1): online, feature set <3.15.1:
    * Resources:
      * 1	(ocf:heartbeat:IPaddr2):	Active 
      * 1	(ocf:heartbeat:docker):	Active 
      * 1	(ocf:pacemaker:ping):	Active 
      * 1	(ocf:pacemaker:remote):	Active 
      * 1	(stonith:fence_xvm):	Active 
  * Node cluster02 (2): online, feature set <3.15.1:
    * Resources:
      * 1	(ocf:heartbeat:IPaddr2):	Active 
      * 1	(ocf:heartbeat:docker):	Active 
      * 2	(ocf:pacemaker:Dummy):	Active 
      * 1	(ocf:pacemaker:remote):	Active 
  * GuestNode httpd-bundle-0@cluster02: online:
    * Resources:
      * 1	(ocf:heartbeat:apache):	Active 
  * GuestNode httpd-bundle-1@cluster01: online:
    * Resources:
      * 1	(ocf:heartbeat:apache):	Active 

Inactive Resources:
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster01
    * ping	(ocf:pacemaker:ping):	 Stopped (Not installed) 
  * Resource Group: partially-active-group:
    * 2/4	(ocf:pacemaker:Dummy):	Active cluster02
  * smart-mon	(ocf:pacemaker:HealthSMART):	 Stopped (Not installed) 

Node Attributes:
  * Node: cluster01 (1):
    * pingd                           	: 1000      
  * Node: cluster02 (2):
    * pingd                           	: 1000      

Operations:
  * Node: cluster02 (2):
    * httpd-bundle-ip-192.168.122.131: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-0: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
    * dummy-1: migration-threshold=1000000:
      * (2) start
    * dummy-2: migration-threshold=1000000:
      * (2) probe
    * dummy-4: migration-threshold=1000000:
      * (2) probe
    * smart-mon: migration-threshold=1000000:
      * (9) probe
    * ping: migration-threshold=1000000:
      * (6) probe
  * Node: cluster01 (1):
    * Fencing: migration-threshold=1000000:
      * (15) start
      * (20) monitor: interval="60000ms"
    * ping: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="10000ms"
    * httpd-bundle-ip-192.168.122.132: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-docker-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="60000ms"
    * httpd-bundle-1: migration-threshold=1000000:
      * (2) start
      * (3) monitor: interval="30000ms"
  * Node: httpd-bundle-0@cluster02:
    * httpd: migration-threshold=1000000:
      * (1) start
  * Node: httpd-bundle-1@cluster01:
    * httpd: migration-threshold=1000000:
      * (1) probe

Failed Resource Actions:
  * dummy-2_monitor_0 on cluster02 'Unimplemented' (3): call=2, status='Done', queued=0ms, exec=33ms
=#=#=#= End test: Complete brief text output grouped by node, with inactive resources - OK (0) =#=#=#=
* Passed: crm_mon               - Complete brief text output grouped by node, with inactive resources
=#=#=#= Begin test: Text output of partially active resources, with inactive resources, filtered by node =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 16 resource instances configured (1 DISABLED)

Node List:
  * Online: [ cluster01 ]

Full List of Resources:
  * Clone Set: ping-clone [ping]:
    * Started: [ cluster01 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 FAILED cluster01
  * smart-mon	(ocf:pacemaker:HealthSMART):	 Stopped (Not installed) 
=#=#=#= End test: Text output of partially active resources, with inactive resources, filtered by node - OK (0) =#=#=#=
* Passed: crm_mon               - Text output of partially active resources, with inactive resources, filtered by node
=#=#=#= Begin test: Output of partially active resources, filtered by node (XML) =#=#=#=
unpack_rsc_op 	error: Preventing dummy-2 from restarting on cluster02 because of hard failure (Unimplemented) | dummy-2_last_failure_0
unpack_rsc_op 	error: Preventing httpd-bundle-clone from restarting on httpd-bundle-1 because of hard failure (Invalid parameter) | httpd_last_failure_0
<pacemaker-result api-version="X" request="crm_mon --output-as=xml --node=cluster01">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="4"/>
    <resources_configured number="16" disabled="1" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="5" type="member"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="true" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
    </bundle>
    <resource id="smart-mon" resource_agent="ocf:pacemaker:HealthSMART" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster01">
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output of partially active resources, filtered by node (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output of partially active resources, filtered by node (XML)
=#=#=#= Begin test: Output of active unmanaged resource on offline node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 2 nodes configured
  * 3 resource instances configured

              *** Resource management is DISABLED ***
  The cluster will not attempt to start, stop or recover services

Node List:
  * Online: [ cluster01 ]
  * OFFLINE: [ cluster02 ]

Active Resources:
  * Fencing	(stonith:fence_xvm):	 Started cluster01 (maintenance)
  * rsc1	(ocf:pacemaker:Dummy):	 Started cluster01 (maintenance)
  * rsc2	(ocf:pacemaker:Dummy):	 Started cluster02 (maintenance)
=#=#=#= End test: Output of active unmanaged resource on offline node - OK (0) =#=#=#=
* Passed: crm_mon               - Output of active unmanaged resource on offline node
=#=#=#= Begin test: Output of active unmanaged resource on offline node (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="2"/>
    <resources_configured number="3" disabled="0" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="true" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="2" type="member"/>
    <node name="cluster02" id="2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="true" resources_running="1" type="member"/>
  </nodes>
  <resources>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="rsc1" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="rsc2" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="false"/>
    </resource>
  </resources>
  <node_history>
    <node name="cluster01">
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="cancel" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="rsc1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output of active unmanaged resource on offline node (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output of active unmanaged resource on offline node (XML)
=#=#=#= Begin test: Brief text output of active unmanaged resource on offline node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 2 nodes configured
  * 3 resource instances configured

              *** Resource management is DISABLED ***
  The cluster will not attempt to start, stop or recover services

Node List:
  * Online: [ cluster01 ]
  * OFFLINE: [ cluster02 ]

Active Resources:
  * 1	(ocf:pacemaker:Dummy):	Active cluster01
  * 1	(ocf:pacemaker:Dummy):	Active cluster02
  * 1	(stonith:fence_xvm):	Active cluster01
=#=#=#= End test: Brief text output of active unmanaged resource on offline node - OK (0) =#=#=#=
* Passed: crm_mon               - Brief text output of active unmanaged resource on offline node
=#=#=#= Begin test: Brief text output of active unmanaged resource on offline node, grouped by node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 2 nodes configured
  * 3 resource instances configured

              *** Resource management is DISABLED ***
  The cluster will not attempt to start, stop or recover services

Node List:
  * Node cluster01: online:
    * Resources:
      * 1	(ocf:pacemaker:Dummy):	Active 
      * 1	(stonith:fence_xvm):	Active 
  * Node cluster02: OFFLINE:
    * Resources:
      * 1	(ocf:pacemaker:Dummy):	Active 
=#=#=#= End test: Brief text output of active unmanaged resource on offline node, grouped by node - OK (0) =#=#=#=
* Passed: crm_mon               - Brief text output of active unmanaged resource on offline node, grouped by node
=#=#=#= Begin test: Output of all resources with maintenance-mode enabled =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

              *** Resource management is DISABLED ***
  The cluster will not attempt to start, stop or recover services

Node List:
  * GuestNode httpd-bundle-0: maintenance
  * GuestNode httpd-bundle-1: maintenance
  * Online: [ cluster01 cluster02 ]

Full List of Resources:
  * Clone Set: ping-clone [ping] (maintenance):
    * ping	(ocf:pacemaker:ping):	 Started cluster02 (maintenance)
    * ping	(ocf:pacemaker:ping):	 Started cluster01 (maintenance)
  * Fencing	(stonith:fence_xvm):	 Started cluster01 (maintenance)
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02 (maintenance)
  * Clone Set: inactive-clone [inactive-dhcpd] (disabled, maintenance):
    * Stopped (disabled): [ cluster01 cluster02 ]
  * Resource Group: inactive-group (disabled, maintenance):
    * inactive-dummy-1	(ocf:pacemaker:Dummy):	 Stopped (disabled, maintenance)
    * inactive-dummy-2	(ocf:pacemaker:Dummy):	 Stopped (disabled, maintenance)
  * Container bundle set: httpd-bundle [pcmk:http] (maintenance):
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01 (maintenance)
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02 (maintenance)
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped (maintenance)
  * Resource Group: exim-group (maintenance):
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02 (maintenance)
    * Email	(lsb:exim):	 Started cluster02 (maintenance)
  * Clone Set: mysql-clone-group [mysql-group] (maintenance):
    * Resource Group: mysql-group:0 (maintenance):
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02 (maintenance)
    * Resource Group: mysql-group:1 (maintenance):
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01 (maintenance)
  * Clone Set: promotable-clone [promotable-rsc] (promotable, maintenance):
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Promoted cluster02 (maintenance)
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Unpromoted cluster01 (maintenance)
=#=#=#= End test: Output of all resources with maintenance-mode enabled - OK (0) =#=#=#=
* Passed: crm_mon               - Output of all resources with maintenance-mode enabled
=#=#=#= Begin test: Output of all resources with maintenance-mode enabled (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 -r">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="true" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="true" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="true" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="true" managed="false" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="true" managed="false" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="true" managed="false" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="true" managed="false" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <group id="exim-group" number_resources="2" maintenance="true" managed="false" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="true" managed="false" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="true" managed="false" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output of all resources with maintenance-mode enabled (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output of all resources with maintenance-mode enabled (XML)
=#=#=#= Begin test: Output of all resources with maintenance enabled for a node =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * Node cluster02: maintenance
  * GuestNode httpd-bundle-1: maintenance
  * Online: [ cluster01 ]
  * GuestOnline: [ httpd-bundle-0 ]

Full List of Resources:
  * Clone Set: ping-clone [ping]:
    * ping	(ocf:pacemaker:ping):	 Started cluster02 (maintenance)
    * Started: [ cluster01 ]
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02 (maintenance)
  * Clone Set: inactive-clone [inactive-dhcpd] (disabled):
    * Stopped (disabled): [ cluster01 cluster02 ]
  * Resource Group: inactive-group (disabled):
    * inactive-dummy-1	(ocf:pacemaker:Dummy):	 Stopped (disabled)
    * inactive-dummy-2	(ocf:pacemaker:Dummy):	 Stopped (disabled)
  * Container bundle set: httpd-bundle [pcmk:http]:
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02 (maintenance)
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped
  * Resource Group: exim-group:
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02 (maintenance)
    * Email	(lsb:exim):	 Started cluster02 (maintenance)
  * Clone Set: mysql-clone-group [mysql-group]:
    * Resource Group: mysql-group:0:
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02 (maintenance)
    * Started: [ cluster01 ]
  * Clone Set: promotable-clone [promotable-rsc] (promotable):
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Promoted cluster02 (maintenance)
    * Unpromoted: [ cluster01 ]
=#=#=#= End test: Output of all resources with maintenance enabled for a node - OK (0) =#=#=#=
* Passed: crm_mon               - Output of all resources with maintenance enabled for a node
=#=#=#= Begin test: Output of all resources with maintenance enabled for a node (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 -r">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="true" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="true" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="false" managed="true" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="false" managed="true" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="false" managed="true" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <group id="exim-group" number_resources="2" maintenance="false" managed="true" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="false" managed="true" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="false" managed="true" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="maintenance" value="true"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output of all resources with maintenance enabled for a node (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output of all resources with maintenance enabled for a node (XML)
=#=#=#= Begin test: Output of all resources with maintenance meta attribute true =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cluster02 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 5 nodes configured
  * 32 resource instances configured (4 DISABLED)

Node List:
  * GuestNode httpd-bundle-0: maintenance
  * GuestNode httpd-bundle-1: maintenance
  * Online: [ cluster01 cluster02 ]

Full List of Resources:
  * Clone Set: ping-clone [ping] (maintenance):
    * ping	(ocf:pacemaker:ping):	 Started cluster02 (maintenance)
    * ping	(ocf:pacemaker:ping):	 Started cluster01 (maintenance)
  * Fencing	(stonith:fence_xvm):	 Started cluster01
  * dummy	(ocf:pacemaker:Dummy):	 Started cluster02 (maintenance)
  * Clone Set: inactive-clone [inactive-dhcpd] (disabled, maintenance):
    * Stopped (disabled): [ cluster01 cluster02 ]
  * Resource Group: inactive-group (disabled, maintenance):
    * inactive-dummy-1	(ocf:pacemaker:Dummy):	 Stopped (disabled, maintenance)
    * inactive-dummy-2	(ocf:pacemaker:Dummy):	 Stopped (disabled, maintenance)
  * Container bundle set: httpd-bundle [pcmk:http] (maintenance):
    * httpd-bundle-0 (192.168.122.131)	(ocf:heartbeat:apache):	 Started cluster01 (maintenance)
    * httpd-bundle-1 (192.168.122.132)	(ocf:heartbeat:apache):	 Started cluster02 (maintenance)
    * httpd-bundle-2 (192.168.122.133)	(ocf:heartbeat:apache):	 Stopped (maintenance)
  * Resource Group: exim-group (maintenance):
    * Public-IP	(ocf:heartbeat:IPaddr):	 Started cluster02 (maintenance)
    * Email	(lsb:exim):	 Started cluster02 (maintenance)
  * Clone Set: mysql-clone-group [mysql-group] (maintenance):
    * Resource Group: mysql-group:0 (maintenance):
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster02 (maintenance)
    * Resource Group: mysql-group:1 (maintenance):
      * mysql-proxy	(lsb:mysql-proxy):	 Started cluster01 (maintenance)
  * Clone Set: promotable-clone [promotable-rsc] (promotable, maintenance):
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Promoted cluster02 (maintenance)
    * promotable-rsc	(ocf:pacemaker:Stateful):	 Unpromoted cluster01 (maintenance)
=#=#=#= End test: Output of all resources with maintenance meta attribute true - OK (0) =#=#=#=
* Passed: crm_mon               - Output of all resources with maintenance meta attribute true
=#=#=#= Begin test: Output of all resources with maintenance meta attribute true (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_mon --output-as=xml -1 -r">
  <summary>
    <stack type="corosync"/>
    <current_dc present="true" version="" name="cluster02" id="2" with_quorum="true" mixed_version="false"/>
    <last_update time=""/>
    <last_change time=""/>
    <nodes_configured number="5"/>
    <resources_configured number="32" disabled="4" blocked="0"/>
    <cluster_options stonith-enabled="true" symmetric-cluster="true" no-quorum-policy="stop" maintenance-mode="false" stop-all-resources="false" stonith-timeout-ms="60000" priority-fencing-delay-ms="0"/>
  </summary>
  <nodes>
    <node name="cluster01" id="1" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="false" resources_running="7" type="member"/>
    <node name="cluster02" id="2" online="true" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" feature_set="&lt;3.15.1" shutdown="false" expected_up="true" is_dc="true" resources_running="9" type="member"/>
    <node name="httpd-bundle-0" id="httpd-bundle-0" online="true" standby="false" standby_onfail="false" maintenance="true" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-0"/>
    <node name="httpd-bundle-1" id="httpd-bundle-1" online="true" standby="false" standby_onfail="false" maintenance="true" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="1" type="remote" id_as_resource="httpd-bundle-docker-1"/>
    <node name="httpd-bundle-2" id="httpd-bundle-2" online="false" standby="false" standby_onfail="false" maintenance="false" pending="false" unclean="false" health="green" shutdown="false" expected_up="false" is_dc="false" resources_running="0" type="remote" id_as_resource="httpd-bundle-docker-2"/>
  </nodes>
  <resources>
    <clone id="ping-clone" multi_state="false" unique="false" maintenance="true" managed="false" disabled="false" failed="false" failure_ignored="false">
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="ping" resource_agent="ocf:pacemaker:ping" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
    </clone>
    <resource id="Fencing" resource_agent="stonith:fence_xvm" role="Started" active="true" orphaned="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster01" id="1" cached="true"/>
    </resource>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
      <node name="cluster02" id="2" cached="true"/>
    </resource>
    <clone id="inactive-clone" multi_state="false" unique="false" maintenance="true" managed="false" disabled="true" failed="false" failure_ignored="false" target_role="stopped">
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dhcpd" resource_agent="lsb:dhcpd" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
    <group id="inactive-group" number_resources="2" maintenance="true" managed="false" disabled="true">
      <resource id="inactive-dummy-1" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="inactive-dummy-2" resource_agent="ocf:pacemaker:Dummy" role="Stopped" target_role="stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </group>
    <bundle id="httpd-bundle" type="docker" image="pcmk:http" unique="false" maintenance="true" managed="false" failed="false">
      <replica id="0">
        <resource id="httpd-bundle-ip-192.168.122.131" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-0" id="httpd-bundle-0" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-0" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-0" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </replica>
      <replica id="1">
        <resource id="httpd-bundle-ip-192.168.122.132" resource_agent="ocf:heartbeat:IPaddr2" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="httpd-bundle-1" id="httpd-bundle-1" cached="true"/>
        </resource>
        <resource id="httpd-bundle-docker-1" resource_agent="ocf:heartbeat:docker" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
        <resource id="httpd-bundle-1" resource_agent="ocf:pacemaker:remote" role="Started" target_role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </replica>
      <replica id="2">
        <resource id="httpd-bundle-ip-192.168.122.133" resource_agent="ocf:heartbeat:IPaddr2" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd" resource_agent="ocf:heartbeat:apache" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-docker-2" resource_agent="ocf:heartbeat:docker" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
        <resource id="httpd-bundle-2" resource_agent="ocf:pacemaker:remote" role="Stopped" target_role="Started" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </replica>
    </bundle>
    <group id="exim-group" number_resources="2" maintenance="true" managed="false" disabled="false">
      <resource id="Public-IP" resource_agent="ocf:heartbeat:IPaddr" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="Email" resource_agent="lsb:exim" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
    </group>
    <clone id="mysql-clone-group" multi_state="false" unique="false" maintenance="true" managed="false" disabled="false" failed="false" failure_ignored="false">
      <group id="mysql-group:0" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster02" id="2" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:1" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Started" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
          <node name="cluster01" id="1" cached="true"/>
        </resource>
      </group>
      <group id="mysql-group:2" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:3" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
      <group id="mysql-group:4" number_resources="1" maintenance="true" managed="false" disabled="false">
        <resource id="mysql-proxy" resource_agent="lsb:mysql-proxy" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      </group>
    </clone>
    <clone id="promotable-clone" multi_state="true" unique="false" maintenance="true" managed="false" disabled="false" failed="false" failure_ignored="false">
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Promoted" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster02" id="2" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Unpromoted" active="true" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="1">
        <node name="cluster01" id="1" cached="true"/>
      </resource>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
      <resource id="promotable-rsc" resource_agent="ocf:pacemaker:Stateful" role="Stopped" active="false" orphaned="false" blocked="false" maintenance="true" managed="false" failed="false" failure_ignored="false" nodes_running_on="0"/>
    </clone>
  </resources>
  <node_attributes>
    <node name="cluster01">
      <attribute name="location" value="office"/>
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
    <node name="cluster02">
      <attribute name="pingd" value="1000" expected="1000"/>
    </node>
  </node_attributes>
  <node_history>
    <node name="cluster02">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="11" task="start" rc="0" rc_text="OK" exec-time="2044ms" queue-time="0ms"/>
        <operation_history call="12" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2031ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="18" task="start" rc="0" rc_text="OK" exec-time="6020ms" queue-time="0ms"/>
        <operation_history call="19" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="6015ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Public-IP" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Email" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="5" task="cancel" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="6" task="promote" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="7" task="monitor" rc="8" rc_text="Promoted" interval="5000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.132" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-1" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="cluster01">
      <resource_history id="ping" orphan="false" migration-threshold="1000000">
        <operation_history call="17" task="start" rc="0" rc_text="OK" exec-time="2038ms" queue-time="0ms"/>
        <operation_history call="18" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="2034ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="Fencing" orphan="false" migration-threshold="1000000">
        <operation_history call="15" task="start" rc="0" rc_text="OK" exec-time="36ms" queue-time="0ms"/>
        <operation_history call="20" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="dummy" orphan="false" migration-threshold="1000000">
        <operation_history call="16" task="stop" rc="0" rc_text="OK" exec-time="6048ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="mysql-proxy" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="promotable-rsc" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="4" task="monitor" rc="0" rc_text="OK" interval="10000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-ip-192.168.122.131" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-docker-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="60000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
      <resource_history id="httpd-bundle-0" orphan="false" migration-threshold="1000000">
        <operation_history call="2" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
        <operation_history call="3" task="monitor" rc="0" rc_text="OK" interval="30000ms" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-0">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
    <node name="httpd-bundle-1">
      <resource_history id="httpd" orphan="false" migration-threshold="1000000">
        <operation_history call="1" task="start" rc="0" rc_text="OK" exec-time="0ms" queue-time="0ms"/>
      </resource_history>
    </node>
  </node_history>
  <bans>
    <ban id="not-on-cluster1" resource="dummy" node="cluster01" weight="-1000000" promoted-only="false" master_only="false"/>
  </bans>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Output of all resources with maintenance meta attribute true (XML) - OK (0) =#=#=#=
* Passed: crm_mon               - Output of all resources with maintenance meta attribute true (XML)
=#=#=#= Begin test: Text output of guest node's container on different node from its remote resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cent7-host2 (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 10 resource instances configured

Node List:
  * Online: [ cent7-host1 cent7-host2 ]
  * GuestOnline: [ httpd-bundle1-0 httpd-bundle2-0 ]

Active Resources:
  * Resource Group: group1:
    * dummy1	(ocf:pacemaker:Dummy):	 Started cent7-host1
  * Resource Group: group2:
    * dummy2	(ocf:pacemaker:Dummy):	 Started cent7-host2
  * Container bundle: httpd-bundle1 [pcmktest:http]:
    * httpd-bundle1-0 (192.168.20.188)	(ocf:heartbeat:apache):	 Started cent7-host1
  * Container bundle: httpd-bundle2 [pcmktest:http]:
    * httpd-bundle2-0 (192.168.20.190)	(ocf:heartbeat:apache):	 Started cent7-host2
=#=#=#= End test: Text output of guest node's container on different node from its remote resource - OK (0) =#=#=#=
* Passed: crm_mon               - Text output of guest node's container on different node from its remote resource
=#=#=#= Begin test: Complete text output of guest node's container on different node from its remote resource =#=#=#=
Cluster Summary:
  * Stack: corosync
  * Current DC: cent7-host2 (3232262829) (version) - partition with quorum
  * Last updated:
  * Last change:
  * 4 nodes configured
  * 10 resource instances configured

Node List:
  * Node cent7-host1 (3232262828): online, feature set <3.15.1
  * Node cent7-host2 (3232262829): online, feature set <3.15.1
  * GuestNode httpd-bundle1-0@cent7-host1: online
  * GuestNode httpd-bundle2-0@cent7-host2: online

Active Resources:
  * Resource Group: group1:
    * dummy1	(ocf:pacemaker:Dummy):	 Started cent7-host1
  * Resource Group: group2:
    * dummy2	(ocf:pacemaker:Dummy):	 Started cent7-host2
  * Container bundle: httpd-bundle1 [pcmktest:http]:
      * httpd-bundle1-ip-192.168.20.188	(ocf:heartbeat:IPaddr2):	 Started cent7-host1
      * httpd1	(ocf:heartbeat:apache):	 Started httpd-bundle1-0
      * httpd-bundle1-docker-0	(ocf:heartbeat:docker):	 Started cent7-host1
      * httpd-bundle1-0	(ocf:pacemaker:remote):	 Started cent7-host2
  * Container bundle: httpd-bundle2 [pcmktest:http]:
      * httpd-bundle2-ip-192.168.20.190	(ocf:heartbeat:IPaddr2):	 Started cent7-host2
      * httpd2	(ocf:heartbeat:apache):	 Started httpd-bundle2-0
      * httpd-bundle2-docker-0	(ocf:heartbeat:docker):	 Started cent7-host2
      * httpd-bundle2-0	(ocf:pacemaker:remote):	 Started cent7-host2
=#=#=#= End test: Complete text output of guest node's container on different node from its remote resource - OK (0) =#=#=#=
* Passed: crm_mon               - Complete text output of guest node's container on different node from its remote resource
