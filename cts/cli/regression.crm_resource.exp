=#=#=#= Begin test: crm_resource run with extra arguments =#=#=#=
crm_resource: non-option ARGV-elements:
[1 of 2] foo
[2 of 2] bar
=#=#=#= End test: crm_resource run with extra arguments - Incorrect usage (64) =#=#=#=
* Passed: crm_resource          - crm_resource run with extra arguments
=#=#=#= Begin test: List all available resource options (invalid type) =#=#=#=
crm_resource: Error parsing option --list-options
=#=#=#= End test: List all available resource options (invalid type) - Incorrect usage (64) =#=#=#=
* Passed: crm_resource          - List all available resource options (invalid type)
=#=#=#= Begin test: List all available resource options (invalid type) =#=#=#=
crm_resource: Error parsing option --list-options
=#=#=#= End test: List all available resource options (invalid type) - Incorrect usage (64) =#=#=#=
* Passed: crm_resource          - List all available resource options (invalid type)
=#=#=#= Begin test: List non-advanced primitive meta-attributes =#=#=#=
Primitive meta-attributes

Meta-attributes applicable to primitive resources

  * priority: Resource assignment priority
    * If not all resources can be active, the cluster will stop lower-priority resources in order to keep higher-priority ones active.
    * Possible values: score (default: )

  * critical: Default value for influence in colocation constraints
    * Use this value as the default for influence in all colocation constraints involving this resource, as well as in the implicit colocation constraints created if this resource is in a group.
    * Possible values: boolean (default: )

  * target-role: State the cluster should attempt to keep this resource in
    * "Stopped" forces the resource to be stopped. "Started" allows the resource to be started (and in the case of promotable clone resources, promoted if appropriate). "Unpromoted" allows the resource to be started, but only in the unpromoted role if the resource is promotable. "Promoted" is equivalent to "Started".
    * Possible values: "Stopped", "Started" (default), "Unpromoted", "Promoted"

  * is-managed: Whether the cluster is allowed to actively change the resource's state
    * If false, the cluster will not start, stop, promote, or demote the resource on any node. Recurring actions for the resource are unaffected. If true, a true value for the maintenance-mode cluster option, the maintenance node attribute, or the maintenance resource meta-attribute overrides this.
    * Possible values: boolean (default: )

  * maintenance: If true, the cluster will not schedule any actions involving the resource
    * If true, the cluster will not start, stop, promote, or demote the resource on any node, and will pause any recurring monitors (except those specifying role as "Stopped"). If false, a true value for the maintenance-mode cluster option or maintenance node attribute overrides this.
    * Possible values: boolean (default: )

  * resource-stickiness: Score to add to the current node when a resource is already active
    * Score to add to the current node when a resource is already active. This allows running resources to stay where they are, even if they would be placed elsewhere if they were being started from a stopped state. The default is 1 for individual clone instances, and 0 for all other resources.
    * Possible values: score (no default)

  * requires: Conditions under which the resource can be started
    * Conditions under which the resource can be started. "nothing" means the cluster can always start this resource. "quorum" means the cluster can start this resource only if a majority of the configured nodes are active. "fencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced. "unfencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced, and only on nodes that have been unfenced. The default is "quorum" for resources with a class of stonith; otherwise, "unfencing" if unfencing is active in the cluster; otherwise, "fencing" if the fencing-enabled cluster option is true; otherwise, "quorum".
    * Possible values: "nothing", "quorum", "fencing", "unfencing"

  * migration-threshold: Number of failures on a node before the resource becomes ineligible to run there.
    * Number of failures that may occur for this resource on a node, before that node is marked ineligible to host this resource. A value of 0 indicates that this feature is disabled (the node will never be marked ineligible). By contrast, the cluster treats "INFINITY" (the default) as a very large but finite number. This option has an effect only if the failed operation specifies its on-fail attribute as "restart" (the default), and additionally for failed start operations, if the start-failure-is-fatal cluster property is set to false.
    * Possible values: score (default: )

  * failure-timeout: Number of seconds before acting as if a failure had not occurred
    * Number of seconds after a failed action for this resource before acting as if the failure had not occurred, and potentially allowing the resource back to the node on which it failed. A value of 0 indicates that this feature is disabled.
    * Possible values: duration (default: )

  * multiple-active: What to do if the cluster finds the resource active on more than one node
    * What to do if the cluster finds the resource active on more than one node. "block" means to mark the resource as unmanaged. "stop_only" means to stop all active instances of this resource and leave them stopped. "stop_start" means to stop all active instances of this resource and start the resource in one location only. "stop_unexpected" means to stop all active instances of this resource except where the resource should be active. (This should be used only when extra instances are not expected to disrupt existing instances, and the resource agent's monitor of an existing instance is capable of detecting any problems that could be caused. Note that any resources ordered after this one will still need to be restarted.)
    * Possible values: "block", "stop_only", "stop_start" (default), "stop_unexpected"

  * allow-migrate: Whether the cluster should try to "live migrate" this resource when it needs to be moved
    * Whether the cluster should try to "live migrate" this resource when it needs to be moved. The default is true for ocf:pacemaker:remote resources, and false otherwise.
    * Possible values: boolean (no default)

  * allow-unhealthy-nodes: Whether the resource should be allowed to run on a node even if the node's health score would otherwise prevent it
    * Possible values: boolean (default: )

  * container-attribute-target: Where to check user-defined node attributes
    * Whether to check user-defined node attributes on the physical host where a container is running or on the local node. This is usually set for a bundle resource and inherited by the bundle's primitive resource. A value of "host" means to check user-defined node attributes on the underlying physical host. Any other value means to check user-defined node attributes on the local node (for a bundled primitive resource, this is the bundle node).
    * Possible values: string (no default)

  * remote-node: Name of the Pacemaker Remote guest node this resource is associated with, if any
    * Name of the Pacemaker Remote guest node this resource is associated with, if any. If specified, this both enables the resource as a guest node and defines the unique name used to identify the guest node. The guest must be configured to run the Pacemaker Remote daemon when it is started. WARNING: This value cannot overlap with any resource or node IDs.
    * Possible values: string (no default)

  * remote-addr: If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote
    * If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote. The Pacemaker Remote daemon on the guest must be configured to accept connections on this address. The default is the value of the remote-node meta-attribute.
    * Possible values: string (no default)

  * remote-port: If remote-node is specified, port on the guest used for its Pacemaker Remote connection
    * If remote-node is specified, the port on the guest used for its Pacemaker Remote connection. The Pacemaker Remote daemon on the guest must be configured to listen on this port.
    * Possible values: port (default: )

  * remote-connect-timeout: If remote-node is specified, how long before a pending Pacemaker Remote guest connection times out.
    * Possible values: timeout (default: )

  * remote-allow-migrate: If remote-node is specified, this acts as the allow-migrate meta-attribute for the implicit remote connection resource (ocf:pacemaker:remote).
    * Possible values: boolean (default: )
=#=#=#= End test: List non-advanced primitive meta-attributes - OK (0) =#=#=#=
* Passed: crm_resource          - List non-advanced primitive meta-attributes
=#=#=#= Begin test: List non-advanced primitive meta-attributes (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --list-options=primitive">
  <resource-agent name="primitive-meta" version="">
    <version>1.1</version>
    <longdesc lang="en">Meta-attributes applicable to primitive resources</longdesc>
    <shortdesc lang="en">Primitive meta-attributes</shortdesc>
    <parameters>
      <parameter name="priority" advanced="0" generated="0">
        <longdesc lang="en">If not all resources can be active, the cluster will stop lower-priority resources in order to keep higher-priority ones active.</longdesc>
        <shortdesc lang="en">Resource assignment priority</shortdesc>
        <content type="score" default=""/>
      </parameter>
      <parameter name="critical" advanced="0" generated="0">
        <longdesc lang="en">Use this value as the default for influence in all colocation constraints involving this resource, as well as in the implicit colocation constraints created if this resource is in a group.</longdesc>
        <shortdesc lang="en">Default value for influence in colocation constraints</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="target-role" advanced="0" generated="0">
        <longdesc lang="en">"Stopped" forces the resource to be stopped. "Started" allows the resource to be started (and in the case of promotable clone resources, promoted if appropriate). "Unpromoted" allows the resource to be started, but only in the unpromoted role if the resource is promotable. "Promoted" is equivalent to "Started".</longdesc>
        <shortdesc lang="en">State the cluster should attempt to keep this resource in</shortdesc>
        <content type="select" default="">
          <option value="Stopped"/>
          <option value="Started"/>
          <option value="Unpromoted"/>
          <option value="Promoted"/>
        </content>
      </parameter>
      <parameter name="is-managed" advanced="0" generated="0">
        <longdesc lang="en">If false, the cluster will not start, stop, promote, or demote the resource on any node. Recurring actions for the resource are unaffected. If true, a true value for the maintenance-mode cluster option, the maintenance node attribute, or the maintenance resource meta-attribute overrides this.</longdesc>
        <shortdesc lang="en">Whether the cluster is allowed to actively change the resource's state</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="maintenance" advanced="0" generated="0">
        <longdesc lang="en">If true, the cluster will not start, stop, promote, or demote the resource on any node, and will pause any recurring monitors (except those specifying role as "Stopped"). If false, a true value for the maintenance-mode cluster option or maintenance node attribute overrides this.</longdesc>
        <shortdesc lang="en">If true, the cluster will not schedule any actions involving the resource</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="resource-stickiness" advanced="0" generated="0">
        <longdesc lang="en">Score to add to the current node when a resource is already active. This allows running resources to stay where they are, even if they would be placed elsewhere if they were being started from a stopped state. The default is 1 for individual clone instances, and 0 for all other resources.</longdesc>
        <shortdesc lang="en">Score to add to the current node when a resource is already active</shortdesc>
        <content type="score"/>
      </parameter>
      <parameter name="requires" advanced="0" generated="0">
        <longdesc lang="en">Conditions under which the resource can be started. "nothing" means the cluster can always start this resource. "quorum" means the cluster can start this resource only if a majority of the configured nodes are active. "fencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced. "unfencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced, and only on nodes that have been unfenced. The default is "quorum" for resources with a class of stonith; otherwise, "unfencing" if unfencing is active in the cluster; otherwise, "fencing" if the fencing-enabled cluster option is true; otherwise, "quorum".</longdesc>
        <shortdesc lang="en">Conditions under which the resource can be started</shortdesc>
        <content type="select">
          <option value="nothing"/>
          <option value="quorum"/>
          <option value="fencing"/>
          <option value="unfencing"/>
        </content>
      </parameter>
      <parameter name="migration-threshold" advanced="0" generated="0">
        <longdesc lang="en">Number of failures that may occur for this resource on a node, before that node is marked ineligible to host this resource. A value of 0 indicates that this feature is disabled (the node will never be marked ineligible). By contrast, the cluster treats "INFINITY" (the default) as a very large but finite number. This option has an effect only if the failed operation specifies its on-fail attribute as "restart" (the default), and additionally for failed start operations, if the start-failure-is-fatal cluster property is set to false.</longdesc>
        <shortdesc lang="en">Number of failures on a node before the resource becomes ineligible to run there.</shortdesc>
        <content type="score" default=""/>
      </parameter>
      <parameter name="failure-timeout" advanced="0" generated="0">
        <longdesc lang="en">Number of seconds after a failed action for this resource before acting as if the failure had not occurred, and potentially allowing the resource back to the node on which it failed. A value of 0 indicates that this feature is disabled.</longdesc>
        <shortdesc lang="en">Number of seconds before acting as if a failure had not occurred</shortdesc>
        <content type="duration" default=""/>
      </parameter>
      <parameter name="multiple-active" advanced="0" generated="0">
        <longdesc lang="en">What to do if the cluster finds the resource active on more than one node. "block" means to mark the resource as unmanaged. "stop_only" means to stop all active instances of this resource and leave them stopped. "stop_start" means to stop all active instances of this resource and start the resource in one location only. "stop_unexpected" means to stop all active instances of this resource except where the resource should be active. (This should be used only when extra instances are not expected to disrupt existing instances, and the resource agent's monitor of an existing instance is capable of detecting any problems that could be caused. Note that any resources ordered after this one will still need to be restarted.)</longdesc>
        <shortdesc lang="en">What to do if the cluster finds the resource active on more than one node</shortdesc>
        <content type="select" default="">
          <option value="block"/>
          <option value="stop_only"/>
          <option value="stop_start"/>
          <option value="stop_unexpected"/>
        </content>
      </parameter>
      <parameter name="allow-migrate" advanced="0" generated="0">
        <longdesc lang="en">Whether the cluster should try to "live migrate" this resource when it needs to be moved. The default is true for ocf:pacemaker:remote resources, and false otherwise.</longdesc>
        <shortdesc lang="en">Whether the cluster should try to "live migrate" this resource when it needs to be moved</shortdesc>
        <content type="boolean"/>
      </parameter>
      <parameter name="allow-unhealthy-nodes" advanced="0" generated="0">
        <longdesc lang="en">Whether the resource should be allowed to run on a node even if the node's health score would otherwise prevent it</longdesc>
        <shortdesc lang="en">Whether the resource should be allowed to run on a node even if the node's health score would otherwise prevent it</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="container-attribute-target" advanced="0" generated="0">
        <longdesc lang="en">Whether to check user-defined node attributes on the physical host where a container is running or on the local node. This is usually set for a bundle resource and inherited by the bundle's primitive resource. A value of "host" means to check user-defined node attributes on the underlying physical host. Any other value means to check user-defined node attributes on the local node (for a bundled primitive resource, this is the bundle node).</longdesc>
        <shortdesc lang="en">Where to check user-defined node attributes</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="remote-node" advanced="0" generated="0">
        <longdesc lang="en">Name of the Pacemaker Remote guest node this resource is associated with, if any. If specified, this both enables the resource as a guest node and defines the unique name used to identify the guest node. The guest must be configured to run the Pacemaker Remote daemon when it is started. WARNING: This value cannot overlap with any resource or node IDs.</longdesc>
        <shortdesc lang="en">Name of the Pacemaker Remote guest node this resource is associated with, if any</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="remote-addr" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote. The Pacemaker Remote daemon on the guest must be configured to accept connections on this address. The default is the value of the remote-node meta-attribute.</longdesc>
        <shortdesc lang="en">If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="remote-port" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, the port on the guest used for its Pacemaker Remote connection. The Pacemaker Remote daemon on the guest must be configured to listen on this port.</longdesc>
        <shortdesc lang="en">If remote-node is specified, port on the guest used for its Pacemaker Remote connection</shortdesc>
        <content type="port" default=""/>
      </parameter>
      <parameter name="remote-connect-timeout" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, how long before a pending Pacemaker Remote guest connection times out.</longdesc>
        <shortdesc lang="en">If remote-node is specified, how long before a pending Pacemaker Remote guest connection times out.</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="remote-allow-migrate" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, this acts as the allow-migrate meta-attribute for the implicit remote connection resource (ocf:pacemaker:remote).</longdesc>
        <shortdesc lang="en">If remote-node is specified, this acts as the allow-migrate meta-attribute for the implicit remote connection resource (ocf:pacemaker:remote).</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
    </parameters>
  </resource-agent>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List non-advanced primitive meta-attributes (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List non-advanced primitive meta-attributes (XML)
=#=#=#= Begin test: List all available primitive meta-attributes =#=#=#=
Primitive meta-attributes

Meta-attributes applicable to primitive resources

  * priority: Resource assignment priority
    * If not all resources can be active, the cluster will stop lower-priority resources in order to keep higher-priority ones active.
    * Possible values: score (default: )

  * critical: Default value for influence in colocation constraints
    * Use this value as the default for influence in all colocation constraints involving this resource, as well as in the implicit colocation constraints created if this resource is in a group.
    * Possible values: boolean (default: )

  * target-role: State the cluster should attempt to keep this resource in
    * "Stopped" forces the resource to be stopped. "Started" allows the resource to be started (and in the case of promotable clone resources, promoted if appropriate). "Unpromoted" allows the resource to be started, but only in the unpromoted role if the resource is promotable. "Promoted" is equivalent to "Started".
    * Possible values: "Stopped", "Started" (default), "Unpromoted", "Promoted"

  * is-managed: Whether the cluster is allowed to actively change the resource's state
    * If false, the cluster will not start, stop, promote, or demote the resource on any node. Recurring actions for the resource are unaffected. If true, a true value for the maintenance-mode cluster option, the maintenance node attribute, or the maintenance resource meta-attribute overrides this.
    * Possible values: boolean (default: )

  * maintenance: If true, the cluster will not schedule any actions involving the resource
    * If true, the cluster will not start, stop, promote, or demote the resource on any node, and will pause any recurring monitors (except those specifying role as "Stopped"). If false, a true value for the maintenance-mode cluster option or maintenance node attribute overrides this.
    * Possible values: boolean (default: )

  * resource-stickiness: Score to add to the current node when a resource is already active
    * Score to add to the current node when a resource is already active. This allows running resources to stay where they are, even if they would be placed elsewhere if they were being started from a stopped state. The default is 1 for individual clone instances, and 0 for all other resources.
    * Possible values: score (no default)

  * requires: Conditions under which the resource can be started
    * Conditions under which the resource can be started. "nothing" means the cluster can always start this resource. "quorum" means the cluster can start this resource only if a majority of the configured nodes are active. "fencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced. "unfencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced, and only on nodes that have been unfenced. The default is "quorum" for resources with a class of stonith; otherwise, "unfencing" if unfencing is active in the cluster; otherwise, "fencing" if the fencing-enabled cluster option is true; otherwise, "quorum".
    * Possible values: "nothing", "quorum", "fencing", "unfencing"

  * migration-threshold: Number of failures on a node before the resource becomes ineligible to run there.
    * Number of failures that may occur for this resource on a node, before that node is marked ineligible to host this resource. A value of 0 indicates that this feature is disabled (the node will never be marked ineligible). By contrast, the cluster treats "INFINITY" (the default) as a very large but finite number. This option has an effect only if the failed operation specifies its on-fail attribute as "restart" (the default), and additionally for failed start operations, if the start-failure-is-fatal cluster property is set to false.
    * Possible values: score (default: )

  * failure-timeout: Number of seconds before acting as if a failure had not occurred
    * Number of seconds after a failed action for this resource before acting as if the failure had not occurred, and potentially allowing the resource back to the node on which it failed. A value of 0 indicates that this feature is disabled.
    * Possible values: duration (default: )

  * multiple-active: What to do if the cluster finds the resource active on more than one node
    * What to do if the cluster finds the resource active on more than one node. "block" means to mark the resource as unmanaged. "stop_only" means to stop all active instances of this resource and leave them stopped. "stop_start" means to stop all active instances of this resource and start the resource in one location only. "stop_unexpected" means to stop all active instances of this resource except where the resource should be active. (This should be used only when extra instances are not expected to disrupt existing instances, and the resource agent's monitor of an existing instance is capable of detecting any problems that could be caused. Note that any resources ordered after this one will still need to be restarted.)
    * Possible values: "block", "stop_only", "stop_start" (default), "stop_unexpected"

  * allow-migrate: Whether the cluster should try to "live migrate" this resource when it needs to be moved
    * Whether the cluster should try to "live migrate" this resource when it needs to be moved. The default is true for ocf:pacemaker:remote resources, and false otherwise.
    * Possible values: boolean (no default)

  * allow-unhealthy-nodes: Whether the resource should be allowed to run on a node even if the node's health score would otherwise prevent it
    * Possible values: boolean (default: )

  * container-attribute-target: Where to check user-defined node attributes
    * Whether to check user-defined node attributes on the physical host where a container is running or on the local node. This is usually set for a bundle resource and inherited by the bundle's primitive resource. A value of "host" means to check user-defined node attributes on the underlying physical host. Any other value means to check user-defined node attributes on the local node (for a bundled primitive resource, this is the bundle node).
    * Possible values: string (no default)

  * remote-node: Name of the Pacemaker Remote guest node this resource is associated with, if any
    * Name of the Pacemaker Remote guest node this resource is associated with, if any. If specified, this both enables the resource as a guest node and defines the unique name used to identify the guest node. The guest must be configured to run the Pacemaker Remote daemon when it is started. WARNING: This value cannot overlap with any resource or node IDs.
    * Possible values: string (no default)

  * remote-addr: If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote
    * If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote. The Pacemaker Remote daemon on the guest must be configured to accept connections on this address. The default is the value of the remote-node meta-attribute.
    * Possible values: string (no default)

  * remote-port: If remote-node is specified, port on the guest used for its Pacemaker Remote connection
    * If remote-node is specified, the port on the guest used for its Pacemaker Remote connection. The Pacemaker Remote daemon on the guest must be configured to listen on this port.
    * Possible values: port (default: )

  * remote-connect-timeout: If remote-node is specified, how long before a pending Pacemaker Remote guest connection times out.
    * Possible values: timeout (default: )

  * remote-allow-migrate: If remote-node is specified, this acts as the allow-migrate meta-attribute for the implicit remote connection resource (ocf:pacemaker:remote).
    * Possible values: boolean (default: )
=#=#=#= End test: List all available primitive meta-attributes - OK (0) =#=#=#=
* Passed: crm_resource          - List all available primitive meta-attributes
=#=#=#= Begin test: List all available primitive meta-attributes (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --list-options=primitive --all">
  <resource-agent name="primitive-meta" version="">
    <version>1.1</version>
    <longdesc lang="en">Meta-attributes applicable to primitive resources</longdesc>
    <shortdesc lang="en">Primitive meta-attributes</shortdesc>
    <parameters>
      <parameter name="priority" advanced="0" generated="0">
        <longdesc lang="en">If not all resources can be active, the cluster will stop lower-priority resources in order to keep higher-priority ones active.</longdesc>
        <shortdesc lang="en">Resource assignment priority</shortdesc>
        <content type="score" default=""/>
      </parameter>
      <parameter name="critical" advanced="0" generated="0">
        <longdesc lang="en">Use this value as the default for influence in all colocation constraints involving this resource, as well as in the implicit colocation constraints created if this resource is in a group.</longdesc>
        <shortdesc lang="en">Default value for influence in colocation constraints</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="target-role" advanced="0" generated="0">
        <longdesc lang="en">"Stopped" forces the resource to be stopped. "Started" allows the resource to be started (and in the case of promotable clone resources, promoted if appropriate). "Unpromoted" allows the resource to be started, but only in the unpromoted role if the resource is promotable. "Promoted" is equivalent to "Started".</longdesc>
        <shortdesc lang="en">State the cluster should attempt to keep this resource in</shortdesc>
        <content type="select" default="">
          <option value="Stopped"/>
          <option value="Started"/>
          <option value="Unpromoted"/>
          <option value="Promoted"/>
        </content>
      </parameter>
      <parameter name="is-managed" advanced="0" generated="0">
        <longdesc lang="en">If false, the cluster will not start, stop, promote, or demote the resource on any node. Recurring actions for the resource are unaffected. If true, a true value for the maintenance-mode cluster option, the maintenance node attribute, or the maintenance resource meta-attribute overrides this.</longdesc>
        <shortdesc lang="en">Whether the cluster is allowed to actively change the resource's state</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="maintenance" advanced="0" generated="0">
        <longdesc lang="en">If true, the cluster will not start, stop, promote, or demote the resource on any node, and will pause any recurring monitors (except those specifying role as "Stopped"). If false, a true value for the maintenance-mode cluster option or maintenance node attribute overrides this.</longdesc>
        <shortdesc lang="en">If true, the cluster will not schedule any actions involving the resource</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="resource-stickiness" advanced="0" generated="0">
        <longdesc lang="en">Score to add to the current node when a resource is already active. This allows running resources to stay where they are, even if they would be placed elsewhere if they were being started from a stopped state. The default is 1 for individual clone instances, and 0 for all other resources.</longdesc>
        <shortdesc lang="en">Score to add to the current node when a resource is already active</shortdesc>
        <content type="score"/>
      </parameter>
      <parameter name="requires" advanced="0" generated="0">
        <longdesc lang="en">Conditions under which the resource can be started. "nothing" means the cluster can always start this resource. "quorum" means the cluster can start this resource only if a majority of the configured nodes are active. "fencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced. "unfencing" means the cluster can start this resource only if a majority of the configured nodes are active and any failed or unknown nodes have been fenced, and only on nodes that have been unfenced. The default is "quorum" for resources with a class of stonith; otherwise, "unfencing" if unfencing is active in the cluster; otherwise, "fencing" if the fencing-enabled cluster option is true; otherwise, "quorum".</longdesc>
        <shortdesc lang="en">Conditions under which the resource can be started</shortdesc>
        <content type="select">
          <option value="nothing"/>
          <option value="quorum"/>
          <option value="fencing"/>
          <option value="unfencing"/>
        </content>
      </parameter>
      <parameter name="migration-threshold" advanced="0" generated="0">
        <longdesc lang="en">Number of failures that may occur for this resource on a node, before that node is marked ineligible to host this resource. A value of 0 indicates that this feature is disabled (the node will never be marked ineligible). By contrast, the cluster treats "INFINITY" (the default) as a very large but finite number. This option has an effect only if the failed operation specifies its on-fail attribute as "restart" (the default), and additionally for failed start operations, if the start-failure-is-fatal cluster property is set to false.</longdesc>
        <shortdesc lang="en">Number of failures on a node before the resource becomes ineligible to run there.</shortdesc>
        <content type="score" default=""/>
      </parameter>
      <parameter name="failure-timeout" advanced="0" generated="0">
        <longdesc lang="en">Number of seconds after a failed action for this resource before acting as if the failure had not occurred, and potentially allowing the resource back to the node on which it failed. A value of 0 indicates that this feature is disabled.</longdesc>
        <shortdesc lang="en">Number of seconds before acting as if a failure had not occurred</shortdesc>
        <content type="duration" default=""/>
      </parameter>
      <parameter name="multiple-active" advanced="0" generated="0">
        <longdesc lang="en">What to do if the cluster finds the resource active on more than one node. "block" means to mark the resource as unmanaged. "stop_only" means to stop all active instances of this resource and leave them stopped. "stop_start" means to stop all active instances of this resource and start the resource in one location only. "stop_unexpected" means to stop all active instances of this resource except where the resource should be active. (This should be used only when extra instances are not expected to disrupt existing instances, and the resource agent's monitor of an existing instance is capable of detecting any problems that could be caused. Note that any resources ordered after this one will still need to be restarted.)</longdesc>
        <shortdesc lang="en">What to do if the cluster finds the resource active on more than one node</shortdesc>
        <content type="select" default="">
          <option value="block"/>
          <option value="stop_only"/>
          <option value="stop_start"/>
          <option value="stop_unexpected"/>
        </content>
      </parameter>
      <parameter name="allow-migrate" advanced="0" generated="0">
        <longdesc lang="en">Whether the cluster should try to "live migrate" this resource when it needs to be moved. The default is true for ocf:pacemaker:remote resources, and false otherwise.</longdesc>
        <shortdesc lang="en">Whether the cluster should try to "live migrate" this resource when it needs to be moved</shortdesc>
        <content type="boolean"/>
      </parameter>
      <parameter name="allow-unhealthy-nodes" advanced="0" generated="0">
        <longdesc lang="en">Whether the resource should be allowed to run on a node even if the node's health score would otherwise prevent it</longdesc>
        <shortdesc lang="en">Whether the resource should be allowed to run on a node even if the node's health score would otherwise prevent it</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
      <parameter name="container-attribute-target" advanced="0" generated="0">
        <longdesc lang="en">Whether to check user-defined node attributes on the physical host where a container is running or on the local node. This is usually set for a bundle resource and inherited by the bundle's primitive resource. A value of "host" means to check user-defined node attributes on the underlying physical host. Any other value means to check user-defined node attributes on the local node (for a bundled primitive resource, this is the bundle node).</longdesc>
        <shortdesc lang="en">Where to check user-defined node attributes</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="remote-node" advanced="0" generated="0">
        <longdesc lang="en">Name of the Pacemaker Remote guest node this resource is associated with, if any. If specified, this both enables the resource as a guest node and defines the unique name used to identify the guest node. The guest must be configured to run the Pacemaker Remote daemon when it is started. WARNING: This value cannot overlap with any resource or node IDs.</longdesc>
        <shortdesc lang="en">Name of the Pacemaker Remote guest node this resource is associated with, if any</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="remote-addr" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote. The Pacemaker Remote daemon on the guest must be configured to accept connections on this address. The default is the value of the remote-node meta-attribute.</longdesc>
        <shortdesc lang="en">If remote-node is specified, the IP address or hostname used to connect to the guest via Pacemaker Remote</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="remote-port" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, the port on the guest used for its Pacemaker Remote connection. The Pacemaker Remote daemon on the guest must be configured to listen on this port.</longdesc>
        <shortdesc lang="en">If remote-node is specified, port on the guest used for its Pacemaker Remote connection</shortdesc>
        <content type="port" default=""/>
      </parameter>
      <parameter name="remote-connect-timeout" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, how long before a pending Pacemaker Remote guest connection times out.</longdesc>
        <shortdesc lang="en">If remote-node is specified, how long before a pending Pacemaker Remote guest connection times out.</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="remote-allow-migrate" advanced="0" generated="0">
        <longdesc lang="en">If remote-node is specified, this acts as the allow-migrate meta-attribute for the implicit remote connection resource (ocf:pacemaker:remote).</longdesc>
        <shortdesc lang="en">If remote-node is specified, this acts as the allow-migrate meta-attribute for the implicit remote connection resource (ocf:pacemaker:remote).</shortdesc>
        <content type="boolean" default=""/>
      </parameter>
    </parameters>
  </resource-agent>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List all available primitive meta-attributes (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List all available primitive meta-attributes (XML)
=#=#=#= Begin test: List non-advanced fencing parameters =#=#=#=
Fencing resource common parameters

Special parameters that are available for all fencing resources, regardless of type. They are processed by Pacemaker, rather than by the fence agent or the fencing library.

  * pcmk_host_map: A mapping of node names to port numbers for devices that do not support node names.
    * For example, "node1:1;node2:2,3" would tell the cluster to use port 1 for node1 and ports 2 and 3 for node2.
    * Possible values: string (no default)

  * pcmk_host_list: Nodes targeted by this device
    * Comma-separated list of nodes that can be targeted by this device (for example, "node1,node2,node3"). If pcmk_host_check is "static-list", either this or pcmk_host_map must be set.
    * Possible values: string (no default)

  * pcmk_host_check: How to determine which nodes can be targeted by the device
    * Use "dynamic-list" to query the device via the 'list' command; "static-list" to check the pcmk_host_list attribute; "status" to query the device via the 'status' command; or "none" to assume every device can fence every node. The default value is "static-list" if pcmk_host_map or pcmk_host_list is set; otherwise "dynamic-list" if the device supports the list operation; otherwise "status" if the device supports the status operation; otherwise "none"
    * Possible values: "dynamic-list", "static-list", "status", "none"

  * pcmk_delay_max: Enable a delay of no more than the time specified before executing fencing actions.
    * Enable a delay of no more than the time specified before executing fencing actions. Pacemaker derives the overall delay by taking the value of pcmk_delay_base and adding a random delay value such that the sum is kept below this maximum.
    * Possible values: duration (default: )

  * pcmk_delay_base: Enable a base delay for fencing actions and specify base delay value.
    * This enables a static delay for fencing actions, which can help avoid "death matches" where two nodes try to fence each other at the same time. If pcmk_delay_max is also used, a random delay will be added such that the total delay is kept below that value. This can be set to a single time value to apply to any node targeted by this device (useful if a separate device is configured for each target), or to a node map (for example, "node1:1s;node2:5") to set a different value for each target.
    * Possible values: string (default: )

  * pcmk_action_limit: The maximum number of actions can be performed in parallel on this device
    * If the concurrent-fencing cluster property is "true", this specifies the maximum number of actions that can be performed in parallel on this device. A value of -1 means unlimited.
    * Possible values: integer (default: )
=#=#=#= End test: List non-advanced fencing parameters - OK (0) =#=#=#=
* Passed: crm_resource          - List non-advanced fencing parameters
=#=#=#= Begin test: List non-advanced fencing parameters (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --list-options=fencing">
  <resource-agent name="fence-attributes" version="">
    <version>1.1</version>
    <longdesc lang="en">Special parameters that are available for all fencing resources, regardless of type. They are processed by Pacemaker, rather than by the fence agent or the fencing library.</longdesc>
    <shortdesc lang="en">Fencing resource common parameters</shortdesc>
    <parameters>
      <parameter name="pcmk_host_argument" advanced="1" generated="0">
        <longdesc lang="en">If the fencing agent metadata advertises support for the "port" or "plug" parameter, that will be used as the default, otherwise "none" will be used, which tells the cluster not to supply any additional parameters.</longdesc>
        <shortdesc lang="en">Name of agent parameter that should be set to the fencing target</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="pcmk_host_map" advanced="0" generated="0">
        <longdesc lang="en">For example, "node1:1;node2:2,3" would tell the cluster to use port 1 for node1 and ports 2 and 3 for node2.</longdesc>
        <shortdesc lang="en">A mapping of node names to port numbers for devices that do not support node names.</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="pcmk_host_list" advanced="0" generated="0">
        <longdesc lang="en">Comma-separated list of nodes that can be targeted by this device (for example, "node1,node2,node3"). If pcmk_host_check is "static-list", either this or pcmk_host_map must be set.</longdesc>
        <shortdesc lang="en">Nodes targeted by this device</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="pcmk_host_check" advanced="0" generated="0">
        <longdesc lang="en">Use "dynamic-list" to query the device via the 'list' command; "static-list" to check the pcmk_host_list attribute; "status" to query the device via the 'status' command; or "none" to assume every device can fence every node. The default value is "static-list" if pcmk_host_map or pcmk_host_list is set; otherwise "dynamic-list" if the device supports the list operation; otherwise "status" if the device supports the status operation; otherwise "none"</longdesc>
        <shortdesc lang="en">How to determine which nodes can be targeted by the device</shortdesc>
        <content type="select">
          <option value="dynamic-list"/>
          <option value="static-list"/>
          <option value="status"/>
          <option value="none"/>
        </content>
      </parameter>
      <parameter name="pcmk_delay_max" advanced="0" generated="0">
        <longdesc lang="en">Enable a delay of no more than the time specified before executing fencing actions. Pacemaker derives the overall delay by taking the value of pcmk_delay_base and adding a random delay value such that the sum is kept below this maximum.</longdesc>
        <shortdesc lang="en">Enable a delay of no more than the time specified before executing fencing actions.</shortdesc>
        <content type="duration" default=""/>
      </parameter>
      <parameter name="pcmk_delay_base" advanced="0" generated="0">
        <longdesc lang="en">This enables a static delay for fencing actions, which can help avoid "death matches" where two nodes try to fence each other at the same time. If pcmk_delay_max is also used, a random delay will be added such that the total delay is kept below that value. This can be set to a single time value to apply to any node targeted by this device (useful if a separate device is configured for each target), or to a node map (for example, "node1:1s;node2:5") to set a different value for each target.</longdesc>
        <shortdesc lang="en">Enable a base delay for fencing actions and specify base delay value.</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_action_limit" advanced="0" generated="0">
        <longdesc lang="en">If the concurrent-fencing cluster property is "true", this specifies the maximum number of actions that can be performed in parallel on this device. A value of -1 means unlimited.</longdesc>
        <shortdesc lang="en">The maximum number of actions can be performed in parallel on this device</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_reboot_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'reboot' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'reboot'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_reboot_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'reboot' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'reboot' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_reboot_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'reboot' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'reboot' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_off_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'off' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'off'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_off_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'off' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'off' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_off_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'off' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'off' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_on_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'on' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'on'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_on_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'on' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'on' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_on_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'on' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'on' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_list_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'list' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'list'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_list_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'list' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'list' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_list_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'list' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'list' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_monitor_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'monitor' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'monitor'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_monitor_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'monitor' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'monitor' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_monitor_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'monitor' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'monitor' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_status_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'status' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'status'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_status_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'status' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'status' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_status_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'status' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'status' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
    </parameters>
  </resource-agent>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List non-advanced fencing parameters (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List non-advanced fencing parameters (XML)
=#=#=#= Begin test: List all available fencing parameters =#=#=#=
Fencing resource common parameters

Special parameters that are available for all fencing resources, regardless of type. They are processed by Pacemaker, rather than by the fence agent or the fencing library.

  * pcmk_host_map: A mapping of node names to port numbers for devices that do not support node names.
    * For example, "node1:1;node2:2,3" would tell the cluster to use port 1 for node1 and ports 2 and 3 for node2.
    * Possible values: string (no default)

  * pcmk_host_list: Nodes targeted by this device
    * Comma-separated list of nodes that can be targeted by this device (for example, "node1,node2,node3"). If pcmk_host_check is "static-list", either this or pcmk_host_map must be set.
    * Possible values: string (no default)

  * pcmk_host_check: How to determine which nodes can be targeted by the device
    * Use "dynamic-list" to query the device via the 'list' command; "static-list" to check the pcmk_host_list attribute; "status" to query the device via the 'status' command; or "none" to assume every device can fence every node. The default value is "static-list" if pcmk_host_map or pcmk_host_list is set; otherwise "dynamic-list" if the device supports the list operation; otherwise "status" if the device supports the status operation; otherwise "none"
    * Possible values: "dynamic-list", "static-list", "status", "none"

  * pcmk_delay_max: Enable a delay of no more than the time specified before executing fencing actions.
    * Enable a delay of no more than the time specified before executing fencing actions. Pacemaker derives the overall delay by taking the value of pcmk_delay_base and adding a random delay value such that the sum is kept below this maximum.
    * Possible values: duration (default: )

  * pcmk_delay_base: Enable a base delay for fencing actions and specify base delay value.
    * This enables a static delay for fencing actions, which can help avoid "death matches" where two nodes try to fence each other at the same time. If pcmk_delay_max is also used, a random delay will be added such that the total delay is kept below that value. This can be set to a single time value to apply to any node targeted by this device (useful if a separate device is configured for each target), or to a node map (for example, "node1:1s;node2:5") to set a different value for each target.
    * Possible values: string (default: )

  * pcmk_action_limit: The maximum number of actions can be performed in parallel on this device
    * If the concurrent-fencing cluster property is "true", this specifies the maximum number of actions that can be performed in parallel on this device. A value of -1 means unlimited.
    * Possible values: integer (default: )

  * ADVANCED OPTIONS:

    * pcmk_host_argument: Name of agent parameter that should be set to the fencing target
      * If the fencing agent metadata advertises support for the "port" or "plug" parameter, that will be used as the default, otherwise "none" will be used, which tells the cluster not to supply any additional parameters.
      * Possible values: string (no default)

    * pcmk_reboot_action: An alternate command to run instead of 'reboot'
      * Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'reboot' action.
      * Possible values: string (default: )

    * pcmk_reboot_timeout: Specify an alternate timeout to use for 'reboot' actions instead of fencing-timeout
      * Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'reboot' actions.
      * Possible values: timeout (default: )

    * pcmk_reboot_retries: The maximum number of times to try the 'reboot' command within the timeout period
      * Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'reboot' action before giving up.
      * Possible values: integer (default: )

    * pcmk_off_action: An alternate command to run instead of 'off'
      * Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'off' action.
      * Possible values: string (default: )

    * pcmk_off_timeout: Specify an alternate timeout to use for 'off' actions instead of fencing-timeout
      * Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'off' actions.
      * Possible values: timeout (default: )

    * pcmk_off_retries: The maximum number of times to try the 'off' command within the timeout period
      * Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'off' action before giving up.
      * Possible values: integer (default: )

    * pcmk_on_action: An alternate command to run instead of 'on'
      * Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'on' action.
      * Possible values: string (default: )

    * pcmk_on_timeout: Specify an alternate timeout to use for 'on' actions instead of fencing-timeout
      * Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'on' actions.
      * Possible values: timeout (default: )

    * pcmk_on_retries: The maximum number of times to try the 'on' command within the timeout period
      * Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'on' action before giving up.
      * Possible values: integer (default: )

    * pcmk_list_action: An alternate command to run instead of 'list'
      * Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'list' action.
      * Possible values: string (default: )

    * pcmk_list_timeout: Specify an alternate timeout to use for 'list' actions instead of fencing-timeout
      * Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'list' actions.
      * Possible values: timeout (default: )

    * pcmk_list_retries: The maximum number of times to try the 'list' command within the timeout period
      * Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'list' action before giving up.
      * Possible values: integer (default: )

    * pcmk_monitor_action: An alternate command to run instead of 'monitor'
      * Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'monitor' action.
      * Possible values: string (default: )

    * pcmk_monitor_timeout: Specify an alternate timeout to use for 'monitor' actions instead of fencing-timeout
      * Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'monitor' actions.
      * Possible values: timeout (default: )

    * pcmk_monitor_retries: The maximum number of times to try the 'monitor' command within the timeout period
      * Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'monitor' action before giving up.
      * Possible values: integer (default: )

    * pcmk_status_action: An alternate command to run instead of 'status'
      * Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'status' action.
      * Possible values: string (default: )

    * pcmk_status_timeout: Specify an alternate timeout to use for 'status' actions instead of fencing-timeout
      * Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'status' actions.
      * Possible values: timeout (default: )

    * pcmk_status_retries: The maximum number of times to try the 'status' command within the timeout period
      * Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'status' action before giving up.
      * Possible values: integer (default: )
=#=#=#= End test: List all available fencing parameters - OK (0) =#=#=#=
* Passed: crm_resource          - List all available fencing parameters
=#=#=#= Begin test: List all available fencing parameters (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --list-options=fencing --all">
  <resource-agent name="fence-attributes" version="">
    <version>1.1</version>
    <longdesc lang="en">Special parameters that are available for all fencing resources, regardless of type. They are processed by Pacemaker, rather than by the fence agent or the fencing library.</longdesc>
    <shortdesc lang="en">Fencing resource common parameters</shortdesc>
    <parameters>
      <parameter name="pcmk_host_argument" advanced="1" generated="0">
        <longdesc lang="en">If the fencing agent metadata advertises support for the "port" or "plug" parameter, that will be used as the default, otherwise "none" will be used, which tells the cluster not to supply any additional parameters.</longdesc>
        <shortdesc lang="en">Name of agent parameter that should be set to the fencing target</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="pcmk_host_map" advanced="0" generated="0">
        <longdesc lang="en">For example, "node1:1;node2:2,3" would tell the cluster to use port 1 for node1 and ports 2 and 3 for node2.</longdesc>
        <shortdesc lang="en">A mapping of node names to port numbers for devices that do not support node names.</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="pcmk_host_list" advanced="0" generated="0">
        <longdesc lang="en">Comma-separated list of nodes that can be targeted by this device (for example, "node1,node2,node3"). If pcmk_host_check is "static-list", either this or pcmk_host_map must be set.</longdesc>
        <shortdesc lang="en">Nodes targeted by this device</shortdesc>
        <content type="string"/>
      </parameter>
      <parameter name="pcmk_host_check" advanced="0" generated="0">
        <longdesc lang="en">Use "dynamic-list" to query the device via the 'list' command; "static-list" to check the pcmk_host_list attribute; "status" to query the device via the 'status' command; or "none" to assume every device can fence every node. The default value is "static-list" if pcmk_host_map or pcmk_host_list is set; otherwise "dynamic-list" if the device supports the list operation; otherwise "status" if the device supports the status operation; otherwise "none"</longdesc>
        <shortdesc lang="en">How to determine which nodes can be targeted by the device</shortdesc>
        <content type="select">
          <option value="dynamic-list"/>
          <option value="static-list"/>
          <option value="status"/>
          <option value="none"/>
        </content>
      </parameter>
      <parameter name="pcmk_delay_max" advanced="0" generated="0">
        <longdesc lang="en">Enable a delay of no more than the time specified before executing fencing actions. Pacemaker derives the overall delay by taking the value of pcmk_delay_base and adding a random delay value such that the sum is kept below this maximum.</longdesc>
        <shortdesc lang="en">Enable a delay of no more than the time specified before executing fencing actions.</shortdesc>
        <content type="duration" default=""/>
      </parameter>
      <parameter name="pcmk_delay_base" advanced="0" generated="0">
        <longdesc lang="en">This enables a static delay for fencing actions, which can help avoid "death matches" where two nodes try to fence each other at the same time. If pcmk_delay_max is also used, a random delay will be added such that the total delay is kept below that value. This can be set to a single time value to apply to any node targeted by this device (useful if a separate device is configured for each target), or to a node map (for example, "node1:1s;node2:5") to set a different value for each target.</longdesc>
        <shortdesc lang="en">Enable a base delay for fencing actions and specify base delay value.</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_action_limit" advanced="0" generated="0">
        <longdesc lang="en">If the concurrent-fencing cluster property is "true", this specifies the maximum number of actions that can be performed in parallel on this device. A value of -1 means unlimited.</longdesc>
        <shortdesc lang="en">The maximum number of actions can be performed in parallel on this device</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_reboot_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'reboot' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'reboot'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_reboot_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'reboot' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'reboot' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_reboot_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'reboot' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'reboot' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_off_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'off' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'off'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_off_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'off' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'off' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_off_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'off' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'off' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_on_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'on' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'on'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_on_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'on' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'on' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_on_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'on' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'on' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_list_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'list' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'list'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_list_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'list' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'list' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_list_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'list' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'list' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_monitor_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'monitor' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'monitor'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_monitor_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'monitor' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'monitor' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_monitor_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'monitor' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'monitor' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
      <parameter name="pcmk_status_action" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support the standard commands or may provide additional ones. Use this to specify an alternate, device-specific, command that implements the 'status' action.</longdesc>
        <shortdesc lang="en">An alternate command to run instead of 'status'</shortdesc>
        <content type="string" default=""/>
      </parameter>
      <parameter name="pcmk_status_timeout" advanced="1" generated="0">
        <longdesc lang="en">Some devices need much more/less time to complete than normal. Use this to specify an alternate, device-specific, timeout for 'status' actions.</longdesc>
        <shortdesc lang="en">Specify an alternate timeout to use for 'status' actions instead of fencing-timeout</shortdesc>
        <content type="timeout" default=""/>
      </parameter>
      <parameter name="pcmk_status_retries" advanced="1" generated="0">
        <longdesc lang="en">Some devices do not support multiple connections. Operations may "fail" if the device is busy with another task. In that case, Pacemaker will automatically retry the operation if there is time remaining. Use this option to alter the number of times Pacemaker tries a 'status' action before giving up.</longdesc>
        <shortdesc lang="en">The maximum number of times to try the 'status' command within the timeout period</shortdesc>
        <content type="integer" default=""/>
      </parameter>
    </parameters>
  </resource-agent>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List all available fencing parameters (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List all available fencing parameters (XML)
=#=#=#= Begin test: Create a resource =#=#=#=
=#=#=#= Current cib after: Create a resource =#=#=#=
<cib admin_epoch="0" epoch="4" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy"/>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Create a resource - OK (0) =#=#=#=
* Passed: cibadmin              - Create a resource
=#=#=#= Begin test: crm_resource given both -r and resource config =#=#=#=
crm_resource: --class, --agent, and --provider cannot be used with -r/--resource
=#=#=#= End test: crm_resource given both -r and resource config - Incorrect usage (64) =#=#=#=
* Passed: crm_resource          - crm_resource given both -r and resource config
=#=#=#= Begin test: crm_resource given resource config with invalid action =#=#=#=
crm_resource: --class, --agent, and --provider can only be used with --validate and --force-*
=#=#=#= End test: crm_resource given resource config with invalid action - Incorrect usage (64) =#=#=#=
* Passed: crm_resource          - crm_resource given resource config with invalid action
=#=#=#= Begin test: Create a resource meta attribute =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Set 'dummy' option: id=dummy-meta_attributes-is-managed set=dummy-meta_attributes name=is-managed value=false
=#=#=#= Current cib after: Create a resource meta attribute =#=#=#=
<cib admin_epoch="0" epoch="5" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes">
          <nvpair id="dummy-meta_attributes-is-managed" name="is-managed" value="false"/>
        </meta_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Create a resource meta attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute
=#=#=#= Begin test: Query a resource meta attribute =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
false
=#=#=#= Current cib after: Query a resource meta attribute =#=#=#=
<cib admin_epoch="0" epoch="5" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes">
          <nvpair id="dummy-meta_attributes-is-managed" name="is-managed" value="false"/>
        </meta_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Query a resource meta attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Query a resource meta attribute
=#=#=#= Begin test: Remove a resource meta attribute =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Deleted 'dummy' option: id=dummy-meta_attributes-is-managed name=is-managed
=#=#=#= Current cib after: Remove a resource meta attribute =#=#=#=
<cib admin_epoch="0" epoch="6" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Remove a resource meta attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Remove a resource meta attribute
=#=#=#= Begin test: Create another resource meta attribute (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy --meta -p target-role -v Stopped --output-as=xml">
  <resource-settings>
    <primitive id="dummy">
      <meta_attributes id="dummy-meta_attributes">
        <nvpair id="dummy-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
  </resource-settings>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Create another resource meta attribute (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Create another resource meta attribute (XML)
=#=#=#= Begin test: Show why a resource is not running (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -Y -r dummy --output-as=xml">
  <reason running="false">
    <check id="dummy" remain_stopped="true"/>
  </reason>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Show why a resource is not running (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Show why a resource is not running (XML)
=#=#=#= Begin test: Remove another resource meta attribute (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy --meta -d target-role --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Remove another resource meta attribute (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Remove another resource meta attribute (XML)
=#=#=#= Begin test: Get a non-existent attribute from a resource element (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy --get-parameter nonexistent --element --output-as=xml">
  <status code="0" message="OK">
    <errors>
      <error>Attribute 'nonexistent' not found for 'dummy'</error>
    </errors>
  </status>
</pacemaker-result>
=#=#=#= End test: Get a non-existent attribute from a resource element (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Get a non-existent attribute from a resource element (XML)
=#=#=#= Begin test: Get a non-existent attribute from a resource element =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Attribute 'nonexistent' not found for 'dummy'
=#=#=#= Current cib after: Get a non-existent attribute from a resource element =#=#=#=
<cib admin_epoch="0" epoch="8" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Get a non-existent attribute from a resource element - OK (0) =#=#=#=
* Passed: crm_resource          - Get a non-existent attribute from a resource element
=#=#=#= Begin test: Get a non-existent attribute from a resource element (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -r dummy --get-parameter nonexistent --element">
  <status code="0" message="OK">
    <errors>
      <error>Attribute 'nonexistent' not found for 'dummy'</error>
    </errors>
  </status>
</pacemaker-result>
=#=#=#= Current cib after: Get a non-existent attribute from a resource element (XML) =#=#=#=
<cib admin_epoch="0" epoch="8" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Get a non-existent attribute from a resource element (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Get a non-existent attribute from a resource element (XML)
=#=#=#= Begin test: Get an existent attribute from a resource element =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
ocf
=#=#=#= Current cib after: Get an existent attribute from a resource element =#=#=#=
<cib admin_epoch="0" epoch="8" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Get an existent attribute from a resource element - OK (0) =#=#=#=
* Passed: crm_resource          - Get an existent attribute from a resource element
=#=#=#= Begin test: Set a non-existent attribute for a resource element (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy --set-parameter=description -v test_description --element --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: Set a non-existent attribute for a resource element (XML) =#=#=#=
<cib admin_epoch="0" epoch="9" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy" description="test_description">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Set a non-existent attribute for a resource element (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Set a non-existent attribute for a resource element (XML)
=#=#=#= Begin test: Set an existent attribute for a resource element (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy --set-parameter=description -v test_description --element --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: Set an existent attribute for a resource element (XML) =#=#=#=
<cib admin_epoch="0" epoch="10" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy" description="test_description">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Set an existent attribute for a resource element (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Set an existent attribute for a resource element (XML)
=#=#=#= Begin test: Delete an existent attribute for a resource element (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy -d description --element --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: Delete an existent attribute for a resource element (XML) =#=#=#=
<cib admin_epoch="0" epoch="11" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Delete an existent attribute for a resource element (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Delete an existent attribute for a resource element (XML)
=#=#=#= Begin test: Delete a non-existent attribute for a resource element (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource -r dummy -d description --element --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: Delete a non-existent attribute for a resource element (XML) =#=#=#=
<cib admin_epoch="0" epoch="12" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Delete a non-existent attribute for a resource element (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Delete a non-existent attribute for a resource element (XML)
=#=#=#= Begin test: Set a non-existent attribute for a resource element =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Set attribute: name=description value=test_description
=#=#=#= Current cib after: Set a non-existent attribute for a resource element =#=#=#=
<cib admin_epoch="0" epoch="13" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy" description="test_description">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Set a non-existent attribute for a resource element - OK (0) =#=#=#=
* Passed: crm_resource          - Set a non-existent attribute for a resource element
=#=#=#= Begin test: Set an existent attribute for a resource element =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Set attribute: name=description value=test_description
=#=#=#= Current cib after: Set an existent attribute for a resource element =#=#=#=
<cib admin_epoch="0" epoch="14" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy" description="test_description">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Set an existent attribute for a resource element - OK (0) =#=#=#=
* Passed: crm_resource          - Set an existent attribute for a resource element
=#=#=#= Begin test: Delete an existent attribute for a resource element =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Deleted attribute: description
=#=#=#= Current cib after: Delete an existent attribute for a resource element =#=#=#=
<cib admin_epoch="0" epoch="15" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Delete an existent attribute for a resource element - OK (0) =#=#=#=
* Passed: crm_resource          - Delete an existent attribute for a resource element
=#=#=#= Begin test: Delete a non-existent attribute for a resource element =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Deleted attribute: description
=#=#=#= Current cib after: Delete a non-existent attribute for a resource element =#=#=#=
<cib admin_epoch="0" epoch="16" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Delete a non-existent attribute for a resource element - OK (0) =#=#=#=
* Passed: crm_resource          - Delete a non-existent attribute for a resource element
=#=#=#= Begin test: Create a resource attribute =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Set 'dummy' option: id=dummy-instance_attributes-delay set=dummy-instance_attributes name=delay value=10s
=#=#=#= Current cib after: Create a resource attribute =#=#=#=
<cib admin_epoch="0" epoch="17" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Create a resource attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource attribute
=#=#=#= Begin test: List the configured resources =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Full List of Resources:
  * dummy	(ocf:pacemaker:Dummy):	 Stopped
=#=#=#= Current cib after: List the configured resources =#=#=#=
<cib admin_epoch="0" epoch="17" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: List the configured resources - OK (0) =#=#=#=
* Passed: crm_resource          - List the configured resources
=#=#=#= Begin test: List the configured resources (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -L">
  <resources>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Stopped" active="false" orphaned="false" removed="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
  </resources>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: List the configured resources (XML) =#=#=#=
<cib admin_epoch="0" epoch="17" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: List the configured resources (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List the configured resources (XML)
=#=#=#= Begin test: Implicitly list the configured resources =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
Full List of Resources:
  * dummy	(ocf:pacemaker:Dummy):	 Stopped
=#=#=#= End test: Implicitly list the configured resources - OK (0) =#=#=#=
* Passed: crm_resource          - Implicitly list the configured resources
=#=#=#= Begin test: List IDs of instantiated resources =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
dummy
=#=#=#= End test: List IDs of instantiated resources - OK (0) =#=#=#=
* Passed: crm_resource          - List IDs of instantiated resources
=#=#=#= Begin test: Show XML configuration of resource =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
dummy	(ocf:pacemaker:Dummy):	 Stopped
Resource XML:
<primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
  <meta_attributes id="dummy-meta_attributes"/>
  <instance_attributes id="dummy-instance_attributes">
    <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
  </instance_attributes>
</primitive>
=#=#=#= End test: Show XML configuration of resource - OK (0) =#=#=#=
* Passed: crm_resource          - Show XML configuration of resource
=#=#=#= Begin test: Show XML configuration of resource (XML) =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -q -r dummy">
  <resource_config>
    <resource id="dummy" resource_agent="ocf:pacemaker:Dummy" role="Stopped" active="false" orphaned="false" removed="false" blocked="false" maintenance="false" managed="true" failed="false" failure_ignored="false" nodes_running_on="0"/>
    <xml><![CDATA[<primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
  <meta_attributes id="dummy-meta_attributes"/>
  <instance_attributes id="dummy-instance_attributes">
    <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
  </instance_attributes>
</primitive>
]]></xml>
  </resource_config>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Show XML configuration of resource (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Show XML configuration of resource (XML)
=#=#=#= Begin test: Require a destination when migrating a resource that is stopped =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
crm_resource: Resource 'dummy' not moved: active in 0 locations.
To prevent 'dummy' from running on a specific location, specify a node.
=#=#=#= Current cib after: Require a destination when migrating a resource that is stopped =#=#=#=
<cib admin_epoch="0" epoch="17" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Require a destination when migrating a resource that is stopped - Incorrect usage (64) =#=#=#=
* Passed: crm_resource          - Require a destination when migrating a resource that is stopped
=#=#=#= Begin test: Don't support migration to non-existent locations =#=#=#=
unpack_resources 	error: Resource start-up disabled since no fencing resources have been defined. Either configure some or disable fencing with the fencing-enabled option. NOTE: Clusters with shared data need fencing to ensure data integrity.
crm_resource: Node 'i.do.not.exist' not found
Error performing operation: No such object
=#=#=#= Current cib after: Don't support migration to non-existent locations =#=#=#=
<cib admin_epoch="0" epoch="17" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Don't support migration to non-existent locations - No such object (105) =#=#=#=
* Passed: crm_resource          - Don't support migration to non-existent locations
=#=#=#= Begin test: Create a fencing resource =#=#=#=
=#=#=#= Current cib after: Create a fencing resource =#=#=#=
<cib admin_epoch="0" epoch="18" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate"/>
  </status>
</cib>
=#=#=#= End test: Create a fencing resource - OK (0) =#=#=#=
* Passed: cibadmin              - Create a fencing resource
=#=#=#= Begin test: Bring resources online =#=#=#=
Current cluster status:
  * Node List:
    * Online: [ node1 ]

  * Full List of Resources:
    * dummy	(ocf:pacemaker:Dummy):	 Stopped
    * Fence	(stonith:fence_true):	 Stopped

Transition Summary:
  * Start      dummy   ( node1 )
  * Start      Fence   ( node1 )

Executing Cluster Transition:
  * Resource action: dummy           monitor on node1
  * Resource action: Fence           monitor on node1
  * Resource action: dummy           start on node1
  * Resource action: Fence           start on node1

Revised Cluster Status:
  * Node List:
    * Online: [ node1 ]

  * Full List of Resources:
    * dummy	(ocf:pacemaker:Dummy):	 Started node1
    * Fence	(stonith:fence_true):	 Started node1
=#=#=#= Current cib after: Bring resources online =#=#=#=
<cib admin_epoch="0" epoch="18" num_updates="4">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Bring resources online - OK (0) =#=#=#=
* Passed: crm_simulate          - Bring resources online
=#=#=#= Begin test: Try to move a resource to its existing location =#=#=#=
crm_resource: Error performing operation: Requested item already exists
=#=#=#= Current cib after: Try to move a resource to its existing location =#=#=#=
<cib admin_epoch="0" epoch="18" num_updates="4">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Try to move a resource to its existing location - Requested item already exists (108) =#=#=#=
* Passed: crm_resource          - Try to move a resource to its existing location
=#=#=#= Begin test: Try to move a resource that doesn't exist =#=#=#=
crm_resource: Resource 'xyz' not found
Error performing operation: No such object
=#=#=#= End test: Try to move a resource that doesn't exist - No such object (105) =#=#=#=
* Passed: crm_resource          - Try to move a resource that doesn't exist
=#=#=#= Begin test: Move a resource from its existing location =#=#=#=
WARNING: Creating rsc_location constraint 'cli-ban-dummy-on-node1' with a score of -INFINITY for resource dummy on node1.
	This will prevent dummy from running on node1 until the constraint is removed using the clear option or by editing the CIB with an appropriate tool.
	This will be the case even if node1 is the last node in the cluster
=#=#=#= Current cib after: Move a resource from its existing location =#=#=#=
<cib admin_epoch="0" epoch="19" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints>
      <rsc_location id="cli-ban-dummy-on-node1" rsc="dummy" role="Started" node="node1" score="-INFINITY"/>
    </constraints>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Move a resource from its existing location - OK (0) =#=#=#=
* Passed: crm_resource          - Move a resource from its existing location
=#=#=#= Begin test: Clear out constraints generated by --move =#=#=#=
Removing constraint: cli-ban-dummy-on-node1
=#=#=#= Current cib after: Clear out constraints generated by --move =#=#=#=
<cib admin_epoch="0" epoch="20" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Clear out constraints generated by --move - OK (0) =#=#=#=
* Passed: crm_resource          - Clear out constraints generated by --move
=#=#=#= Begin test: Ban a resource on unknown node =#=#=#=
crm_resource: Node 'host1' not found
Error performing operation: No such object
=#=#=#= End test: Ban a resource on unknown node - No such object (105) =#=#=#=
* Passed: crm_resource          - Ban a resource on unknown node
=#=#=#= Begin test: Create two more nodes and bring them online =#=#=#=
Current cluster status:
  * Node List:
    * Online: [ node1 ]

  * Full List of Resources:
    * dummy	(ocf:pacemaker:Dummy):	 Started node1
    * Fence	(stonith:fence_true):	 Started node1

Performing Requested Modifications:
  * Bringing node node2 online
  * Bringing node node3 online

Transition Summary:
  * Move       Fence   ( node1 -> node2 )

Executing Cluster Transition:
  * Resource action: dummy           monitor on node3
  * Resource action: dummy           monitor on node2
  * Resource action: Fence           stop on node1
  * Resource action: Fence           monitor on node3
  * Resource action: Fence           monitor on node2
  * Resource action: Fence           start on node2

Revised Cluster Status:
  * Node List:
    * Online: [ node1 node2 node3 ]

  * Full List of Resources:
    * dummy	(ocf:pacemaker:Dummy):	 Started node1
    * Fence	(stonith:fence_true):	 Started node2
=#=#=#= Current cib after: Create two more nodes and bring them online =#=#=#=
<cib admin_epoch="0" epoch="22" num_updates="8">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints/>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node2" uname="node2" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node2">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node3" uname="node3" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node3">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Create two more nodes and bring them online - OK (0) =#=#=#=
* Passed: crm_simulate          - Create two more nodes and bring them online
=#=#=#= Begin test: Ban dummy from node1 =#=#=#=
WARNING: Creating rsc_location constraint 'cli-ban-dummy-on-node1' with a score of -INFINITY for resource dummy on node1.
	This will prevent dummy from running on node1 until the constraint is removed using the clear option or by editing the CIB with an appropriate tool.
	This will be the case even if node1 is the last node in the cluster
=#=#=#= Current cib after: Ban dummy from node1 =#=#=#=
<cib admin_epoch="0" epoch="23" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints>
      <rsc_location id="cli-ban-dummy-on-node1" rsc="dummy" role="Started" node="node1" score="-INFINITY"/>
    </constraints>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node2" uname="node2" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node2">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node3" uname="node3" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node3">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Ban dummy from node1 - OK (0) =#=#=#=
* Passed: crm_resource          - Ban dummy from node1
=#=#=#= Begin test: Show where a resource is running =#=#=#=
resource dummy is running on: node1
=#=#=#= End test: Show where a resource is running - OK (0) =#=#=#=
* Passed: crm_resource          - Show where a resource is running
=#=#=#= Begin test: Show constraints on a resource =#=#=#=
Locations:
  * Node node1 (score=-INFINITY, id=cli-ban-dummy-on-node1, rsc=dummy)
=#=#=#= End test: Show constraints on a resource - OK (0) =#=#=#=
* Passed: crm_resource          - Show constraints on a resource
=#=#=#= Begin test: Ban dummy from node2 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource -r dummy -B -N node2 --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: Ban dummy from node2 (XML) =#=#=#=
<cib admin_epoch="0" epoch="24" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints>
      <rsc_location id="cli-ban-dummy-on-node1" rsc="dummy" role="Started" node="node1" score="-INFINITY"/>
      <rsc_location id="cli-ban-dummy-on-node2" rsc="dummy" role="Started" node="node2" score="-INFINITY"/>
    </constraints>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node2" uname="node2" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node2">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node3" uname="node3" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node3">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Ban dummy from node2 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Ban dummy from node2 (XML)
=#=#=#= Begin test: Relocate resources due to ban =#=#=#=
Current cluster status:
  * Node List:
    * Online: [ node1 node2 node3 ]

  * Full List of Resources:
    * dummy	(ocf:pacemaker:Dummy):	 Started node1
    * Fence	(stonith:fence_true):	 Started node2

Transition Summary:
  * Move       dummy   ( node1 -> node3 )

Executing Cluster Transition:
  * Resource action: dummy           stop on node1
  * Resource action: dummy           start on node3

Revised Cluster Status:
  * Node List:
    * Online: [ node1 node2 node3 ]

  * Full List of Resources:
    * dummy	(ocf:pacemaker:Dummy):	 Started node3
    * Fence	(stonith:fence_true):	 Started node2
=#=#=#= Current cib after: Relocate resources due to ban =#=#=#=
<cib admin_epoch="0" epoch="24" num_updates="2">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints>
      <rsc_location id="cli-ban-dummy-on-node1" rsc="dummy" role="Started" node="node1" score="-INFINITY"/>
      <rsc_location id="cli-ban-dummy-on-node2" rsc="dummy" role="Started" node="node2" score="-INFINITY"/>
    </constraints>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node2" uname="node2" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node2">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node3" uname="node3" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node3">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Relocate resources due to ban - OK (0) =#=#=#=
* Passed: crm_simulate          - Relocate resources due to ban
=#=#=#= Begin test: Move dummy to node1 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource -r dummy -M -N node1 --output-as=xml">
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= Current cib after: Move dummy to node1 (XML) =#=#=#=
<cib admin_epoch="0" epoch="26" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints>
      <rsc_location id="cli-ban-dummy-on-node2" rsc="dummy" role="Started" node="node2" score="-INFINITY"/>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node2" uname="node2" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node2">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node3" uname="node3" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node3">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Move dummy to node1 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Move dummy to node1 (XML)
=#=#=#= Begin test: Clear implicit constraints for dummy on node2 =#=#=#=
Removing constraint: cli-ban-dummy-on-node2
=#=#=#= Current cib after: Clear implicit constraints for dummy on node2 =#=#=#=
<cib admin_epoch="0" epoch="27" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status>
    <node_state id="node1" uname="node1" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node1">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_stop_0" operation="stop" crm-debug-origin="crm_simulate" transition-key="3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;3:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node1" call-id="3" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node2" uname="node2" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node2">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node2" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
    <node_state id="node3" uname="node3" in_ccm="true" crmd="online" join="member" expected="member" crm-debug-origin="crm_simulate">
      <lrm id="node3">
        <lrm_resources>
          <lrm_resource id="dummy" class="ocf" provider="pacemaker" type="Dummy">
            <lrm_rsc_op id="dummy_last_0" operation_key="dummy_start_0" operation="start" crm-debug-origin="crm_simulate" transition-key="2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:0;2:-1:0:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="2" rc-code="0" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="0830891652dabe627ca72b8e879199b1"/>
          </lrm_resource>
          <lrm_resource id="Fence" class="stonith" type="fence_true">
            <lrm_rsc_op id="Fence_last_0" operation_key="Fence_monitor_0" operation="monitor" crm-debug-origin="crm_simulate" transition-key="1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" transition-magic="0:7;1:-1:7:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" exit-reason="" on_node="node3" call-id="1" rc-code="7" op-status="0" interval="0" exec-time="0" queue-time="0" op-digest="f2317cad3d54cec5d7d7aa7d0bf35cf8"/>
          </lrm_resource>
        </lrm_resources>
      </lrm>
    </node_state>
  </status>
</cib>
=#=#=#= End test: Clear implicit constraints for dummy on node2 - OK (0) =#=#=#=
* Passed: crm_resource          - Clear implicit constraints for dummy on node2
=#=#=#= Begin test: Drop the status section =#=#=#=
=#=#=#= End test: Drop the status section - OK (0) =#=#=#=
* Passed: cibadmin              - Drop the status section
=#=#=#= Begin test: Create a clone =#=#=#=
=#=#=#= End test: Create a clone - OK (0) =#=#=#=
* Passed: cibadmin              - Create a clone
=#=#=#= Begin test: Create a resource meta attribute =#=#=#=
Performing update of 'is-managed' on 'test-clone', the parent of 'test-primitive'
Set 'test-clone' option: id=test-clone-meta_attributes-is-managed set=test-clone-meta_attributes name=is-managed value=false
=#=#=#= Current cib after: Create a resource meta attribute =#=#=#=
<cib admin_epoch="0" epoch="29" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy"/>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="false"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create a resource meta attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute
=#=#=#= Begin test: Create a resource meta attribute in the primitive =#=#=#=
Set 'test-primitive' option: id=test-primitive-meta_attributes-is-managed set=test-primitive-meta_attributes name=is-managed value=false
=#=#=#= Current cib after: Create a resource meta attribute in the primitive =#=#=#=
<cib admin_epoch="0" epoch="30" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="false"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="false"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create a resource meta attribute in the primitive - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute in the primitive
=#=#=#= Begin test: Update resource meta attribute with duplicates =#=#=#=
Multiple attributes match name=is-managed
  Value: false 	(id=test-primitive-meta_attributes-is-managed)
  Value: false 	(id=test-clone-meta_attributes-is-managed)

A value for 'is-managed' already exists in child 'test-primitive', performing update on that instead of 'test-clone'
Set 'test-primitive' option: id=test-primitive-meta_attributes-is-managed name=is-managed value=true
=#=#=#= Current cib after: Update resource meta attribute with duplicates =#=#=#=
<cib admin_epoch="0" epoch="31" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="true"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="false"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Update resource meta attribute with duplicates - OK (0) =#=#=#=
* Passed: crm_resource          - Update resource meta attribute with duplicates
=#=#=#= Begin test: Update resource meta attribute with duplicates (force clone) =#=#=#=
Set 'test-clone' option: id=test-clone-meta_attributes-is-managed name=is-managed value=true
=#=#=#= Current cib after: Update resource meta attribute with duplicates (force clone) =#=#=#=
<cib admin_epoch="0" epoch="32" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="true"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Update resource meta attribute with duplicates (force clone) - OK (0) =#=#=#=
* Passed: crm_resource          - Update resource meta attribute with duplicates (force clone)
=#=#=#= Begin test: Update child resource meta attribute with duplicates =#=#=#=
Multiple attributes match name=is-managed
  Value: true 	(id=test-primitive-meta_attributes-is-managed)
  Value: true 	(id=test-clone-meta_attributes-is-managed)

Set 'test-primitive' option: id=test-primitive-meta_attributes-is-managed name=is-managed value=false
=#=#=#= Current cib after: Update child resource meta attribute with duplicates =#=#=#=
<cib admin_epoch="0" epoch="33" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="false"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Update child resource meta attribute with duplicates - OK (0) =#=#=#=
* Passed: crm_resource          - Update child resource meta attribute with duplicates
=#=#=#= Begin test: Delete resource meta attribute with duplicates =#=#=#=
Multiple attributes match name=is-managed
  Value: false 	(id=test-primitive-meta_attributes-is-managed)
  Value: true 	(id=test-clone-meta_attributes-is-managed)

A value for 'is-managed' already exists in child 'test-primitive', performing delete on that instead of 'test-clone'
Deleted 'test-primitive' option: id=test-primitive-meta_attributes-is-managed name=is-managed
=#=#=#= Current cib after: Delete resource meta attribute with duplicates =#=#=#=
<cib admin_epoch="0" epoch="34" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Delete resource meta attribute with duplicates - OK (0) =#=#=#=
* Passed: crm_resource          - Delete resource meta attribute with duplicates
=#=#=#= Begin test: Delete resource meta attribute in parent =#=#=#=
Performing delete of 'is-managed' on 'test-clone', the parent of 'test-primitive'
Deleted 'test-clone' option: id=test-clone-meta_attributes-is-managed name=is-managed
=#=#=#= Current cib after: Delete resource meta attribute in parent =#=#=#=
<cib admin_epoch="0" epoch="35" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes"/>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Delete resource meta attribute in parent - OK (0) =#=#=#=
* Passed: crm_resource          - Delete resource meta attribute in parent
=#=#=#= Begin test: Create a resource meta attribute in the primitive =#=#=#=
Set 'test-primitive' option: id=test-primitive-meta_attributes-is-managed set=test-primitive-meta_attributes name=is-managed value=false
=#=#=#= Current cib after: Create a resource meta attribute in the primitive =#=#=#=
<cib admin_epoch="0" epoch="36" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="false"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes"/>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create a resource meta attribute in the primitive - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute in the primitive
=#=#=#= Begin test: Update existing resource meta attribute =#=#=#=
A value for 'is-managed' already exists in child 'test-primitive', performing update on that instead of 'test-clone'
Set 'test-primitive' option: id=test-primitive-meta_attributes-is-managed name=is-managed value=true
=#=#=#= Current cib after: Update existing resource meta attribute =#=#=#=
<cib admin_epoch="0" epoch="37" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="true"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes"/>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Update existing resource meta attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Update existing resource meta attribute
=#=#=#= Begin test: Create a resource meta attribute in the parent =#=#=#=
Set 'test-clone' option: id=test-clone-meta_attributes-is-managed set=test-clone-meta_attributes name=is-managed value=true
=#=#=#= Current cib after: Create a resource meta attribute in the parent =#=#=#=
<cib admin_epoch="0" epoch="38" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="true"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create a resource meta attribute in the parent - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute in the parent
=#=#=#= Begin test: Delete resource parent meta attribute (force) =#=#=#=
Deleted 'test-clone' option: id=test-clone-meta_attributes-is-managed name=is-managed
=#=#=#= Current cib after: Delete resource parent meta attribute (force) =#=#=#=
<cib admin_epoch="0" epoch="39" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes">
            <nvpair id="test-primitive-meta_attributes-is-managed" name="is-managed" value="true"/>
          </meta_attributes>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes"/>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Delete resource parent meta attribute (force) - OK (0) =#=#=#=
* Passed: crm_resource          - Delete resource parent meta attribute (force)
=#=#=#= Begin test: Delete resource child meta attribute =#=#=#=
Multiple attributes match name=is-managed
  Value: true 	(id=test-primitive-meta_attributes-is-managed)
  Value: true 	(id=test-clone-meta_attributes-is-managed)

Deleted 'test-primitive' option: id=test-primitive-meta_attributes-is-managed name=is-managed
=#=#=#= Current cib after: Delete resource child meta attribute =#=#=#=
<cib admin_epoch="0" epoch="41" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Delete resource child meta attribute - OK (0) =#=#=#=
* Passed: crm_resource          - Delete resource child meta attribute
=#=#=#= Begin test: Create the dummy-group resource group =#=#=#=
=#=#=#= Current cib after: Create the dummy-group resource group =#=#=#=
<cib admin_epoch="0" epoch="42" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
      <group id="dummy-group">
        <primitive id="dummy1" class="ocf" provider="pacemaker" type="Dummy"/>
        <primitive id="dummy2" class="ocf" provider="pacemaker" type="Dummy"/>
      </group>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create the dummy-group resource group - OK (0) =#=#=#=
* Passed: cibadmin              - Create the dummy-group resource group
=#=#=#= Begin test: Create a resource meta attribute in dummy1 =#=#=#=
Set 'dummy1' option: id=dummy1-meta_attributes-is-managed set=dummy1-meta_attributes name=is-managed value=true
=#=#=#= Current cib after: Create a resource meta attribute in dummy1 =#=#=#=
<cib admin_epoch="0" epoch="43" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
      <group id="dummy-group">
        <primitive id="dummy1" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="dummy1-meta_attributes">
            <nvpair id="dummy1-meta_attributes-is-managed" name="is-managed" value="true"/>
          </meta_attributes>
        </primitive>
        <primitive id="dummy2" class="ocf" provider="pacemaker" type="Dummy"/>
      </group>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create a resource meta attribute in dummy1 - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute in dummy1
=#=#=#= Begin test: Create a resource meta attribute in dummy-group =#=#=#=
Set 'dummy1' option: id=dummy1-meta_attributes-is-managed name=is-managed value=false
Set 'dummy-group' option: id=dummy-group-meta_attributes-is-managed set=dummy-group-meta_attributes name=is-managed value=false
=#=#=#= Current cib after: Create a resource meta attribute in dummy-group =#=#=#=
<cib admin_epoch="0" epoch="45" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
      <group id="dummy-group">
        <primitive id="dummy1" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="dummy1-meta_attributes">
            <nvpair id="dummy1-meta_attributes-is-managed" name="is-managed" value="false"/>
          </meta_attributes>
        </primitive>
        <primitive id="dummy2" class="ocf" provider="pacemaker" type="Dummy"/>
        <meta_attributes id="dummy-group-meta_attributes">
          <nvpair id="dummy-group-meta_attributes-is-managed" name="is-managed" value="false"/>
        </meta_attributes>
      </group>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Create a resource meta attribute in dummy-group - OK (0) =#=#=#=
* Passed: crm_resource          - Create a resource meta attribute in dummy-group
=#=#=#= Begin test: Delete the dummy-group resource group =#=#=#=
=#=#=#= Current cib after: Delete the dummy-group resource group =#=#=#=
<cib admin_epoch="0" epoch="46" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Delete the dummy-group resource group - OK (0) =#=#=#=
* Passed: cibadmin              - Delete the dummy-group resource group
=#=#=#= Begin test: Specify a lifetime when moving a resource =#=#=#=
Migration will take effect until:
=#=#=#= Current cib after: Specify a lifetime when moving a resource =#=#=#=
<cib admin_epoch="0" epoch="48" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started">
        <rule id="cli-prefer-rule-dummy" score="INFINITY" boolean-op="and">
          <expression id="cli-prefer-expr-dummy" attribute="#uname" operation="eq" value="node2" type="string"/>
          <date_expression id="cli-prefer-lifetime-end-dummy" operation="lt" end=""/>
        </rule>
      </rsc_location>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Specify a lifetime when moving a resource - OK (0) =#=#=#=
* Passed: crm_resource          - Specify a lifetime when moving a resource
=#=#=#= Begin test: Try to move a resource previously moved with a lifetime =#=#=#=
=#=#=#= Current cib after: Try to move a resource previously moved with a lifetime =#=#=#=
<cib admin_epoch="0" epoch="50" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Try to move a resource previously moved with a lifetime - OK (0) =#=#=#=
* Passed: crm_resource          - Try to move a resource previously moved with a lifetime
=#=#=#= Begin test: Ban dummy from node1 for a short time =#=#=#=
Migration will take effect until:
WARNING: Creating rsc_location constraint 'cli-ban-dummy-on-node1' with a score of -INFINITY for resource dummy on node1.
	This will prevent dummy from running on node1 until the constraint is removed using the clear option or by editing the CIB with an appropriate tool.
	This will be the case even if node1 is the last node in the cluster
=#=#=#= Current cib after: Ban dummy from node1 for a short time =#=#=#=
<cib admin_epoch="0" epoch="51" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
      <rsc_location id="cli-ban-dummy-on-node1" rsc="dummy" role="Started">
        <rule id="cli-ban-dummy-on-node1-rule" score="-INFINITY" boolean-op="and">
          <expression id="cli-ban-dummy-on-node1-expr" attribute="#uname" operation="eq" value="node1" type="string"/>
          <date_expression id="cli-ban-dummy-on-node1-lifetime" operation="lt" end=""/>
        </rule>
      </rsc_location>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Ban dummy from node1 for a short time - OK (0) =#=#=#=
* Passed: crm_resource          - Ban dummy from node1 for a short time
=#=#=#= Begin test: Remove expired constraints =#=#=#=
Removing constraint: cli-ban-dummy-on-node1
=#=#=#= Current cib after: Remove expired constraints =#=#=#=
<cib admin_epoch="0" epoch="52" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints>
      <rsc_location id="cli-prefer-dummy" rsc="dummy" role="Started" node="node1" score="INFINITY"/>
    </constraints>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Remove expired constraints - OK (0) =#=#=#=
* Passed: sleep                 - Remove expired constraints
=#=#=#= Begin test: Clear all implicit constraints for dummy =#=#=#=
Removing constraint: cli-prefer-dummy
=#=#=#= Current cib after: Clear all implicit constraints for dummy =#=#=#=
<cib admin_epoch="0" epoch="53" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints/>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Clear all implicit constraints for dummy - OK (0) =#=#=#=
* Passed: crm_resource          - Clear all implicit constraints for dummy
=#=#=#= Begin test: Set a node health strategy =#=#=#=
=#=#=#= Current cib after: Set a node health strategy =#=#=#=
<cib admin_epoch="0" epoch="54" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
        <nvpair id="cib-bootstrap-options-node-health-strategy" name="node-health-strategy" value="migrate-on-red"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3"/>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints/>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Set a node health strategy - OK (0) =#=#=#=
* Passed: crm_attribute         - Set a node health strategy
=#=#=#= Begin test: Set a node health attribute =#=#=#=
=#=#=#= Current cib after: Set a node health attribute =#=#=#=
<cib admin_epoch="0" epoch="55" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
        <nvpair id="cib-bootstrap-options-node-health-strategy" name="node-health-strategy" value="migrate-on-red"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3">
        <instance_attributes id="nodes-node3">
          <nvpair id="nodes-node3-.health-cts-cli" name="#health-cts-cli" value="red"/>
        </instance_attributes>
      </node>
    </nodes>
    <resources>
      <primitive id="dummy" class="ocf" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy-meta_attributes"/>
        <instance_attributes id="dummy-instance_attributes">
          <nvpair id="dummy-instance_attributes-delay" name="delay" value="10s"/>
        </instance_attributes>
      </primitive>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints/>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Set a node health attribute - OK (0) =#=#=#=
* Passed: crm_attribute         - Set a node health attribute
=#=#=#= Begin test: Show why a resource is not running on an unhealthy node (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource -N node3 -Y -r dummy --output-as=xml">
  <reason>
    <check id="dummy" unhealthy="true"/>
  </reason>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Show why a resource is not running on an unhealthy node (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Show why a resource is not running on an unhealthy node (XML)
=#=#=#= Begin test: Delete a resource =#=#=#=
=#=#=#= Current cib after: Delete a resource =#=#=#=
<cib admin_epoch="0" epoch="56" num_updates="0">
  <configuration>
    <crm_config>
      <cluster_property_set id="cib-bootstrap-options">
        <nvpair id="cib-bootstrap-options-no-quorum-policy" name="no-quorum-policy" value="ignore"/>
        <nvpair id="cib-bootstrap-options-node-health-strategy" name="node-health-strategy" value="migrate-on-red"/>
      </cluster_property_set>
    </crm_config>
    <nodes>
      <node id="node1" uname="node1"/>
      <node id="node2" uname="node2"/>
      <node id="node3" uname="node3">
        <instance_attributes id="nodes-node3">
          <nvpair id="nodes-node3-.health-cts-cli" name="#health-cts-cli" value="red"/>
        </instance_attributes>
      </node>
    </nodes>
    <resources>
      <primitive id="Fence" class="stonith" type="fence_true"/>
      <clone id="test-clone">
        <primitive id="test-primitive" class="ocf" provider="pacemaker" type="Dummy">
          <meta_attributes id="test-primitive-meta_attributes"/>
        </primitive>
        <meta_attributes id="test-clone-meta_attributes">
          <nvpair id="test-clone-meta_attributes-is-managed" name="is-managed" value="true"/>
        </meta_attributes>
      </clone>
    </resources>
    <constraints/>
  </configuration>
  <status/>
</cib>
=#=#=#= End test: Delete a resource - OK (0) =#=#=#=
* Passed: crm_resource          - Delete a resource
=#=#=#= Begin test: Check locations and constraints for prim1 =#=#=#=
=#=#=#= End test: Check locations and constraints for prim1 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim1
=#=#=#= Begin test: Check locations and constraints for prim1 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim1">
  <constraints/>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim1 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim1 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim1 =#=#=#=
=#=#=#= End test: Recursively check locations and constraints for prim1 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim1
=#=#=#= Begin test: Recursively check locations and constraints for prim1 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim1">
  <constraints/>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim1 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim1 (XML)
=#=#=#= Begin test: Check locations and constraints for prim2 =#=#=#=
Locations:
  * Node cluster01 (score=INFINITY, id=prim2-on-cluster1, rsc=prim2)
Resources prim2 is colocated with:
  * prim3 (score=INFINITY, id=colocation-prim2-prim3-INFINITY)
=#=#=#= End test: Check locations and constraints for prim2 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim2
=#=#=#= Begin test: Check locations and constraints for prim2 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim2">
  <constraints>
    <rsc_location node="cluster01" rsc="prim2" id="prim2-on-cluster1" score="INFINITY"/>
    <rsc_colocation id="colocation-prim2-prim3-INFINITY" rsc="prim2" with-rsc="prim3" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim2 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim2 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim2 =#=#=#=
Locations:
  * Node cluster01 (score=INFINITY, id=prim2-on-cluster1, rsc=prim2)
Resources prim2 is colocated with:
  * prim3 (score=INFINITY, id=colocation-prim2-prim3-INFINITY)
    * Resources prim3 is colocated with:
      * prim4 (score=INFINITY, id=colocation-prim3-prim4-INFINITY)
        * Locations:
          * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
        * Resources prim4 is colocated with:
          * prim5 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim2 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim2
=#=#=#= Begin test: Recursively check locations and constraints for prim2 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim2">
  <constraints>
    <rsc_location node="cluster01" rsc="prim2" id="prim2-on-cluster1" score="INFINITY"/>
    <rsc_colocation id="colocation-prim2-prim3-INFINITY" rsc="prim2" with-rsc="prim3" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim3-prim4-INFINITY" rsc="prim3" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim2 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim2 (XML)
=#=#=#= Begin test: Check locations and constraints for prim3 =#=#=#=
Resources colocated with prim3:
  * prim2 (score=INFINITY, id=colocation-prim2-prim3-INFINITY)
    * Locations:
      * Node cluster01 (score=INFINITY, id=prim2-on-cluster1, rsc=prim2)
Resources prim3 is colocated with:
  * prim4 (score=INFINITY, id=colocation-prim3-prim4-INFINITY)
    * Locations:
      * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
=#=#=#= End test: Check locations and constraints for prim3 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim3
=#=#=#= Begin test: Check locations and constraints for prim3 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim3">
  <constraints>
    <rsc_colocation id="colocation-prim2-prim3-INFINITY" rsc="prim2" with-rsc="prim3" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster01" rsc="prim2" id="prim2-on-cluster1" score="INFINITY"/>
    <rsc_colocation id="colocation-prim3-prim4-INFINITY" rsc="prim3" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim3 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim3 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim3 =#=#=#=
Resources colocated with prim3:
  * prim2 (score=INFINITY, id=colocation-prim2-prim3-INFINITY)
    * Locations:
      * Node cluster01 (score=INFINITY, id=prim2-on-cluster1, rsc=prim2)
Resources prim3 is colocated with:
  * prim4 (score=INFINITY, id=colocation-prim3-prim4-INFINITY)
    * Locations:
      * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
    * Resources prim4 is colocated with:
      * prim5 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim3 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim3
=#=#=#= Begin test: Recursively check locations and constraints for prim3 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim3">
  <constraints>
    <rsc_colocation id="colocation-prim2-prim3-INFINITY" rsc="prim2" with-rsc="prim3" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster01" rsc="prim2" id="prim2-on-cluster1" score="INFINITY"/>
    <rsc_colocation id="colocation-prim3-prim4-INFINITY" rsc="prim3" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim3 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim3 (XML)
=#=#=#= Begin test: Check locations and constraints for prim4 =#=#=#=
Locations:
  * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
Resources colocated with prim4:
  * prim10 (score=INFINITY, id=colocation-prim10-prim4-INFINITY)
  * prim3 (score=INFINITY, id=colocation-prim3-prim4-INFINITY)
Resources prim4 is colocated with:
  * prim5 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
=#=#=#= End test: Check locations and constraints for prim4 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim4
=#=#=#= Begin test: Check locations and constraints for prim4 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim4">
  <constraints>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
    <rsc_colocation id="colocation-prim10-prim4-INFINITY" rsc="prim10" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim3-prim4-INFINITY" rsc="prim3" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim4 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim4 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim4 =#=#=#=
Locations:
  * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
Resources colocated with prim4:
  * prim10 (score=INFINITY, id=colocation-prim10-prim4-INFINITY)
  * prim3 (score=INFINITY, id=colocation-prim3-prim4-INFINITY)
    * Resources colocated with prim3:
      * prim2 (score=INFINITY, id=colocation-prim2-prim3-INFINITY)
        * Locations:
          * Node cluster01 (score=INFINITY, id=prim2-on-cluster1, rsc=prim2)
Resources prim4 is colocated with:
  * prim5 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim4 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim4
=#=#=#= Begin test: Recursively check locations and constraints for prim4 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim4">
  <constraints>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
    <rsc_colocation id="colocation-prim10-prim4-INFINITY" rsc="prim10" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim3-prim4-INFINITY" rsc="prim3" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim2-prim3-INFINITY" rsc="prim2" with-rsc="prim3" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster01" rsc="prim2" id="prim2-on-cluster1" score="INFINITY"/>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim4 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim4 (XML)
=#=#=#= Begin test: Check locations and constraints for prim5 =#=#=#=
Resources colocated with prim5:
  * prim4 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
    * Locations:
      * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
=#=#=#= End test: Check locations and constraints for prim5 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim5
=#=#=#= Begin test: Check locations and constraints for prim5 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim5">
  <constraints>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim5 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim5 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim5 =#=#=#=
Resources colocated with prim5:
  * prim4 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
    * Locations:
      * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
    * Resources colocated with prim4:
      * prim10 (score=INFINITY, id=colocation-prim10-prim4-INFINITY)
      * prim3 (score=INFINITY, id=colocation-prim3-prim4-INFINITY)
        * Resources colocated with prim3:
          * prim2 (score=INFINITY, id=colocation-prim2-prim3-INFINITY)
            * Locations:
              * Node cluster01 (score=INFINITY, id=prim2-on-cluster1, rsc=prim2)
=#=#=#= End test: Recursively check locations and constraints for prim5 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim5
=#=#=#= Begin test: Recursively check locations and constraints for prim5 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim5">
  <constraints>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
    <rsc_colocation id="colocation-prim10-prim4-INFINITY" rsc="prim10" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim3-prim4-INFINITY" rsc="prim3" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim2-prim3-INFINITY" rsc="prim2" with-rsc="prim3" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster01" rsc="prim2" id="prim2-on-cluster1" score="INFINITY"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim5 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim5 (XML)
=#=#=#= Begin test: Check locations and constraints for prim6 =#=#=#=
Locations:
  * Node cluster02 (score=-INFINITY, id=prim6-not-on-cluster2, rsc=prim6)
=#=#=#= End test: Check locations and constraints for prim6 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim6
=#=#=#= Begin test: Check locations and constraints for prim6 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim6">
  <constraints>
    <rsc_location node="cluster02" rsc="prim6" id="prim6-not-on-cluster2" score="-INFINITY"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim6 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim6 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim6 =#=#=#=
Locations:
  * Node cluster02 (score=-INFINITY, id=prim6-not-on-cluster2, rsc=prim6)
=#=#=#= End test: Recursively check locations and constraints for prim6 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim6
=#=#=#= Begin test: Recursively check locations and constraints for prim6 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim6">
  <constraints>
    <rsc_location node="cluster02" rsc="prim6" id="prim6-not-on-cluster2" score="-INFINITY"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim6 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim6 (XML)
=#=#=#= Begin test: Check locations and constraints for prim7 =#=#=#=
Resources prim7 is colocated with:
  * group (score=INFINITY, id=colocation-prim7-group-INFINITY)
=#=#=#= End test: Check locations and constraints for prim7 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim7
=#=#=#= Begin test: Check locations and constraints for prim7 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim7">
  <constraints>
    <rsc_colocation id="colocation-prim7-group-INFINITY" rsc="prim7" with-rsc="group" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim7 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim7 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim7 =#=#=#=
Resources prim7 is colocated with:
  * group (score=INFINITY, id=colocation-prim7-group-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim7 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim7
=#=#=#= Begin test: Recursively check locations and constraints for prim7 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim7">
  <constraints>
    <rsc_colocation id="colocation-prim7-group-INFINITY" rsc="prim7" with-rsc="group" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim7 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim7 (XML)
=#=#=#= Begin test: Check locations and constraints for prim8 =#=#=#=
Resources prim8 is colocated with:
  * gr2 (score=INFINITY, id=colocation-prim8-gr2-INFINITY)
=#=#=#= End test: Check locations and constraints for prim8 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim8
=#=#=#= Begin test: Check locations and constraints for prim8 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim8">
  <constraints>
    <rsc_colocation id="colocation-prim8-gr2-INFINITY" rsc="prim8" with-rsc="gr2" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim8 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim8 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim8 =#=#=#=
Resources prim8 is colocated with:
  * gr2 (score=INFINITY, id=colocation-prim8-gr2-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim8 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim8
=#=#=#= Begin test: Recursively check locations and constraints for prim8 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim8">
  <constraints>
    <rsc_colocation id="colocation-prim8-gr2-INFINITY" rsc="prim8" with-rsc="gr2" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim8 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim8 (XML)
=#=#=#= Begin test: Check locations and constraints for prim9 =#=#=#=
Resources prim9 is colocated with:
  * clone (score=INFINITY, id=colocation-prim9-clone-INFINITY)
=#=#=#= End test: Check locations and constraints for prim9 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim9
=#=#=#= Begin test: Check locations and constraints for prim9 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim9">
  <constraints>
    <rsc_colocation id="colocation-prim9-clone-INFINITY" rsc="prim9" with-rsc="clone" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim9 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim9 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim9 =#=#=#=
Resources prim9 is colocated with:
  * clone (score=INFINITY, id=colocation-prim9-clone-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim9 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim9
=#=#=#= Begin test: Recursively check locations and constraints for prim9 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim9">
  <constraints>
    <rsc_colocation id="colocation-prim9-clone-INFINITY" rsc="prim9" with-rsc="clone" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim9 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim9 (XML)
=#=#=#= Begin test: Check locations and constraints for prim10 =#=#=#=
Resources prim10 is colocated with:
  * prim4 (score=INFINITY, id=colocation-prim10-prim4-INFINITY)
    * Locations:
      * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
=#=#=#= End test: Check locations and constraints for prim10 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim10
=#=#=#= Begin test: Check locations and constraints for prim10 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim10">
  <constraints>
    <rsc_colocation id="colocation-prim10-prim4-INFINITY" rsc="prim10" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim10 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim10 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim10 =#=#=#=
Resources prim10 is colocated with:
  * prim4 (score=INFINITY, id=colocation-prim10-prim4-INFINITY)
    * Locations:
      * Node cluster02 (score=INFINITY, id=prim4-on-cluster2, rsc=prim4)
    * Resources prim4 is colocated with:
      * prim5 (score=INFINITY, id=colocation-prim4-prim5-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for prim10 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim10
=#=#=#= Begin test: Recursively check locations and constraints for prim10 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim10">
  <constraints>
    <rsc_colocation id="colocation-prim10-prim4-INFINITY" rsc="prim10" with-rsc="prim4" score="INFINITY" node-attribute="#uname"/>
    <rsc_location node="cluster02" rsc="prim4" id="prim4-on-cluster2" score="INFINITY"/>
    <rsc_colocation id="colocation-prim4-prim5-INFINITY" rsc="prim4" with-rsc="prim5" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim10 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim10 (XML)
=#=#=#= Begin test: Check locations and constraints for prim11 =#=#=#=
Resources colocated with prim11:
  * prim13 (score=INFINITY, id=colocation-prim13-prim11-INFINITY)
Resources prim11 is colocated with:
  * prim12 (score=INFINITY, id=colocation-prim11-prim12-INFINITY)
=#=#=#= End test: Check locations and constraints for prim11 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim11
=#=#=#= Begin test: Check locations and constraints for prim11 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim11">
  <constraints>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim11 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim11 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim11 =#=#=#=
Resources colocated with prim11:
  * prim13 (score=INFINITY, id=colocation-prim13-prim11-INFINITY)
    * Resources colocated with prim13:
      * prim12 (score=INFINITY, id=colocation-prim12-prim13-INFINITY)
        * Resources colocated with prim12:
          * prim11 (id=colocation-prim11-prim12-INFINITY - loop)
Resources prim11 is colocated with:
  * prim12 (score=INFINITY, id=colocation-prim11-prim12-INFINITY)
    * Resources prim12 is colocated with:
      * prim13 (score=INFINITY, id=colocation-prim12-prim13-INFINITY)
        * Resources prim13 is colocated with:
          * prim11 (id=colocation-prim13-prim11-INFINITY - loop)
=#=#=#= End test: Recursively check locations and constraints for prim11 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim11
=#=#=#= Begin test: Recursively check locations and constraints for prim11 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim11">
  <constraints>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim11 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim11 (XML)
=#=#=#= Begin test: Check locations and constraints for prim12 =#=#=#=
Resources colocated with prim12:
  * prim11 (score=INFINITY, id=colocation-prim11-prim12-INFINITY)
Resources prim12 is colocated with:
  * prim13 (score=INFINITY, id=colocation-prim12-prim13-INFINITY)
=#=#=#= End test: Check locations and constraints for prim12 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim12
=#=#=#= Begin test: Check locations and constraints for prim12 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim12">
  <constraints>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim12 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim12 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim12 =#=#=#=
Resources colocated with prim12:
  * prim11 (score=INFINITY, id=colocation-prim11-prim12-INFINITY)
    * Resources colocated with prim11:
      * prim13 (score=INFINITY, id=colocation-prim13-prim11-INFINITY)
        * Resources colocated with prim13:
          * prim12 (id=colocation-prim12-prim13-INFINITY - loop)
Resources prim12 is colocated with:
  * prim13 (score=INFINITY, id=colocation-prim12-prim13-INFINITY)
    * Resources prim13 is colocated with:
      * prim11 (score=INFINITY, id=colocation-prim13-prim11-INFINITY)
        * Resources prim11 is colocated with:
          * prim12 (id=colocation-prim11-prim12-INFINITY - loop)
=#=#=#= End test: Recursively check locations and constraints for prim12 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim12
=#=#=#= Begin test: Recursively check locations and constraints for prim12 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim12">
  <constraints>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim12 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim12 (XML)
=#=#=#= Begin test: Check locations and constraints for prim13 =#=#=#=
Resources colocated with prim13:
  * prim12 (score=INFINITY, id=colocation-prim12-prim13-INFINITY)
Resources prim13 is colocated with:
  * prim11 (score=INFINITY, id=colocation-prim13-prim11-INFINITY)
=#=#=#= End test: Check locations and constraints for prim13 - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim13
=#=#=#= Begin test: Check locations and constraints for prim13 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r prim13">
  <constraints>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for prim13 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for prim13 (XML)
=#=#=#= Begin test: Recursively check locations and constraints for prim13 =#=#=#=
Resources colocated with prim13:
  * prim12 (score=INFINITY, id=colocation-prim12-prim13-INFINITY)
    * Resources colocated with prim12:
      * prim11 (score=INFINITY, id=colocation-prim11-prim12-INFINITY)
        * Resources colocated with prim11:
          * prim13 (id=colocation-prim13-prim11-INFINITY - loop)
Resources prim13 is colocated with:
  * prim11 (score=INFINITY, id=colocation-prim13-prim11-INFINITY)
    * Resources prim11 is colocated with:
      * prim12 (score=INFINITY, id=colocation-prim11-prim12-INFINITY)
        * Resources prim12 is colocated with:
          * prim13 (id=colocation-prim12-prim13-INFINITY - loop)
=#=#=#= End test: Recursively check locations and constraints for prim13 - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim13
=#=#=#= Begin test: Recursively check locations and constraints for prim13 (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r prim13">
  <constraints>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim13-prim11-INFINITY" rsc="prim13" with-rsc="prim11" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim11-prim12-INFINITY" rsc="prim11" with-rsc="prim12" score="INFINITY" node-attribute="#uname"/>
    <rsc_colocation id="colocation-prim12-prim13-INFINITY" rsc="prim12" with-rsc="prim13" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for prim13 (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for prim13 (XML)
=#=#=#= Begin test: Check locations and constraints for group =#=#=#=
Resources colocated with group:
  * prim7 (score=INFINITY, id=colocation-prim7-group-INFINITY)
=#=#=#= End test: Check locations and constraints for group - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for group
=#=#=#= Begin test: Check locations and constraints for group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r group">
  <constraints>
    <rsc_colocation id="colocation-prim7-group-INFINITY" rsc="prim7" with-rsc="group" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for group (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for group (XML)
=#=#=#= Begin test: Recursively check locations and constraints for group =#=#=#=
Resources colocated with group:
  * prim7 (score=INFINITY, id=colocation-prim7-group-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for group - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for group
=#=#=#= Begin test: Recursively check locations and constraints for group (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r group">
  <constraints>
    <rsc_colocation id="colocation-prim7-group-INFINITY" rsc="prim7" with-rsc="group" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for group (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for group (XML)
=#=#=#= Begin test: Check locations and constraints for clone =#=#=#=
Resources colocated with clone:
  * prim9 (score=INFINITY, id=colocation-prim9-clone-INFINITY)
=#=#=#= End test: Check locations and constraints for clone - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for clone
=#=#=#= Begin test: Check locations and constraints for clone (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -a -r clone">
  <constraints>
    <rsc_colocation id="colocation-prim9-clone-INFINITY" rsc="prim9" with-rsc="clone" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check locations and constraints for clone (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for clone (XML)
=#=#=#= Begin test: Recursively check locations and constraints for clone =#=#=#=
Resources colocated with clone:
  * prim9 (score=INFINITY, id=colocation-prim9-clone-INFINITY)
=#=#=#= End test: Recursively check locations and constraints for clone - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for clone
=#=#=#= Begin test: Recursively check locations and constraints for clone (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml -A -r clone">
  <constraints>
    <rsc_colocation id="colocation-prim9-clone-INFINITY" rsc="prim9" with-rsc="clone" score="INFINITY" node-attribute="#uname"/>
  </constraints>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Recursively check locations and constraints for clone (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Recursively check locations and constraints for clone (XML)
=#=#=#= Begin test: Check locations and constraints for group member (referring to group) =#=#=#=
Resources colocated with group:
  * prim7 (score=INFINITY, id=colocation-prim7-group-INFINITY)
=#=#=#= End test: Check locations and constraints for group member (referring to group) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for group member (referring to group)
=#=#=#= Begin test: Check locations and constraints for group member (without referring to group) =#=#=#=
Resources colocated with gr2:
  * prim8 (score=INFINITY, id=colocation-prim8-gr2-INFINITY)
=#=#=#= End test: Check locations and constraints for group member (without referring to group) - OK (0) =#=#=#=
* Passed: crm_resource          - Check locations and constraints for group member (without referring to group)
=#=#=#= Begin test: Set a meta-attribute for primitive and resources colocated with it (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource -r prim5 --meta --set-parameter=target-role -v Stopped --recursive --output-as=xml">
  <resource-settings>
    <primitive id="prim5">
      <meta_attributes id="prim5-meta_attributes">
        <nvpair id="prim5-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
    <primitive id="prim4">
      <meta_attributes id="prim4-meta_attributes">
        <nvpair id="prim4-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
    <primitive id="prim10">
      <meta_attributes id="prim10-meta_attributes">
        <nvpair id="prim10-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
    <primitive id="prim3">
      <meta_attributes id="prim3-meta_attributes">
        <nvpair id="prim3-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
    <primitive id="prim2">
      <meta_attributes id="prim2-meta_attributes">
        <nvpair id="prim2-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
  </resource-settings>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Set a meta-attribute for primitive and resources colocated with it (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Set a meta-attribute for primitive and resources colocated with it (XML)
=#=#=#= Begin test: Set a meta-attribute for group and resource colocated with it =#=#=#=
Set 'group' option: id=group-meta_attributes-target-role set=group-meta_attributes name=target-role value=Stopped
Set 'prim7' option: id=prim7-meta_attributes-target-role set=prim7-meta_attributes name=target-role value=Stopped
=#=#=#= End test: Set a meta-attribute for group and resource colocated with it - OK (0) =#=#=#=
* Passed: crm_resource          - Set a meta-attribute for group and resource colocated with it
=#=#=#= Begin test: Set a meta-attribute for clone and resource colocated with it (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource -r clone --meta --set-parameter=target-role -v Stopped --recursive --output-as=xml">
  <resource-settings>
    <clone id="clone">
      <meta_attributes id="clone-meta_attributes">
        <nvpair id="clone-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </clone>
    <primitive id="prim9">
      <meta_attributes id="prim9-meta_attributes">
        <nvpair id="prim9-meta_attributes-target-role" value="Stopped" name="target-role"/>
      </meta_attributes>
    </primitive>
  </resource-settings>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Set a meta-attribute for clone and resource colocated with it (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Set a meta-attribute for clone and resource colocated with it (XML)
=#=#=#= Begin test: Show resource digests (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --digests -r rsc1 -N node1 --output-as=xml">
  <digests resource="rsc1" node="node1" task="start" interval="0ms">
    <digest type="all" hash="3acdbe4c12734ebeb1251a59545af936">
      <parameters passwd="secret" fake="0"/>
    </digest>
    <digest type="nonprivate" hash="279c477dbc38c621904a00ab9e599b2f">
      <parameters fake="0"/>
    </digest>
    <digest type="nonreloadable" hash="5de1fd72a2e7762ed41543231034f6d7">
      <parameters passwd="secret"/>
    </digest>
  </digests>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Show resource digests (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Show resource digests (XML)
=#=#=#= Begin test: Show resource digests with overrides =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --digests -r rsc1 -N node1 --output-as=xml CRM_meta_interval=10000 CRM_meta_timeout=20000">
  <digests resource="rsc1" node="node1" task="start" interval="10000ms">
    <digest type="all" hash="720718e8d715d5d3be1403cbbcb953bc">
      <parameters passwd="secret" fake="0" CRM_meta_timeout="20000"/>
    </digest>
    <digest type="nonprivate" hash="279c477dbc38c621904a00ab9e599b2f">
      <parameters fake="0"/>
    </digest>
    <digest type="nonreloadable" hash="5de1fd72a2e7762ed41543231034f6d7">
      <parameters passwd="secret"/>
    </digest>
  </digests>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Show resource digests with overrides - OK (0) =#=#=#=
* Passed: crm_resource          - Show resource digests with overrides
=#=#=#= Begin test: Show resource operations =#=#=#=
rsc1	(ocf:pacemaker:Dummy):	 Started: rsc1_monitor_0 (node=node4, call=136, rc=7, exec=28ms): Done
Fencing	(stonith:fence_xvm):	 Started: Fencing_monitor_0 (node=node4, call=5, rc=7, exec=2ms): Done
rsc1	(ocf:pacemaker:Dummy):	 Started: rsc1_monitor_0 (node=node2, call=101, rc=7, exec=45ms): Done
Fencing	(stonith:fence_xvm):	 Started: Fencing_monitor_0 (node=node2, call=5, rc=7, exec=4ms): Done
Fencing	(stonith:fence_xvm):	 Started: Fencing_monitor_0 (node=node3, call=5, rc=7, exec=24ms): Done
rsc1	(ocf:pacemaker:Dummy):	 Started: rsc1_monitor_0 (node=node5, call=99, rc=193, exec=27ms): Pending
Fencing	(stonith:fence_xvm):	 Started: Fencing_monitor_0 (node=node5, call=5, rc=7, exec=14ms): Done
rsc1	(ocf:pacemaker:Dummy):	 Started: rsc1_start_0 (node=node1, call=104, rc=0, exec=22ms): Done
rsc1	(ocf:pacemaker:Dummy):	 Started: rsc1_monitor_10000 (node=node1, call=106, rc=0, exec=20ms): Done
Fencing	(stonith:fence_xvm):	 Started: Fencing_start_0 (node=node1, call=10, rc=0, exec=59ms): Done
Fencing	(stonith:fence_xvm):	 Started: Fencing_monitor_120000 (node=node1, call=12, rc=0, exec=70ms): Done
=#=#=#= End test: Show resource operations - OK (0) =#=#=#=
* Passed: crm_resource          - Show resource operations
=#=#=#= Begin test: Show resource operations (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --list-operations">
  <operations>
    <operation op="rsc1_monitor_0" node="node4" call="136" rc="7" status="Done" rsc="rsc1" agent="ocf:pacemaker:Dummy" exec-time="28"/>
    <operation op="Fencing_monitor_0" node="node4" call="5" rc="7" status="Done" rsc="Fencing" agent="stonith::fence_xvm" exec-time="2"/>
    <operation op="rsc1_monitor_0" node="node2" call="101" rc="7" status="Done" rsc="rsc1" agent="ocf:pacemaker:Dummy" exec-time="45"/>
    <operation op="Fencing_monitor_0" node="node2" call="5" rc="7" status="Done" rsc="Fencing" agent="stonith::fence_xvm" exec-time="4"/>
    <operation op="Fencing_monitor_0" node="node3" call="5" rc="7" status="Done" rsc="Fencing" agent="stonith::fence_xvm" exec-time="24"/>
    <operation op="rsc1_monitor_0" node="node5" call="99" rc="193" status="Pending" rsc="rsc1" agent="ocf:pacemaker:Dummy" exec-time="27"/>
    <operation op="Fencing_monitor_0" node="node5" call="5" rc="7" status="Done" rsc="Fencing" agent="stonith::fence_xvm" exec-time="14"/>
    <operation op="rsc1_start_0" node="node1" call="104" rc="0" status="Done" rsc="rsc1" agent="ocf:pacemaker:Dummy" exec-time="22"/>
    <operation op="rsc1_monitor_10000" node="node1" call="106" rc="0" status="Done" rsc="rsc1" agent="ocf:pacemaker:Dummy" exec-time="20"/>
    <operation op="Fencing_start_0" node="node1" call="10" rc="0" status="Done" rsc="Fencing" agent="stonith::fence_xvm" exec-time="59"/>
    <operation op="Fencing_monitor_120000" node="node1" call="12" rc="0" status="Done" rsc="Fencing" agent="stonith::fence_xvm" exec-time="70"/>
  </operations>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Show resource operations (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Show resource operations (XML)
=#=#=#= Begin test: List a promotable clone resource =#=#=#=
resource promotable-clone is running on: cluster01
resource promotable-clone is running on: cluster02 Promoted
=#=#=#= End test: List a promotable clone resource - OK (0) =#=#=#=
* Passed: crm_resource          - List a promotable clone resource
=#=#=#= Begin test: List a promotable clone resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --locate -r promotable-clone">
  <nodes resource="promotable-clone">
    <node>cluster01</node>
    <node state="promoted">cluster02</node>
  </nodes>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List a promotable clone resource (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List a promotable clone resource (XML)
=#=#=#= Begin test: List the primitive of a promotable clone resource =#=#=#=
resource promotable-rsc is running on: cluster01
resource promotable-rsc is running on: cluster02 Promoted
=#=#=#= End test: List the primitive of a promotable clone resource - OK (0) =#=#=#=
* Passed: crm_resource          - List the primitive of a promotable clone resource
=#=#=#= Begin test: List the primitive of a promotable clone resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --locate -r promotable-rsc">
  <nodes resource="promotable-rsc">
    <node>cluster01</node>
    <node state="promoted">cluster02</node>
  </nodes>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List the primitive of a promotable clone resource (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List the primitive of a promotable clone resource (XML)
=#=#=#= Begin test: List a single instance of a promotable clone resource =#=#=#=
resource promotable-rsc:0 is running on: cluster02 Promoted
=#=#=#= End test: List a single instance of a promotable clone resource - OK (0) =#=#=#=
* Passed: crm_resource          - List a single instance of a promotable clone resource
=#=#=#= Begin test: List a single instance of a promotable clone resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --locate -r promotable-rsc:0">
  <nodes resource="promotable-rsc:0">
    <node state="promoted">cluster02</node>
  </nodes>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List a single instance of a promotable clone resource (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List a single instance of a promotable clone resource (XML)
=#=#=#= Begin test: List another instance of a promotable clone resource =#=#=#=
resource promotable-rsc:1 is running on: cluster01
=#=#=#= End test: List another instance of a promotable clone resource - OK (0) =#=#=#=
* Passed: crm_resource          - List another instance of a promotable clone resource
=#=#=#= Begin test: List another instance of a promotable clone resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --output-as=xml --locate -r promotable-rsc:1">
  <nodes resource="promotable-rsc:1">
    <node>cluster01</node>
  </nodes>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: List another instance of a promotable clone resource (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - List another instance of a promotable clone resource (XML)
=#=#=#= Begin test: Try to move an instance of a cloned resource =#=#=#=
crm_resource: Cannot operate on clone resource instance 'promotable-rsc:0'
Error performing operation: Invalid parameter
=#=#=#= End test: Try to move an instance of a cloned resource - Invalid parameter (2) =#=#=#=
* Passed: crm_resource          - Try to move an instance of a cloned resource
=#=#=#= Begin test: Check that CIB_file="-" works - crm_resource (XML) =#=#=#=
<pacemaker-result api-version="X" request="crm_resource --digests -r rsc1 -N node1 --output-as=xml">
  <digests resource="rsc1" node="node1" task="start" interval="0ms">
    <digest type="all" hash="3acdbe4c12734ebeb1251a59545af936">
      <parameters passwd="secret" fake="0"/>
    </digest>
    <digest type="nonprivate" hash="279c477dbc38c621904a00ab9e599b2f">
      <parameters fake="0"/>
    </digest>
    <digest type="nonreloadable" hash="5de1fd72a2e7762ed41543231034f6d7">
      <parameters passwd="secret"/>
    </digest>
  </digests>
  <status code="0" message="OK"/>
</pacemaker-result>
=#=#=#= End test: Check that CIB_file="-" works - crm_resource (XML) - OK (0) =#=#=#=
* Passed: crm_resource          - Check that CIB_file="-" works - crm_resource (XML)
